{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naufalhisyam/TurbidityPrediction-thesis/blob/main/ResNet50_CV_ori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpSYbrzpM90P",
        "outputId": "7566a3da-f1b1-4e06-80fa-3d84a0f9d162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "!pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn.model_selection import KFold, train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKCAZxGrzo8m",
        "outputId": "c00d3628-9a3f-4dbc-c9e4-a78711d6ec88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TurbidityPrediction-thesis'...\n",
            "remote: Enumerating objects: 3141, done.\u001b[K\n",
            "remote: Counting objects: 100% (151/151), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 3141 (delta 56), reused 117 (delta 31), pack-reused 2990\u001b[K\n",
            "Receiving objects: 100% (3141/3141), 674.56 MiB | 21.17 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n",
            "Checking out files: 100% (3487/3487), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/naufalhisyam/TurbidityPrediction-thesis.git\n",
        "os.chdir('/content/TurbidityPrediction-thesis') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zNwDTsrAzo8o"
      },
      "outputs": [],
      "source": [
        "images = pd.read_csv(r'./Datasets/0degree_lowrange/0degInfo.csv') #load dataset info\n",
        "train_df, test_df = train_test_split(images, train_size=0.9, shuffle=True, random_state=1)\n",
        "Y = train_df[['Turbidity']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9c4a0DepYGth"
      },
      "outputs": [],
      "source": [
        "VALIDATION_R2 = []\n",
        "VALIDATION_LOSS = []\n",
        "VALIDATION_MSE = []\n",
        "VALIDATION_MAE = []\n",
        "\n",
        "name = 'ResNet_0deg_withTL'\n",
        "tl = True\n",
        "\n",
        "save_dir = f'saved_models/{name}'\n",
        "if not os.path.exists(save_dir):\n",
        "  os.makedirs(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_hHE40KdmqZI",
        "outputId": "6f277722-08d3-49f9-a635-0d2786548670"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def get_model():\n",
        "    #Create model\n",
        "    weight = None\n",
        "    if tl is True:\n",
        "        weight = 'imagenet'\n",
        "    base_model = tf.keras.applications.ResNet50(include_top=False, weights=weight, \n",
        "                                                input_shape=(224, 224, 3), pooling='avg')\n",
        "    out = base_model.output\n",
        "    #x = tf.keras.layers.Dropout(0.9)(out)\n",
        "    #x =  tf.keras.layers.Dense(4, activation='relu')(out)\n",
        "    #x =  tf.keras.layers.Dense(2, activation='relu')(x)\n",
        "    prediction = tf.keras.layers.Dense(1, activation='linear')(out)\n",
        "    model = tf.keras.Model(inputs = base_model.input, outputs = prediction)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def get_model_name(k):\n",
        "    return 'resnet_'+str(k)+'.h5'\n",
        "\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GiN2pSedmCqo"
      },
      "outputs": [],
      "source": [
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "kf = KFold(n_splits = 5)\n",
        "fold_var = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQDemGIbml2O",
        "outputId": "1ee60637-37fe-4e29-ff88-62bc589e53d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 388 validated image filenames.\n",
            "Found 98 validated image filenames.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 31.9360 - mae: 32.4291 - mse: 1875.3861 - R2: -0.3769\n",
            "Epoch 1: val_loss improved from inf to 232.82013, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 46s 658ms/step - loss: 31.9360 - mae: 32.4291 - mse: 1875.3861 - R2: -0.3769 - val_loss: 232.8201 - val_mae: 233.3201 - val_mse: 54988.3828 - val_R2: -42.1531\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 11.3757 - mae: 11.8620 - mse: 302.9475 - R2: 0.7776\n",
            "Epoch 2: val_loss improved from 232.82013 to 180.87769, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 452ms/step - loss: 11.3757 - mae: 11.8620 - mse: 302.9475 - R2: 0.7776 - val_loss: 180.8777 - val_mae: 181.3777 - val_mse: 33123.7812 - val_R2: -24.9945\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 11.0424 - mae: 11.5301 - mse: 242.2122 - R2: 0.8222\n",
            "Epoch 3: val_loss improved from 180.87769 to 178.85942, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 453ms/step - loss: 11.0424 - mae: 11.5301 - mse: 242.2122 - R2: 0.8222 - val_loss: 178.8594 - val_mae: 179.3594 - val_mse: 33186.2305 - val_R2: -25.0435\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 8.4833 - mae: 8.9709 - mse: 162.9853 - R2: 0.8803\n",
            "Epoch 4: val_loss improved from 178.85942 to 162.14563, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 453ms/step - loss: 8.4833 - mae: 8.9709 - mse: 162.9853 - R2: 0.8803 - val_loss: 162.1456 - val_mae: 162.6456 - val_mse: 26889.5430 - val_R2: -20.1021\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.9524 - mae: 7.4359 - mse: 98.6632 - R2: 0.9276\n",
            "Epoch 5: val_loss improved from 162.14563 to 36.07424, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 455ms/step - loss: 6.9524 - mae: 7.4359 - mse: 98.6632 - R2: 0.9276 - val_loss: 36.0742 - val_mae: 36.5742 - val_mse: 1612.4330 - val_R2: -0.2654\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.1338 - mae: 6.6142 - mse: 77.6387 - R2: 0.9430\n",
            "Epoch 6: val_loss did not improve from 36.07424\n",
            "13/13 [==============================] - 5s 360ms/step - loss: 6.1338 - mae: 6.6142 - mse: 77.6387 - R2: 0.9430 - val_loss: 39.1195 - val_mae: 39.6195 - val_mse: 1892.4962 - val_R2: -0.4852\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.6984 - mae: 7.1798 - mse: 92.5822 - R2: 0.9320\n",
            "Epoch 7: val_loss did not improve from 36.07424\n",
            "13/13 [==============================] - 5s 363ms/step - loss: 6.6984 - mae: 7.1798 - mse: 92.5822 - R2: 0.9320 - val_loss: 284.8762 - val_mae: 285.3762 - val_mse: 86222.1562 - val_R2: -66.6644\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.8748 - mae: 7.3509 - mse: 97.2557 - R2: 0.9286\n",
            "Epoch 8: val_loss did not improve from 36.07424\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 6.8748 - mae: 7.3509 - mse: 97.2557 - R2: 0.9286 - val_loss: 165.5541 - val_mae: 166.0541 - val_mse: 30155.0527 - val_R2: -22.6647\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.7438 - mae: 6.2207 - mse: 68.0107 - R2: 0.9501\n",
            "Epoch 9: val_loss did not improve from 36.07424\n",
            "13/13 [==============================] - 5s 363ms/step - loss: 5.7438 - mae: 6.2207 - mse: 68.0107 - R2: 0.9501 - val_loss: 43.2592 - val_mae: 43.7592 - val_mse: 2588.6685 - val_R2: -1.0315\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.6843 - mae: 7.1667 - mse: 93.8886 - R2: 0.9311\n",
            "Epoch 10: val_loss improved from 36.07424 to 7.88410, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 460ms/step - loss: 6.6843 - mae: 7.1667 - mse: 93.8886 - R2: 0.9311 - val_loss: 7.8841 - val_mae: 8.3665 - val_mse: 123.4864 - val_R2: 0.9031\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.8446 - mae: 8.3343 - mse: 125.9212 - R2: 0.9075\n",
            "Epoch 11: val_loss did not improve from 7.88410\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 7.8446 - mae: 8.3343 - mse: 125.9212 - R2: 0.9075 - val_loss: 10.9448 - val_mae: 11.4317 - val_mse: 251.7346 - val_R2: 0.8024\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.0446 - mae: 7.5343 - mse: 94.0131 - R2: 0.9310\n",
            "Epoch 12: val_loss did not improve from 7.88410\n",
            "13/13 [==============================] - 5s 365ms/step - loss: 7.0446 - mae: 7.5343 - mse: 94.0131 - R2: 0.9310 - val_loss: 11.6710 - val_mae: 12.1625 - val_mse: 312.2118 - val_R2: 0.7550\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.7954 - mae: 6.2776 - mse: 71.2993 - R2: 0.9477\n",
            "Epoch 13: val_loss did not improve from 7.88410\n",
            "13/13 [==============================] - 5s 368ms/step - loss: 5.7954 - mae: 6.2776 - mse: 71.2993 - R2: 0.9477 - val_loss: 13.8270 - val_mae: 14.3148 - val_mse: 424.4370 - val_R2: 0.6669\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.2106 - mae: 6.6891 - mse: 92.6949 - R2: 0.9319\n",
            "Epoch 14: val_loss did not improve from 7.88410\n",
            "13/13 [==============================] - 5s 369ms/step - loss: 6.2106 - mae: 6.6891 - mse: 92.6949 - R2: 0.9319 - val_loss: 30.4128 - val_mae: 30.9102 - val_mse: 1114.9017 - val_R2: 0.1251\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.2552 - mae: 5.7326 - mse: 57.6358 - R2: 0.9577\n",
            "Epoch 15: val_loss improved from 7.88410 to 7.82852, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 466ms/step - loss: 5.2552 - mae: 5.7326 - mse: 57.6358 - R2: 0.9577 - val_loss: 7.8285 - val_mae: 8.3131 - val_mse: 109.9741 - val_R2: 0.9137\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.3074 - mae: 6.7835 - mse: 88.6596 - R2: 0.9349\n",
            "Epoch 16: val_loss did not improve from 7.82852\n",
            "13/13 [==============================] - 5s 371ms/step - loss: 6.3074 - mae: 6.7835 - mse: 88.6596 - R2: 0.9349 - val_loss: 25.6289 - val_mae: 26.1177 - val_mse: 1030.4192 - val_R2: 0.1914\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.6638 - mae: 6.1478 - mse: 63.7285 - R2: 0.9532\n",
            "Epoch 17: val_loss did not improve from 7.82852\n",
            "13/13 [==============================] - 5s 372ms/step - loss: 5.6638 - mae: 6.1478 - mse: 63.7285 - R2: 0.9532 - val_loss: 16.2635 - val_mae: 16.7532 - val_mse: 441.6277 - val_R2: 0.6534\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.5881 - mae: 6.0683 - mse: 71.6962 - R2: 0.9474\n",
            "Epoch 18: val_loss did not improve from 7.82852\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 5.5881 - mae: 6.0683 - mse: 71.6962 - R2: 0.9474 - val_loss: 50.2334 - val_mae: 50.7314 - val_mse: 3432.9417 - val_R2: -1.6941\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.6473 - mae: 6.1255 - mse: 64.3302 - R2: 0.9528\n",
            "Epoch 19: val_loss did not improve from 7.82852\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 5.6473 - mae: 6.1255 - mse: 64.3302 - R2: 0.9528 - val_loss: 9.8095 - val_mae: 10.3031 - val_mse: 217.4065 - val_R2: 0.8294\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.8847 - mae: 5.3575 - mse: 61.2886 - R2: 0.9550\n",
            "Epoch 20: val_loss did not improve from 7.82852\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 4.8847 - mae: 5.3575 - mse: 61.2886 - R2: 0.9550 - val_loss: 27.9211 - val_mae: 28.4189 - val_mse: 1149.6964 - val_R2: 0.0978\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.5594 - mae: 8.0399 - mse: 107.1147 - R2: 0.9214\n",
            "Epoch 21: val_loss did not improve from 7.82852\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 7.5594 - mae: 8.0399 - mse: 107.1147 - R2: 0.9214 - val_loss: 9.4685 - val_mae: 9.9597 - val_mse: 146.2525 - val_R2: 0.8852\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.1206 - mae: 5.5978 - mse: 58.7949 - R2: 0.9568\n",
            "Epoch 22: val_loss did not improve from 7.82852\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 5.1206 - mae: 5.5978 - mse: 58.7949 - R2: 0.9568 - val_loss: 11.6594 - val_mae: 12.1523 - val_mse: 211.0089 - val_R2: 0.8344\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.7258 - mae: 5.2024 - mse: 52.8034 - R2: 0.9612\n",
            "Epoch 23: val_loss did not improve from 7.82852\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 4.7258 - mae: 5.2024 - mse: 52.8034 - R2: 0.9612 - val_loss: 12.6891 - val_mae: 13.1700 - val_mse: 322.3024 - val_R2: 0.7471\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.8035 - mae: 5.2796 - mse: 52.7400 - R2: 0.9613\n",
            "Epoch 24: val_loss improved from 7.82852 to 7.26889, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 470ms/step - loss: 4.8035 - mae: 5.2796 - mse: 52.7400 - R2: 0.9613 - val_loss: 7.2689 - val_mae: 7.7512 - val_mse: 112.7698 - val_R2: 0.9115\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.0502 - mae: 5.5225 - mse: 52.2192 - R2: 0.9617\n",
            "Epoch 25: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 372ms/step - loss: 5.0502 - mae: 5.5225 - mse: 52.2192 - R2: 0.9617 - val_loss: 14.4341 - val_mae: 14.9225 - val_mse: 302.6068 - val_R2: 0.7625\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.0980 - mae: 5.5747 - mse: 63.4094 - R2: 0.9534\n",
            "Epoch 26: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 372ms/step - loss: 5.0980 - mae: 5.5747 - mse: 63.4094 - R2: 0.9534 - val_loss: 7.9816 - val_mae: 8.4621 - val_mse: 146.8375 - val_R2: 0.8848\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.6826 - mae: 5.1535 - mse: 56.5625 - R2: 0.9585\n",
            "Epoch 27: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 4.6826 - mae: 5.1535 - mse: 56.5625 - R2: 0.9585 - val_loss: 9.8226 - val_mae: 10.3113 - val_mse: 200.9427 - val_R2: 0.8423\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2978 - mae: 4.7747 - mse: 40.3156 - R2: 0.9704\n",
            "Epoch 28: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 372ms/step - loss: 4.2978 - mae: 4.7747 - mse: 40.3156 - R2: 0.9704 - val_loss: 21.8889 - val_mae: 22.3889 - val_mse: 624.4935 - val_R2: 0.5099\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.8476 - mae: 5.3273 - mse: 50.0020 - R2: 0.9633\n",
            "Epoch 29: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 372ms/step - loss: 4.8476 - mae: 5.3273 - mse: 50.0020 - R2: 0.9633 - val_loss: 13.3004 - val_mae: 13.7838 - val_mse: 317.2503 - val_R2: 0.7510\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7804 - mae: 4.2495 - mse: 33.8227 - R2: 0.9752\n",
            "Epoch 30: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 370ms/step - loss: 3.7804 - mae: 4.2495 - mse: 33.8227 - R2: 0.9752 - val_loss: 10.1814 - val_mae: 10.6764 - val_mse: 150.6085 - val_R2: 0.8818\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.6259 - mae: 6.1011 - mse: 68.6975 - R2: 0.9496\n",
            "Epoch 31: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 392ms/step - loss: 5.6259 - mae: 6.1011 - mse: 68.6975 - R2: 0.9496 - val_loss: 14.4811 - val_mae: 14.9764 - val_mse: 303.1322 - val_R2: 0.7621\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7727 - mae: 4.2422 - mse: 36.6079 - R2: 0.9731\n",
            "Epoch 32: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 370ms/step - loss: 3.7727 - mae: 4.2422 - mse: 36.6079 - R2: 0.9731 - val_loss: 7.9169 - val_mae: 8.3914 - val_mse: 125.4095 - val_R2: 0.9016\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.8161 - mae: 5.2873 - mse: 51.9717 - R2: 0.9618\n",
            "Epoch 33: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 371ms/step - loss: 4.8161 - mae: 5.2873 - mse: 51.9717 - R2: 0.9618 - val_loss: 18.4165 - val_mae: 18.9084 - val_mse: 674.1688 - val_R2: 0.4709\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0405 - mae: 4.5097 - mse: 40.9126 - R2: 0.9700\n",
            "Epoch 34: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 4.0405 - mae: 4.5097 - mse: 40.9126 - R2: 0.9700 - val_loss: 20.3407 - val_mae: 20.8389 - val_mse: 845.3714 - val_R2: 0.3366\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.4343 - mae: 4.9097 - mse: 46.4120 - R2: 0.9659\n",
            "Epoch 35: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 372ms/step - loss: 4.4343 - mae: 4.9097 - mse: 46.4120 - R2: 0.9659 - val_loss: 26.0704 - val_mae: 26.5684 - val_mse: 826.1416 - val_R2: 0.3517\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.1914 - mae: 4.6708 - mse: 37.3000 - R2: 0.9726\n",
            "Epoch 36: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 4.1914 - mae: 4.6708 - mse: 37.3000 - R2: 0.9726 - val_loss: 13.4750 - val_mae: 13.9679 - val_mse: 289.3965 - val_R2: 0.7729\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.4051 - mae: 4.8788 - mse: 45.8351 - R2: 0.9663\n",
            "Epoch 37: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 372ms/step - loss: 4.4051 - mae: 4.8788 - mse: 45.8351 - R2: 0.9663 - val_loss: 11.4864 - val_mae: 11.9774 - val_mse: 225.3881 - val_R2: 0.8231\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.7556 - mae: 5.2282 - mse: 50.7142 - R2: 0.9628\n",
            "Epoch 38: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 397ms/step - loss: 4.7556 - mae: 5.2282 - mse: 50.7142 - R2: 0.9628 - val_loss: 12.7052 - val_mae: 13.1985 - val_mse: 255.3552 - val_R2: 0.7996\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7816 - mae: 4.2481 - mse: 37.8800 - R2: 0.9722\n",
            "Epoch 39: val_loss did not improve from 7.26889\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 3.7816 - mae: 4.2481 - mse: 37.8800 - R2: 0.9722 - val_loss: 11.7177 - val_mae: 12.2091 - val_mse: 209.1953 - val_R2: 0.8358\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.4550 - mae: 4.9286 - mse: 45.6867 - R2: 0.9665\n",
            "Epoch 40: val_loss improved from 7.26889 to 6.55880, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 470ms/step - loss: 4.4550 - mae: 4.9286 - mse: 45.6867 - R2: 0.9665 - val_loss: 6.5588 - val_mae: 7.0337 - val_mse: 91.1674 - val_R2: 0.9285\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6230 - mae: 4.0895 - mse: 31.3651 - R2: 0.9770\n",
            "Epoch 41: val_loss did not improve from 6.55880\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 3.6230 - mae: 4.0895 - mse: 31.3651 - R2: 0.9770 - val_loss: 19.3394 - val_mae: 19.8210 - val_mse: 755.4234 - val_R2: 0.4072\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3895 - mae: 3.8568 - mse: 27.6496 - R2: 0.9797\n",
            "Epoch 42: val_loss did not improve from 6.55880\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 3.3895 - mae: 3.8568 - mse: 27.6496 - R2: 0.9797 - val_loss: 15.6943 - val_mae: 16.1929 - val_mse: 347.2942 - val_R2: 0.7275\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7349 - mae: 4.2070 - mse: 31.0107 - R2: 0.9772\n",
            "Epoch 43: val_loss did not improve from 6.55880\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 3.7349 - mae: 4.2070 - mse: 31.0107 - R2: 0.9772 - val_loss: 17.7234 - val_mae: 18.2192 - val_mse: 419.8983 - val_R2: 0.6705\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.1754 - mae: 4.6427 - mse: 37.7856 - R2: 0.9723\n",
            "Epoch 44: val_loss did not improve from 6.55880\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 4.1754 - mae: 4.6427 - mse: 37.7856 - R2: 0.9723 - val_loss: 9.7186 - val_mae: 10.2021 - val_mse: 161.8450 - val_R2: 0.8730\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3417 - mae: 3.8071 - mse: 24.6335 - R2: 0.9819\n",
            "Epoch 45: val_loss improved from 6.55880 to 5.42481, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 470ms/step - loss: 3.3417 - mae: 3.8071 - mse: 24.6335 - R2: 0.9819 - val_loss: 5.4248 - val_mae: 5.9013 - val_mse: 58.1015 - val_R2: 0.9544\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4433 - mae: 3.9089 - mse: 28.3103 - R2: 0.9792\n",
            "Epoch 46: val_loss did not improve from 5.42481\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 3.4433 - mae: 3.9089 - mse: 28.3103 - R2: 0.9792 - val_loss: 17.0893 - val_mae: 17.5832 - val_mse: 435.8271 - val_R2: 0.6580\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7948 - mae: 4.2620 - mse: 30.7813 - R2: 0.9774\n",
            "Epoch 47: val_loss did not improve from 5.42481\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 3.7948 - mae: 4.2620 - mse: 30.7813 - R2: 0.9774 - val_loss: 22.2206 - val_mae: 22.7197 - val_mse: 702.8718 - val_R2: 0.4484\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3738 - mae: 3.8445 - mse: 24.7420 - R2: 0.9818\n",
            "Epoch 48: val_loss improved from 5.42481 to 4.87917, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 469ms/step - loss: 3.3738 - mae: 3.8445 - mse: 24.7420 - R2: 0.9818 - val_loss: 4.8792 - val_mae: 5.3633 - val_mse: 48.3007 - val_R2: 0.9621\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1863 - mae: 3.6448 - mse: 25.4790 - R2: 0.9813\n",
            "Epoch 49: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 3.1863 - mae: 3.6448 - mse: 25.4790 - R2: 0.9813 - val_loss: 15.9462 - val_mae: 16.4251 - val_mse: 428.5519 - val_R2: 0.6637\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2561 - mae: 3.7177 - mse: 24.7761 - R2: 0.9818\n",
            "Epoch 50: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 3.2561 - mae: 3.7177 - mse: 24.7761 - R2: 0.9818 - val_loss: 19.6377 - val_mae: 20.1330 - val_mse: 596.0746 - val_R2: 0.5322\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.5371 - mae: 5.0064 - mse: 45.7347 - R2: 0.9664\n",
            "Epoch 51: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 4.5371 - mae: 5.0064 - mse: 45.7347 - R2: 0.9664 - val_loss: 15.8245 - val_mae: 16.3121 - val_mse: 447.7164 - val_R2: 0.6486\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7563 - mae: 4.2193 - mse: 39.5799 - R2: 0.9709\n",
            "Epoch 52: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 3.7563 - mae: 4.2193 - mse: 39.5799 - R2: 0.9709 - val_loss: 22.5161 - val_mae: 23.0110 - val_mse: 743.5903 - val_R2: 0.4165\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8730 - mae: 3.3289 - mse: 24.0805 - R2: 0.9823\n",
            "Epoch 53: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.8730 - mae: 3.3289 - mse: 24.0805 - R2: 0.9823 - val_loss: 24.8971 - val_mae: 25.3929 - val_mse: 915.9698 - val_R2: 0.2812\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9864 - mae: 4.4578 - mse: 35.5978 - R2: 0.9739\n",
            "Epoch 54: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 3.9864 - mae: 4.4578 - mse: 35.5978 - R2: 0.9739 - val_loss: 46.0439 - val_mae: 46.5439 - val_mse: 2828.4399 - val_R2: -1.2197\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7803 - mae: 3.2419 - mse: 19.6774 - R2: 0.9856\n",
            "Epoch 55: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.7803 - mae: 3.2419 - mse: 19.6774 - R2: 0.9856 - val_loss: 15.1378 - val_mae: 15.6266 - val_mse: 369.8818 - val_R2: 0.7097\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.8176 - mae: 4.2863 - mse: 34.2123 - R2: 0.9749\n",
            "Epoch 56: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 3.8176 - mae: 4.2863 - mse: 34.2123 - R2: 0.9749 - val_loss: 17.9942 - val_mae: 18.4846 - val_mse: 629.5368 - val_R2: 0.5060\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6497 - mae: 4.1175 - mse: 31.0957 - R2: 0.9772\n",
            "Epoch 57: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 3.6497 - mae: 4.1175 - mse: 31.0957 - R2: 0.9772 - val_loss: 16.6543 - val_mae: 17.1475 - val_mse: 470.4894 - val_R2: 0.6308\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9021 - mae: 3.3559 - mse: 22.5093 - R2: 0.9835\n",
            "Epoch 58: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.9021 - mae: 3.3559 - mse: 22.5093 - R2: 0.9835 - val_loss: 59.6275 - val_mae: 60.1252 - val_mse: 4907.5547 - val_R2: -2.8513\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.5249 - mae: 3.9896 - mse: 30.3620 - R2: 0.9777\n",
            "Epoch 59: val_loss did not improve from 4.87917\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 3.5249 - mae: 3.9896 - mse: 30.3620 - R2: 0.9777 - val_loss: 36.2074 - val_mae: 36.7055 - val_mse: 1848.6924 - val_R2: -0.4508\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9310 - mae: 3.3901 - mse: 21.8305 - R2: 0.9840\n",
            "Epoch 60: val_loss improved from 4.87917 to 4.03681, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 472ms/step - loss: 2.9310 - mae: 3.3901 - mse: 21.8305 - R2: 0.9840 - val_loss: 4.0368 - val_mae: 4.4985 - val_mse: 32.1081 - val_R2: 0.9748\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7892 - mae: 4.2572 - mse: 35.1828 - R2: 0.9742\n",
            "Epoch 61: val_loss did not improve from 4.03681\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 3.7892 - mae: 4.2572 - mse: 35.1828 - R2: 0.9742 - val_loss: 4.5902 - val_mae: 5.0749 - val_mse: 39.4961 - val_R2: 0.9690\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0510 - mae: 3.5123 - mse: 22.9933 - R2: 0.9831\n",
            "Epoch 62: val_loss improved from 4.03681 to 3.88193, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 473ms/step - loss: 3.0510 - mae: 3.5123 - mse: 22.9933 - R2: 0.9831 - val_loss: 3.8819 - val_mae: 4.3477 - val_mse: 29.2775 - val_R2: 0.9770\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3889 - mae: 3.8562 - mse: 29.3879 - R2: 0.9784\n",
            "Epoch 63: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 3.3889 - mae: 3.8562 - mse: 29.3879 - R2: 0.9784 - val_loss: 11.2245 - val_mae: 11.7232 - val_mse: 179.7517 - val_R2: 0.8589\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5753 - mae: 3.0320 - mse: 17.3272 - R2: 0.9873\n",
            "Epoch 64: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 2.5753 - mae: 3.0320 - mse: 17.3272 - R2: 0.9873 - val_loss: 19.1476 - val_mae: 19.6459 - val_mse: 478.2013 - val_R2: 0.6247\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6537 - mae: 3.1097 - mse: 19.0504 - R2: 0.9860\n",
            "Epoch 65: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.6537 - mae: 3.1097 - mse: 19.0504 - R2: 0.9860 - val_loss: 15.0018 - val_mae: 15.5005 - val_mse: 288.2626 - val_R2: 0.7738\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9200 - mae: 3.3667 - mse: 24.2575 - R2: 0.9822\n",
            "Epoch 66: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 398ms/step - loss: 2.9200 - mae: 3.3667 - mse: 24.2575 - R2: 0.9822 - val_loss: 7.9276 - val_mae: 8.4227 - val_mse: 94.3397 - val_R2: 0.9260\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0097 - mae: 3.4663 - mse: 23.3335 - R2: 0.9829\n",
            "Epoch 67: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 3.0097 - mae: 3.4663 - mse: 23.3335 - R2: 0.9829 - val_loss: 12.9591 - val_mae: 13.4522 - val_mse: 231.1473 - val_R2: 0.8186\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0794 - mae: 3.5340 - mse: 24.6898 - R2: 0.9819\n",
            "Epoch 68: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 3.0794 - mae: 3.5340 - mse: 24.6898 - R2: 0.9819 - val_loss: 7.8697 - val_mae: 8.3574 - val_mse: 116.7956 - val_R2: 0.9083\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8982 - mae: 3.3607 - mse: 19.4271 - R2: 0.9857\n",
            "Epoch 69: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 398ms/step - loss: 2.8982 - mae: 3.3607 - mse: 19.4271 - R2: 0.9857 - val_loss: 11.3325 - val_mae: 11.8228 - val_mse: 185.5930 - val_R2: 0.8544\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4785 - mae: 2.9326 - mse: 17.4537 - R2: 0.9872\n",
            "Epoch 70: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.4785 - mae: 2.9326 - mse: 17.4537 - R2: 0.9872 - val_loss: 9.4394 - val_mae: 9.9317 - val_mse: 143.8454 - val_R2: 0.8871\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6003 - mae: 3.0528 - mse: 19.8919 - R2: 0.9854\n",
            "Epoch 71: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 2.6003 - mae: 3.0528 - mse: 19.8919 - R2: 0.9854 - val_loss: 8.8785 - val_mae: 9.3476 - val_mse: 134.9644 - val_R2: 0.8941\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7208 - mae: 3.1795 - mse: 18.0241 - R2: 0.9868\n",
            "Epoch 72: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 2.7208 - mae: 3.1795 - mse: 18.0241 - R2: 0.9868 - val_loss: 6.2824 - val_mae: 6.7623 - val_mse: 69.5105 - val_R2: 0.9455\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4909 - mae: 3.9550 - mse: 29.5171 - R2: 0.9783\n",
            "Epoch 73: val_loss did not improve from 3.88193\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 3.4909 - mae: 3.9550 - mse: 29.5171 - R2: 0.9783 - val_loss: 16.9673 - val_mae: 17.4533 - val_mse: 420.7328 - val_R2: 0.6698\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1654 - mae: 3.6293 - mse: 23.9634 - R2: 0.9824\n",
            "Epoch 74: val_loss improved from 3.88193 to 3.09765, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 471ms/step - loss: 3.1654 - mae: 3.6293 - mse: 23.9634 - R2: 0.9824 - val_loss: 3.0976 - val_mae: 3.5633 - val_mse: 19.4270 - val_R2: 0.9848\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2266 - mae: 3.6838 - mse: 26.2949 - R2: 0.9807\n",
            "Epoch 75: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 3.2266 - mae: 3.6838 - mse: 26.2949 - R2: 0.9807 - val_loss: 3.6408 - val_mae: 4.1148 - val_mse: 27.2916 - val_R2: 0.9786\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4893 - mae: 2.9351 - mse: 17.7274 - R2: 0.9870\n",
            "Epoch 76: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.4893 - mae: 2.9351 - mse: 17.7274 - R2: 0.9870 - val_loss: 4.3883 - val_mae: 4.8646 - val_mse: 38.0966 - val_R2: 0.9701\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4503 - mae: 2.8958 - mse: 15.9889 - R2: 0.9883\n",
            "Epoch 77: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.4503 - mae: 2.8958 - mse: 15.9889 - R2: 0.9883 - val_loss: 5.4419 - val_mae: 5.9141 - val_mse: 63.0864 - val_R2: 0.9505\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5002 - mae: 2.9578 - mse: 15.8782 - R2: 0.9883\n",
            "Epoch 78: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 2.5002 - mae: 2.9578 - mse: 15.8782 - R2: 0.9883 - val_loss: 5.5827 - val_mae: 6.0705 - val_mse: 53.9571 - val_R2: 0.9577\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7555 - mae: 3.2116 - mse: 19.2456 - R2: 0.9859\n",
            "Epoch 79: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.7555 - mae: 3.2116 - mse: 19.2456 - R2: 0.9859 - val_loss: 10.2345 - val_mae: 10.7240 - val_mse: 161.6700 - val_R2: 0.8731\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2343 - mae: 2.6825 - mse: 12.6745 - R2: 0.9907\n",
            "Epoch 80: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.2343 - mae: 2.6825 - mse: 12.6745 - R2: 0.9907 - val_loss: 3.8829 - val_mae: 4.3553 - val_mse: 33.7607 - val_R2: 0.9735\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6177 - mae: 3.0651 - mse: 17.3718 - R2: 0.9872\n",
            "Epoch 81: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 396ms/step - loss: 2.6177 - mae: 3.0651 - mse: 17.3718 - R2: 0.9872 - val_loss: 16.3907 - val_mae: 16.8795 - val_mse: 389.0285 - val_R2: 0.6947\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8123 - mae: 3.2756 - mse: 19.6411 - R2: 0.9856\n",
            "Epoch 82: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.8123 - mae: 3.2756 - mse: 19.6411 - R2: 0.9856 - val_loss: 12.9794 - val_mae: 13.4691 - val_mse: 300.4852 - val_R2: 0.7642\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2370 - mae: 2.6912 - mse: 12.9883 - R2: 0.9905\n",
            "Epoch 83: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.2370 - mae: 2.6912 - mse: 12.9883 - R2: 0.9905 - val_loss: 16.0047 - val_mae: 16.5024 - val_mse: 408.2155 - val_R2: 0.6796\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5719 - mae: 3.0226 - mse: 17.7080 - R2: 0.9870\n",
            "Epoch 84: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 2.5719 - mae: 3.0226 - mse: 17.7080 - R2: 0.9870 - val_loss: 10.6726 - val_mae: 11.1498 - val_mse: 200.0437 - val_R2: 0.8430\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3562 - mae: 2.8137 - mse: 14.8572 - R2: 0.9891\n",
            "Epoch 85: val_loss did not improve from 3.09765\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 2.3562 - mae: 2.8137 - mse: 14.8572 - R2: 0.9891 - val_loss: 7.0384 - val_mae: 7.5056 - val_mse: 94.0998 - val_R2: 0.9262\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0584 - mae: 2.5005 - mse: 11.7292 - R2: 0.9914\n",
            "Epoch 86: val_loss improved from 3.09765 to 3.06614, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 471ms/step - loss: 2.0584 - mae: 2.5005 - mse: 11.7292 - R2: 0.9914 - val_loss: 3.0661 - val_mae: 3.5309 - val_mse: 18.9877 - val_R2: 0.9851\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3985 - mae: 2.8509 - mse: 14.8495 - R2: 0.9891\n",
            "Epoch 87: val_loss did not improve from 3.06614\n",
            "13/13 [==============================] - 5s 397ms/step - loss: 2.3985 - mae: 2.8509 - mse: 14.8495 - R2: 0.9891 - val_loss: 14.5183 - val_mae: 15.0114 - val_mse: 351.7121 - val_R2: 0.7240\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4481 - mae: 2.8978 - mse: 16.8276 - R2: 0.9876\n",
            "Epoch 88: val_loss did not improve from 3.06614\n",
            "13/13 [==============================] - 5s 395ms/step - loss: 2.4481 - mae: 2.8978 - mse: 16.8276 - R2: 0.9876 - val_loss: 4.9941 - val_mae: 5.4896 - val_mse: 43.7670 - val_R2: 0.9657\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7926 - mae: 3.2409 - mse: 20.8069 - R2: 0.9847\n",
            "Epoch 89: val_loss did not improve from 3.06614\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.7926 - mae: 3.2409 - mse: 20.8069 - R2: 0.9847 - val_loss: 3.4299 - val_mae: 3.9076 - val_mse: 21.7544 - val_R2: 0.9829\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7695 - mae: 3.2256 - mse: 18.8355 - R2: 0.9862\n",
            "Epoch 90: val_loss improved from 3.06614 to 3.01096, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 470ms/step - loss: 2.7695 - mae: 3.2256 - mse: 18.8355 - R2: 0.9862 - val_loss: 3.0110 - val_mae: 3.4707 - val_mse: 19.9701 - val_R2: 0.9843\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6606 - mae: 3.1158 - mse: 18.1459 - R2: 0.9867\n",
            "Epoch 91: val_loss did not improve from 3.01096\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 2.6606 - mae: 3.1158 - mse: 18.1459 - R2: 0.9867 - val_loss: 5.2533 - val_mae: 5.7189 - val_mse: 61.7280 - val_R2: 0.9516\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9816 - mae: 2.4281 - mse: 10.2101 - R2: 0.9925\n",
            "Epoch 92: val_loss did not improve from 3.01096\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.9816 - mae: 2.4281 - mse: 10.2101 - R2: 0.9925 - val_loss: 6.0127 - val_mae: 6.4919 - val_mse: 77.4956 - val_R2: 0.9392\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4856 - mae: 2.9306 - mse: 16.8750 - R2: 0.9876\n",
            "Epoch 93: val_loss improved from 3.01096 to 2.99105, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 496ms/step - loss: 2.4856 - mae: 2.9306 - mse: 16.8750 - R2: 0.9876 - val_loss: 2.9911 - val_mae: 3.4514 - val_mse: 19.9014 - val_R2: 0.9844\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2504 - mae: 2.6920 - mse: 15.0696 - R2: 0.9889\n",
            "Epoch 94: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 372ms/step - loss: 2.2504 - mae: 2.6920 - mse: 15.0696 - R2: 0.9889 - val_loss: 18.0907 - val_mae: 18.5879 - val_mse: 477.0769 - val_R2: 0.6256\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5445 - mae: 2.9907 - mse: 18.3980 - R2: 0.9865\n",
            "Epoch 95: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.5445 - mae: 2.9907 - mse: 18.3980 - R2: 0.9865 - val_loss: 15.4786 - val_mae: 15.9771 - val_mse: 326.1161 - val_R2: 0.7441\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3404 - mae: 2.7835 - mse: 15.7144 - R2: 0.9885\n",
            "Epoch 96: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.3404 - mae: 2.7835 - mse: 15.7144 - R2: 0.9885 - val_loss: 11.0105 - val_mae: 11.4985 - val_mse: 187.0068 - val_R2: 0.8532\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0113 - mae: 2.4630 - mse: 9.9410 - R2: 0.9927 \n",
            "Epoch 97: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.0113 - mae: 2.4630 - mse: 9.9410 - R2: 0.9927 - val_loss: 10.1547 - val_mae: 10.6436 - val_mse: 167.5166 - val_R2: 0.8685\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6226 - mae: 3.0708 - mse: 18.2266 - R2: 0.9866\n",
            "Epoch 98: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.6226 - mae: 3.0708 - mse: 18.2266 - R2: 0.9866 - val_loss: 7.0886 - val_mae: 7.5884 - val_mse: 81.9573 - val_R2: 0.9357\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0427 - mae: 2.4817 - mse: 12.3932 - R2: 0.9909\n",
            "Epoch 99: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 2.0427 - mae: 2.4817 - mse: 12.3932 - R2: 0.9909 - val_loss: 4.5978 - val_mae: 5.0855 - val_mse: 39.5564 - val_R2: 0.9690\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2368 - mae: 2.6864 - mse: 12.7714 - R2: 0.9906\n",
            "Epoch 100: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.2368 - mae: 2.6864 - mse: 12.7714 - R2: 0.9906 - val_loss: 3.1893 - val_mae: 3.6690 - val_mse: 23.2609 - val_R2: 0.9817\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4635 - mae: 2.9177 - mse: 14.9628 - R2: 0.9890\n",
            "Epoch 101: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 2.4635 - mae: 2.9177 - mse: 14.9628 - R2: 0.9890 - val_loss: 3.7081 - val_mae: 4.1853 - val_mse: 30.7519 - val_R2: 0.9759\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3018 - mae: 2.7577 - mse: 13.4762 - R2: 0.9901\n",
            "Epoch 102: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 2.3018 - mae: 2.7577 - mse: 13.4762 - R2: 0.9901 - val_loss: 4.9424 - val_mae: 5.4137 - val_mse: 49.4435 - val_R2: 0.9612\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0725 - mae: 2.5194 - mse: 14.2623 - R2: 0.9895\n",
            "Epoch 103: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.0725 - mae: 2.5194 - mse: 14.2623 - R2: 0.9895 - val_loss: 4.1890 - val_mae: 4.6585 - val_mse: 38.3693 - val_R2: 0.9699\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3859 - mae: 2.8309 - mse: 18.7139 - R2: 0.9863\n",
            "Epoch 104: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 397ms/step - loss: 2.3859 - mae: 2.8309 - mse: 18.7139 - R2: 0.9863 - val_loss: 7.5905 - val_mae: 8.0812 - val_mse: 100.4706 - val_R2: 0.9212\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1024 - mae: 2.5471 - mse: 12.4005 - R2: 0.9909\n",
            "Epoch 105: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.1024 - mae: 2.5471 - mse: 12.4005 - R2: 0.9909 - val_loss: 6.4978 - val_mae: 6.9801 - val_mse: 87.3248 - val_R2: 0.9315\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3902 - mae: 2.8394 - mse: 16.3418 - R2: 0.9880\n",
            "Epoch 106: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.3902 - mae: 2.8394 - mse: 16.3418 - R2: 0.9880 - val_loss: 12.2949 - val_mae: 12.7894 - val_mse: 202.9486 - val_R2: 0.8407\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5600 - mae: 3.0139 - mse: 17.4748 - R2: 0.9872\n",
            "Epoch 107: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 397ms/step - loss: 2.5600 - mae: 3.0139 - mse: 17.4748 - R2: 0.9872 - val_loss: 4.6830 - val_mae: 5.1634 - val_mse: 44.1388 - val_R2: 0.9654\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1368 - mae: 2.5863 - mse: 11.7991 - R2: 0.9913\n",
            "Epoch 108: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 2.1368 - mae: 2.5863 - mse: 11.7991 - R2: 0.9913 - val_loss: 10.3360 - val_mae: 10.8252 - val_mse: 166.5849 - val_R2: 0.8693\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4336 - mae: 2.8909 - mse: 15.7128 - R2: 0.9885\n",
            "Epoch 109: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 398ms/step - loss: 2.4336 - mae: 2.8909 - mse: 15.7128 - R2: 0.9885 - val_loss: 12.1121 - val_mae: 12.5998 - val_mse: 212.1385 - val_R2: 0.8335\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7876 - mae: 2.2260 - mse: 9.9687 - R2: 0.9927\n",
            "Epoch 110: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 1.7876 - mae: 2.2260 - mse: 9.9687 - R2: 0.9927 - val_loss: 13.5905 - val_mae: 14.0828 - val_mse: 275.6795 - val_R2: 0.7837\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2512 - mae: 2.6993 - mse: 13.4702 - R2: 0.9901\n",
            "Epoch 111: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.2512 - mae: 2.6993 - mse: 13.4702 - R2: 0.9901 - val_loss: 15.2455 - val_mae: 15.7394 - val_mse: 328.7602 - val_R2: 0.7420\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8044 - mae: 2.2391 - mse: 10.5006 - R2: 0.9923\n",
            "Epoch 112: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 1.8044 - mae: 2.2391 - mse: 10.5006 - R2: 0.9923 - val_loss: 14.9958 - val_mae: 15.4946 - val_mse: 324.1102 - val_R2: 0.7456\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0895 - mae: 2.5294 - mse: 12.9586 - R2: 0.9905\n",
            "Epoch 113: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 2.0895 - mae: 2.5294 - mse: 12.9586 - R2: 0.9905 - val_loss: 8.7222 - val_mae: 9.2192 - val_mse: 115.6245 - val_R2: 0.9093\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0684 - mae: 2.5056 - mse: 12.2372 - R2: 0.9910\n",
            "Epoch 114: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.0684 - mae: 2.5056 - mse: 12.2372 - R2: 0.9910 - val_loss: 9.6389 - val_mae: 10.1246 - val_mse: 159.0972 - val_R2: 0.8751\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1599 - mae: 2.6013 - mse: 12.8450 - R2: 0.9906\n",
            "Epoch 115: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 2.1599 - mae: 2.6013 - mse: 12.8450 - R2: 0.9906 - val_loss: 16.6308 - val_mae: 17.1192 - val_mse: 430.9643 - val_R2: 0.6618\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6940 - mae: 2.1294 - mse: 8.9065 - R2: 0.9935\n",
            "Epoch 116: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.6940 - mae: 2.1294 - mse: 8.9065 - R2: 0.9935 - val_loss: 13.5208 - val_mae: 14.0118 - val_mse: 285.0177 - val_R2: 0.7763\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9774 - mae: 2.4290 - mse: 10.2282 - R2: 0.9925\n",
            "Epoch 117: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.9774 - mae: 2.4290 - mse: 10.2282 - R2: 0.9925 - val_loss: 8.6728 - val_mae: 9.1548 - val_mse: 127.4125 - val_R2: 0.9000\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8443 - mae: 2.2930 - mse: 8.8816 - R2: 0.9935\n",
            "Epoch 118: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.8443 - mae: 2.2930 - mse: 8.8816 - R2: 0.9935 - val_loss: 6.1813 - val_mae: 6.6712 - val_mse: 68.9837 - val_R2: 0.9459\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6230 - mae: 2.0620 - mse: 7.1579 - R2: 0.9947\n",
            "Epoch 119: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.6230 - mae: 2.0620 - mse: 7.1579 - R2: 0.9947 - val_loss: 17.3978 - val_mae: 17.8864 - val_mse: 436.8346 - val_R2: 0.6572\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6648 - mae: 2.0915 - mse: 8.0550 - R2: 0.9941\n",
            "Epoch 120: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 1.6648 - mae: 2.0915 - mse: 8.0550 - R2: 0.9941 - val_loss: 5.9935 - val_mae: 6.4691 - val_mse: 67.6945 - val_R2: 0.9469\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3851 - mae: 1.8146 - mse: 5.9064 - R2: 0.9957\n",
            "Epoch 121: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.3851 - mae: 1.8146 - mse: 5.9064 - R2: 0.9957 - val_loss: 6.5503 - val_mae: 7.0255 - val_mse: 90.9788 - val_R2: 0.9286\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2005 - mae: 2.6494 - mse: 14.4963 - R2: 0.9894\n",
            "Epoch 122: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.2005 - mae: 2.6494 - mse: 14.4963 - R2: 0.9894 - val_loss: 8.6539 - val_mae: 9.1403 - val_mse: 135.0430 - val_R2: 0.8940\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2267 - mae: 2.6669 - mse: 15.4484 - R2: 0.9887\n",
            "Epoch 123: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 2.2267 - mae: 2.6669 - mse: 15.4484 - R2: 0.9887 - val_loss: 4.2623 - val_mae: 4.7311 - val_mse: 36.5404 - val_R2: 0.9713\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1867 - mae: 2.6230 - mse: 13.3690 - R2: 0.9902\n",
            "Epoch 124: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 2.1867 - mae: 2.6230 - mse: 13.3690 - R2: 0.9902 - val_loss: 5.7475 - val_mae: 6.2334 - val_mse: 73.1935 - val_R2: 0.9426\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6097 - mae: 2.0349 - mse: 8.8261 - R2: 0.9935\n",
            "Epoch 125: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 1.6097 - mae: 2.0349 - mse: 8.8261 - R2: 0.9935 - val_loss: 3.7502 - val_mae: 4.2222 - val_mse: 30.6242 - val_R2: 0.9760\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0464 - mae: 2.4984 - mse: 11.9324 - R2: 0.9912\n",
            "Epoch 126: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.0464 - mae: 2.4984 - mse: 11.9324 - R2: 0.9912 - val_loss: 5.0933 - val_mae: 5.5609 - val_mse: 60.2239 - val_R2: 0.9527\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9233 - mae: 2.3702 - mse: 10.1192 - R2: 0.9926\n",
            "Epoch 127: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.9233 - mae: 2.3702 - mse: 10.1192 - R2: 0.9926 - val_loss: 9.6873 - val_mae: 10.1724 - val_mse: 161.8279 - val_R2: 0.8730\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7302 - mae: 2.1668 - mse: 9.4001 - R2: 0.9931\n",
            "Epoch 128: val_loss did not improve from 2.99105\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.7302 - mae: 2.1668 - mse: 9.4001 - R2: 0.9931 - val_loss: 3.6020 - val_mae: 4.0808 - val_mse: 28.4391 - val_R2: 0.9777\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1444 - mae: 2.5934 - mse: 13.1650 - R2: 0.9903\n",
            "Epoch 129: val_loss improved from 2.99105 to 2.82214, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 469ms/step - loss: 2.1444 - mae: 2.5934 - mse: 13.1650 - R2: 0.9903 - val_loss: 2.8221 - val_mae: 3.2832 - val_mse: 20.3574 - val_R2: 0.9840\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5373 - mae: 1.9658 - mse: 6.7594 - R2: 0.9950\n",
            "Epoch 130: val_loss did not improve from 2.82214\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.5373 - mae: 1.9658 - mse: 6.7594 - R2: 0.9950 - val_loss: 4.3097 - val_mae: 4.7770 - val_mse: 42.5044 - val_R2: 0.9666\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0175 - mae: 2.4556 - mse: 15.7839 - R2: 0.9884\n",
            "Epoch 131: val_loss did not improve from 2.82214\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.0175 - mae: 2.4556 - mse: 15.7839 - R2: 0.9884 - val_loss: 5.0598 - val_mae: 5.5361 - val_mse: 41.1678 - val_R2: 0.9677\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8433 - mae: 2.2727 - mse: 9.9594 - R2: 0.9927\n",
            "Epoch 132: val_loss did not improve from 2.82214\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.8433 - mae: 2.2727 - mse: 9.9594 - R2: 0.9927 - val_loss: 6.3040 - val_mae: 6.7822 - val_mse: 69.6357 - val_R2: 0.9454\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5038 - mae: 1.9401 - mse: 6.7511 - R2: 0.9950\n",
            "Epoch 133: val_loss did not improve from 2.82214\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 1.5038 - mae: 1.9401 - mse: 6.7511 - R2: 0.9950 - val_loss: 7.3975 - val_mae: 7.8913 - val_mse: 85.6856 - val_R2: 0.9328\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9846 - mae: 2.4201 - mse: 11.1742 - R2: 0.9918\n",
            "Epoch 134: val_loss did not improve from 2.82214\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 1.9846 - mae: 2.4201 - mse: 11.1742 - R2: 0.9918 - val_loss: 33.6116 - val_mae: 34.1095 - val_mse: 1501.0103 - val_R2: -0.1779\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8814 - mae: 2.3207 - mse: 11.7679 - R2: 0.9914\n",
            "Epoch 135: val_loss did not improve from 2.82214\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 1.8814 - mae: 2.3207 - mse: 11.7679 - R2: 0.9914 - val_loss: 8.3199 - val_mae: 8.7957 - val_mse: 122.2974 - val_R2: 0.9040\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4655 - mae: 2.9191 - mse: 18.3984 - R2: 0.9865\n",
            "Epoch 136: val_loss did not improve from 2.82214\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.4655 - mae: 2.9191 - mse: 18.3984 - R2: 0.9865 - val_loss: 6.0658 - val_mae: 6.5541 - val_mse: 60.8075 - val_R2: 0.9523\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7038 - mae: 2.1492 - mse: 8.4507 - R2: 0.9938\n",
            "Epoch 137: val_loss improved from 2.82214 to 2.81379, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 467ms/step - loss: 1.7038 - mae: 2.1492 - mse: 8.4507 - R2: 0.9938 - val_loss: 2.8138 - val_mae: 3.2750 - val_mse: 20.6564 - val_R2: 0.9838\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8418 - mae: 2.2861 - mse: 9.9464 - R2: 0.9927 \n",
            "Epoch 138: val_loss did not improve from 2.81379\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.8418 - mae: 2.2861 - mse: 9.9464 - R2: 0.9927 - val_loss: 3.1699 - val_mae: 3.6345 - val_mse: 25.7437 - val_R2: 0.9798\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2086 - mae: 2.6506 - mse: 13.9399 - R2: 0.9898\n",
            "Epoch 139: val_loss did not improve from 2.81379\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.2086 - mae: 2.6506 - mse: 13.9399 - R2: 0.9898 - val_loss: 7.4260 - val_mae: 7.9080 - val_mse: 90.6341 - val_R2: 0.9289\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8402 - mae: 2.2823 - mse: 10.0351 - R2: 0.9926\n",
            "Epoch 140: val_loss did not improve from 2.81379\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.8402 - mae: 2.2823 - mse: 10.0351 - R2: 0.9926 - val_loss: 4.6291 - val_mae: 5.1098 - val_mse: 38.0157 - val_R2: 0.9702\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7844 - mae: 2.2197 - mse: 8.9210 - R2: 0.9935\n",
            "Epoch 141: val_loss improved from 2.81379 to 2.65816, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 469ms/step - loss: 1.7844 - mae: 2.2197 - mse: 8.9210 - R2: 0.9935 - val_loss: 2.6582 - val_mae: 3.1180 - val_mse: 19.0599 - val_R2: 0.9850\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1036 - mae: 1.5221 - mse: 4.1843 - R2: 0.9969\n",
            "Epoch 142: val_loss did not improve from 2.65816\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.1036 - mae: 1.5221 - mse: 4.1843 - R2: 0.9969 - val_loss: 2.9656 - val_mae: 3.4387 - val_mse: 23.1816 - val_R2: 0.9818\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6902 - mae: 2.1241 - mse: 8.7814 - R2: 0.9936\n",
            "Epoch 143: val_loss improved from 2.65816 to 2.55420, saving model to saved_models/ResNet_0deg_withTL/resnet_1.h5\n",
            "13/13 [==============================] - 6s 472ms/step - loss: 1.6902 - mae: 2.1241 - mse: 8.7814 - R2: 0.9936 - val_loss: 2.5542 - val_mae: 3.0161 - val_mse: 17.2145 - val_R2: 0.9865\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5602 - mae: 1.9817 - mse: 8.6200 - R2: 0.9937\n",
            "Epoch 144: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 1.5602 - mae: 1.9817 - mse: 8.6200 - R2: 0.9937 - val_loss: 4.3315 - val_mae: 4.8071 - val_mse: 38.4857 - val_R2: 0.9698\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2248 - mae: 1.6428 - mse: 5.5473 - R2: 0.9959\n",
            "Epoch 145: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 1.2248 - mae: 1.6428 - mse: 5.5473 - R2: 0.9959 - val_loss: 4.6812 - val_mae: 5.1624 - val_mse: 40.1040 - val_R2: 0.9685\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5934 - mae: 2.0407 - mse: 6.9216 - R2: 0.9949\n",
            "Epoch 146: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.5934 - mae: 2.0407 - mse: 6.9216 - R2: 0.9949 - val_loss: 3.9203 - val_mae: 4.3902 - val_mse: 33.4040 - val_R2: 0.9738\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4614 - mae: 1.8836 - mse: 6.8208 - R2: 0.9950\n",
            "Epoch 147: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.4614 - mae: 1.8836 - mse: 6.8208 - R2: 0.9950 - val_loss: 8.6217 - val_mae: 9.1052 - val_mse: 116.4543 - val_R2: 0.9086\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4811 - mae: 1.9172 - mse: 6.4937 - R2: 0.9952\n",
            "Epoch 148: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.4811 - mae: 1.9172 - mse: 6.4937 - R2: 0.9952 - val_loss: 5.0459 - val_mae: 5.5297 - val_mse: 43.8518 - val_R2: 0.9656\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6331 - mae: 2.0664 - mse: 7.6133 - R2: 0.9944\n",
            "Epoch 149: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.6331 - mae: 2.0664 - mse: 7.6133 - R2: 0.9944 - val_loss: 7.0741 - val_mae: 7.5575 - val_mse: 73.5208 - val_R2: 0.9423\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7989 - mae: 2.2422 - mse: 9.5941 - R2: 0.9930\n",
            "Epoch 150: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.7989 - mae: 2.2422 - mse: 9.5941 - R2: 0.9930 - val_loss: 4.7980 - val_mae: 5.2698 - val_mse: 55.6096 - val_R2: 0.9564\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6816 - mae: 2.1115 - mse: 8.6035 - R2: 0.9937\n",
            "Epoch 151: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.6816 - mae: 2.1115 - mse: 8.6035 - R2: 0.9937 - val_loss: 7.1939 - val_mae: 7.6775 - val_mse: 99.2034 - val_R2: 0.9221\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9712 - mae: 2.4039 - mse: 12.1262 - R2: 0.9911\n",
            "Epoch 152: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.9712 - mae: 2.4039 - mse: 12.1262 - R2: 0.9911 - val_loss: 4.6230 - val_mae: 5.0898 - val_mse: 49.5899 - val_R2: 0.9611\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7639 - mae: 2.2049 - mse: 8.8582 - R2: 0.9935\n",
            "Epoch 153: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.7639 - mae: 2.2049 - mse: 8.8582 - R2: 0.9935 - val_loss: 5.6761 - val_mae: 6.1686 - val_mse: 52.0324 - val_R2: 0.9592\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8398 - mae: 2.2777 - mse: 9.4872 - R2: 0.9930\n",
            "Epoch 154: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 1.8398 - mae: 2.2777 - mse: 9.4872 - R2: 0.9930 - val_loss: 4.3931 - val_mae: 4.8686 - val_mse: 49.4406 - val_R2: 0.9612\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6053 - mae: 2.0418 - mse: 7.9912 - R2: 0.9941\n",
            "Epoch 155: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.6053 - mae: 2.0418 - mse: 7.9912 - R2: 0.9941 - val_loss: 3.6956 - val_mae: 4.1639 - val_mse: 35.2660 - val_R2: 0.9723\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7854 - mae: 2.2230 - mse: 9.6147 - R2: 0.9929 \n",
            "Epoch 156: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 397ms/step - loss: 1.7854 - mae: 2.2230 - mse: 9.6147 - R2: 0.9929 - val_loss: 5.0888 - val_mae: 5.5757 - val_mse: 54.3848 - val_R2: 0.9573\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1546 - mae: 2.5995 - mse: 12.7189 - R2: 0.9907\n",
            "Epoch 157: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.1546 - mae: 2.5995 - mse: 12.7189 - R2: 0.9907 - val_loss: 12.3529 - val_mae: 12.8431 - val_mse: 211.6863 - val_R2: 0.8339\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2502 - mae: 1.6746 - mse: 5.3603 - R2: 0.9961\n",
            "Epoch 158: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.2502 - mae: 1.6746 - mse: 5.3603 - R2: 0.9961 - val_loss: 8.8063 - val_mae: 9.3024 - val_mse: 111.8265 - val_R2: 0.9122\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6165 - mae: 2.0312 - mse: 9.0050 - R2: 0.9934\n",
            "Epoch 159: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.6165 - mae: 2.0312 - mse: 9.0050 - R2: 0.9934 - val_loss: 14.7277 - val_mae: 15.2209 - val_mse: 322.5140 - val_R2: 0.7469\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4550 - mae: 1.8797 - mse: 6.6246 - R2: 0.9951\n",
            "Epoch 160: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 1.4550 - mae: 1.8797 - mse: 6.6246 - R2: 0.9951 - val_loss: 23.1807 - val_mae: 23.6791 - val_mse: 716.7833 - val_R2: 0.4375\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8816 - mae: 2.3148 - mse: 11.1361 - R2: 0.9918\n",
            "Epoch 161: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.8816 - mae: 2.3148 - mse: 11.1361 - R2: 0.9918 - val_loss: 14.3677 - val_mae: 14.8573 - val_mse: 276.9826 - val_R2: 0.7826\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7465 - mae: 2.1875 - mse: 10.7524 - R2: 0.9921\n",
            "Epoch 162: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 396ms/step - loss: 1.7465 - mae: 2.1875 - mse: 10.7524 - R2: 0.9921 - val_loss: 4.3487 - val_mae: 4.8384 - val_mse: 42.6783 - val_R2: 0.9665\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6380 - mae: 2.0714 - mse: 7.9224 - R2: 0.9942\n",
            "Epoch 163: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.6380 - mae: 2.0714 - mse: 7.9224 - R2: 0.9942 - val_loss: 3.9023 - val_mae: 4.3786 - val_mse: 29.2690 - val_R2: 0.9770\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6964 - mae: 2.1420 - mse: 8.4934 - R2: 0.9938\n",
            "Epoch 164: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 1.6964 - mae: 2.1420 - mse: 8.4934 - R2: 0.9938 - val_loss: 2.9782 - val_mae: 3.4522 - val_mse: 19.5090 - val_R2: 0.9847\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4676 - mae: 2.9145 - mse: 15.7295 - R2: 0.9885\n",
            "Epoch 165: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.4676 - mae: 2.9145 - mse: 15.7295 - R2: 0.9885 - val_loss: 4.3081 - val_mae: 4.7884 - val_mse: 32.8846 - val_R2: 0.9742\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3350 - mae: 1.7560 - mse: 6.5913 - R2: 0.9952\n",
            "Epoch 166: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.3350 - mae: 1.7560 - mse: 6.5913 - R2: 0.9952 - val_loss: 7.6428 - val_mae: 8.1296 - val_mse: 100.0733 - val_R2: 0.9215\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8243 - mae: 2.2518 - mse: 10.7354 - R2: 0.9921\n",
            "Epoch 167: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 399ms/step - loss: 1.8243 - mae: 2.2518 - mse: 10.7354 - R2: 0.9921 - val_loss: 5.5553 - val_mae: 6.0400 - val_mse: 51.3643 - val_R2: 0.9597\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3793 - mae: 1.8035 - mse: 6.0386 - R2: 0.9956\n",
            "Epoch 168: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.3793 - mae: 1.8035 - mse: 6.0386 - R2: 0.9956 - val_loss: 5.8313 - val_mae: 6.3224 - val_mse: 53.2924 - val_R2: 0.9582\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5338 - mae: 1.9618 - mse: 7.7912 - R2: 0.9943\n",
            "Epoch 169: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.5338 - mae: 1.9618 - mse: 7.7912 - R2: 0.9943 - val_loss: 2.9486 - val_mae: 3.4287 - val_mse: 20.8560 - val_R2: 0.9836\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6572 - mae: 2.0794 - mse: 8.8100 - R2: 0.9935\n",
            "Epoch 170: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.6572 - mae: 2.0794 - mse: 8.8100 - R2: 0.9935 - val_loss: 6.9896 - val_mae: 7.4734 - val_mse: 76.4750 - val_R2: 0.9400\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2340 - mae: 1.6548 - mse: 4.7984 - R2: 0.9965\n",
            "Epoch 171: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.2340 - mae: 1.6548 - mse: 4.7984 - R2: 0.9965 - val_loss: 4.4014 - val_mae: 4.8874 - val_mse: 36.5802 - val_R2: 0.9713\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5060 - mae: 1.9526 - mse: 6.7488 - R2: 0.9950\n",
            "Epoch 172: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.5060 - mae: 1.9526 - mse: 6.7488 - R2: 0.9950 - val_loss: 3.1695 - val_mae: 3.6561 - val_mse: 20.7711 - val_R2: 0.9837\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3352 - mae: 1.7599 - mse: 5.7780 - R2: 0.9958\n",
            "Epoch 173: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.3352 - mae: 1.7599 - mse: 5.7780 - R2: 0.9958 - val_loss: 11.2325 - val_mae: 11.7228 - val_mse: 174.1783 - val_R2: 0.8633\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4767 - mae: 1.9049 - mse: 6.6482 - R2: 0.9951\n",
            "Epoch 174: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.4767 - mae: 1.9049 - mse: 6.6482 - R2: 0.9951 - val_loss: 4.2867 - val_mae: 4.7644 - val_mse: 39.4984 - val_R2: 0.9690\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9008 - mae: 2.3534 - mse: 9.6929 - R2: 0.9929\n",
            "Epoch 175: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.9008 - mae: 2.3534 - mse: 9.6929 - R2: 0.9929 - val_loss: 4.9906 - val_mae: 5.4639 - val_mse: 51.0810 - val_R2: 0.9599\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4048 - mae: 1.8414 - mse: 6.4018 - R2: 0.9953\n",
            "Epoch 176: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.4048 - mae: 1.8414 - mse: 6.4018 - R2: 0.9953 - val_loss: 7.5572 - val_mae: 8.0483 - val_mse: 86.5953 - val_R2: 0.9320\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3101 - mae: 1.7338 - mse: 5.4185 - R2: 0.9960\n",
            "Epoch 177: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.3101 - mae: 1.7338 - mse: 5.4185 - R2: 0.9960 - val_loss: 4.6498 - val_mae: 5.1364 - val_mse: 41.4273 - val_R2: 0.9675\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4285 - mae: 1.8515 - mse: 6.6267 - R2: 0.9951\n",
            "Epoch 178: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.4285 - mae: 1.8515 - mse: 6.6267 - R2: 0.9951 - val_loss: 5.0721 - val_mae: 5.5570 - val_mse: 50.1650 - val_R2: 0.9606\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0471 - mae: 1.4568 - mse: 4.5864 - R2: 0.9966\n",
            "Epoch 179: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.0471 - mae: 1.4568 - mse: 4.5864 - R2: 0.9966 - val_loss: 3.4455 - val_mae: 3.9215 - val_mse: 28.9169 - val_R2: 0.9773\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1761 - mae: 1.5922 - mse: 4.5671 - R2: 0.9966\n",
            "Epoch 180: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.1761 - mae: 1.5922 - mse: 4.5671 - R2: 0.9966 - val_loss: 4.2085 - val_mae: 4.6780 - val_mse: 37.8306 - val_R2: 0.9703\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1694 - mae: 1.5924 - mse: 4.8843 - R2: 0.9964\n",
            "Epoch 181: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.1694 - mae: 1.5924 - mse: 4.8843 - R2: 0.9964 - val_loss: 5.3018 - val_mae: 5.7764 - val_mse: 54.1755 - val_R2: 0.9575\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1954 - mae: 1.6097 - mse: 5.1268 - R2: 0.9962\n",
            "Epoch 182: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.1954 - mae: 1.6097 - mse: 5.1268 - R2: 0.9962 - val_loss: 3.9946 - val_mae: 4.4768 - val_mse: 36.3180 - val_R2: 0.9715\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7210 - mae: 2.1696 - mse: 8.6443 - R2: 0.9937\n",
            "Epoch 183: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 399ms/step - loss: 1.7210 - mae: 2.1696 - mse: 8.6443 - R2: 0.9937 - val_loss: 11.3481 - val_mae: 11.8342 - val_mse: 198.2495 - val_R2: 0.8444\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3037 - mae: 1.7252 - mse: 5.5309 - R2: 0.9959\n",
            "Epoch 184: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.3037 - mae: 1.7252 - mse: 5.5309 - R2: 0.9959 - val_loss: 3.4819 - val_mae: 3.9565 - val_mse: 30.9243 - val_R2: 0.9757\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3499 - mae: 1.7521 - mse: 7.3812 - R2: 0.9946\n",
            "Epoch 185: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.3499 - mae: 1.7521 - mse: 7.3812 - R2: 0.9946 - val_loss: 11.4089 - val_mae: 11.8981 - val_mse: 182.1090 - val_R2: 0.8571\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4335 - mae: 1.8634 - mse: 6.4112 - R2: 0.9953\n",
            "Epoch 186: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.4335 - mae: 1.8634 - mse: 6.4112 - R2: 0.9953 - val_loss: 2.9696 - val_mae: 3.4260 - val_mse: 22.7912 - val_R2: 0.9821\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5148 - mae: 1.9439 - mse: 7.7355 - R2: 0.9943\n",
            "Epoch 187: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.5148 - mae: 1.9439 - mse: 7.7355 - R2: 0.9943 - val_loss: 8.2612 - val_mae: 8.7482 - val_mse: 131.7431 - val_R2: 0.8966\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2905 - mae: 1.7174 - mse: 5.4763 - R2: 0.9960\n",
            "Epoch 188: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.2905 - mae: 1.7174 - mse: 5.4763 - R2: 0.9960 - val_loss: 10.4691 - val_mae: 10.9495 - val_mse: 173.8453 - val_R2: 0.8636\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5643 - mae: 1.9985 - mse: 7.7516 - R2: 0.9943\n",
            "Epoch 189: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.5643 - mae: 1.9985 - mse: 7.7516 - R2: 0.9943 - val_loss: 5.5081 - val_mae: 5.9801 - val_mse: 69.7170 - val_R2: 0.9453\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7516 - mae: 2.1800 - mse: 9.0338 - R2: 0.9934\n",
            "Epoch 190: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.7516 - mae: 2.1800 - mse: 9.0338 - R2: 0.9934 - val_loss: 5.8707 - val_mae: 6.3538 - val_mse: 71.5440 - val_R2: 0.9439\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5594 - mae: 1.9879 - mse: 7.5893 - R2: 0.9944\n",
            "Epoch 191: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 398ms/step - loss: 1.5594 - mae: 1.9879 - mse: 7.5893 - R2: 0.9944 - val_loss: 9.4221 - val_mae: 9.9190 - val_mse: 162.4981 - val_R2: 0.8725\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3641 - mae: 1.7804 - mse: 6.2945 - R2: 0.9954\n",
            "Epoch 192: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.3641 - mae: 1.7804 - mse: 6.2945 - R2: 0.9954 - val_loss: 5.0411 - val_mae: 5.5166 - val_mse: 62.2395 - val_R2: 0.9512\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2682 - mae: 1.6779 - mse: 5.9101 - R2: 0.9957\n",
            "Epoch 193: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.2682 - mae: 1.6779 - mse: 5.9101 - R2: 0.9957 - val_loss: 8.1745 - val_mae: 8.6656 - val_mse: 135.9049 - val_R2: 0.8933\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6914 - mae: 2.1171 - mse: 10.0225 - R2: 0.9926\n",
            "Epoch 194: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.6914 - mae: 2.1171 - mse: 10.0225 - R2: 0.9926 - val_loss: 5.8910 - val_mae: 6.3785 - val_mse: 70.8714 - val_R2: 0.9444\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3222 - mae: 1.7412 - mse: 5.8589 - R2: 0.9957\n",
            "Epoch 195: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 1.3222 - mae: 1.7412 - mse: 5.8589 - R2: 0.9957 - val_loss: 13.3939 - val_mae: 13.8835 - val_mse: 281.4283 - val_R2: 0.7791\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6072 - mae: 2.0344 - mse: 7.9398 - R2: 0.9942\n",
            "Epoch 196: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 401ms/step - loss: 1.6072 - mae: 2.0344 - mse: 7.9398 - R2: 0.9942 - val_loss: 5.7919 - val_mae: 6.2863 - val_mse: 64.5093 - val_R2: 0.9494\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5462 - mae: 1.9902 - mse: 7.1367 - R2: 0.9948\n",
            "Epoch 197: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.5462 - mae: 1.9902 - mse: 7.1367 - R2: 0.9948 - val_loss: 6.1521 - val_mae: 6.6381 - val_mse: 58.4337 - val_R2: 0.9541\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3533 - mae: 1.7799 - mse: 6.3254 - R2: 0.9954\n",
            "Epoch 198: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.3533 - mae: 1.7799 - mse: 6.3254 - R2: 0.9954 - val_loss: 7.2351 - val_mae: 7.7176 - val_mse: 99.4605 - val_R2: 0.9219\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7009 - mae: 2.1295 - mse: 9.2891 - R2: 0.9932\n",
            "Epoch 199: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.7009 - mae: 2.1295 - mse: 9.2891 - R2: 0.9932 - val_loss: 5.3114 - val_mae: 5.7996 - val_mse: 46.5536 - val_R2: 0.9635\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5152 - mae: 1.9485 - mse: 7.1427 - R2: 0.9948\n",
            "Epoch 200: val_loss did not improve from 2.55420\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.5152 - mae: 1.9485 - mse: 7.1427 - R2: 0.9948 - val_loss: 4.4206 - val_mae: 4.8848 - val_mse: 41.4179 - val_R2: 0.9675\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 2.2724 - mae: 2.7099 - mse: 15.4257 - R2: 0.9879\n",
            "Found 389 validated image filenames.\n",
            "Found 97 validated image filenames.\n",
            "Epoch 1/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 34.7148 - mae: 35.2121 - mse: 2067.7595 - R2: -0.5323\n",
            "Epoch 1: val_loss improved from inf to 33.38990, saving model to saved_models/ResNet_0deg_withTL/resnet_2.h5\n",
            "13/13 [==============================] - 25s 690ms/step - loss: 34.7148 - mae: 35.2121 - mse: 2067.7595 - R2: -0.5323 - val_loss: 33.3899 - val_mae: 33.8894 - val_mse: 1486.3910 - val_R2: -0.1200\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 15.7436 - mae: 16.2374 - mse: 508.9739 - R2: 0.6228\n",
            "Epoch 2: val_loss did not improve from 33.38990\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 15.7436 - mae: 16.2374 - mse: 508.9739 - R2: 0.6228 - val_loss: 179.3564 - val_mae: 179.8564 - val_mse: 37723.7617 - val_R2: -27.4247\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 12.1583 - mae: 12.6450 - mse: 302.5307 - R2: 0.7758\n",
            "Epoch 3: val_loss did not improve from 33.38990\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 12.1583 - mae: 12.6450 - mse: 302.5307 - R2: 0.7758 - val_loss: 38.3549 - val_mae: 38.8502 - val_mse: 4106.2646 - val_R2: -2.0941\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 11.6457 - mae: 12.1380 - mse: 247.7183 - R2: 0.8164\n",
            "Epoch 4: val_loss did not improve from 33.38990\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 11.6457 - mae: 12.1380 - mse: 247.7183 - R2: 0.8164 - val_loss: 121.7601 - val_mae: 122.2601 - val_mse: 17108.9180 - val_R2: -11.8915\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 9.7367 - mae: 10.2260 - mse: 186.4385 - R2: 0.8618\n",
            "Epoch 5: val_loss improved from 33.38990 to 24.11376, saving model to saved_models/ResNet_0deg_withTL/resnet_2.h5\n",
            "13/13 [==============================] - 6s 479ms/step - loss: 9.7367 - mae: 10.2260 - mse: 186.4385 - R2: 0.8618 - val_loss: 24.1138 - val_mae: 24.6097 - val_mse: 1390.8851 - val_R2: -0.0480\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.7309 - mae: 8.2165 - mse: 122.2782 - R2: 0.9094\n",
            "Epoch 6: val_loss did not improve from 24.11376\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 7.7309 - mae: 8.2165 - mse: 122.2782 - R2: 0.9094 - val_loss: 600.2095 - val_mae: 600.7095 - val_mse: 399857.5000 - val_R2: -300.2907\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.4147 - mae: 7.9010 - mse: 111.7477 - R2: 0.9172\n",
            "Epoch 7: val_loss did not improve from 24.11376\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 7.4147 - mae: 7.9010 - mse: 111.7477 - R2: 0.9172 - val_loss: 118.8620 - val_mae: 119.3620 - val_mse: 18025.1816 - val_R2: -12.5819\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.1795 - mae: 6.6571 - mse: 80.9963 - R2: 0.9400\n",
            "Epoch 8: val_loss did not improve from 24.11376\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 6.1795 - mae: 6.6571 - mse: 80.9963 - R2: 0.9400 - val_loss: 89.5490 - val_mae: 90.0419 - val_mse: 9782.2998 - val_R2: -6.3709\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.6118 - mae: 7.0933 - mse: 88.5847 - R2: 0.9344\n",
            "Epoch 9: val_loss did not improve from 24.11376\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 6.6118 - mae: 7.0933 - mse: 88.5847 - R2: 0.9344 - val_loss: 52.9495 - val_mae: 53.4493 - val_mse: 3373.7056 - val_R2: -1.5421\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.9867 - mae: 7.4695 - mse: 97.7180 - R2: 0.9276 \n",
            "Epoch 10: val_loss improved from 24.11376 to 9.11532, saving model to saved_models/ResNet_0deg_withTL/resnet_2.h5\n",
            "13/13 [==============================] - 6s 477ms/step - loss: 6.9867 - mae: 7.4695 - mse: 97.7180 - R2: 0.9276 - val_loss: 9.1153 - val_mae: 9.6110 - val_mse: 152.6309 - val_R2: 0.8850\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.7028 - mae: 6.1828 - mse: 69.9437 - R2: 0.9482\n",
            "Epoch 11: val_loss did not improve from 9.11532\n",
            "13/13 [==============================] - 5s 372ms/step - loss: 5.7028 - mae: 6.1828 - mse: 69.9437 - R2: 0.9482 - val_loss: 16.6959 - val_mae: 17.1906 - val_mse: 459.8465 - val_R2: 0.6535\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.6112 - mae: 6.0917 - mse: 72.0167 - R2: 0.9466\n",
            "Epoch 12: val_loss did not improve from 9.11532\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 5.6112 - mae: 6.0917 - mse: 72.0167 - R2: 0.9466 - val_loss: 28.2923 - val_mae: 28.7868 - val_mse: 1173.0730 - val_R2: 0.1161\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.9130 - mae: 5.3948 - mse: 57.8274 - R2: 0.9571\n",
            "Epoch 13: val_loss did not improve from 9.11532\n",
            "13/13 [==============================] - 5s 373ms/step - loss: 4.9130 - mae: 5.3948 - mse: 57.8274 - R2: 0.9571 - val_loss: 21.6733 - val_mae: 22.1630 - val_mse: 879.7283 - val_R2: 0.3371\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.4325 - mae: 5.9057 - mse: 64.6132 - R2: 0.9521\n",
            "Epoch 14: val_loss did not improve from 9.11532\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 5.4325 - mae: 5.9057 - mse: 64.6132 - R2: 0.9521 - val_loss: 27.3327 - val_mae: 27.8281 - val_mse: 910.8669 - val_R2: 0.3137\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.0110 - mae: 6.4950 - mse: 69.7517 - R2: 0.9483\n",
            "Epoch 15: val_loss did not improve from 9.11532\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 6.0110 - mae: 6.4950 - mse: 69.7517 - R2: 0.9483 - val_loss: 16.5804 - val_mae: 17.0674 - val_mse: 443.7546 - val_R2: 0.6656\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.7376 - mae: 7.2180 - mse: 100.6177 - R2: 0.9254\n",
            "Epoch 16: val_loss improved from 9.11532 to 4.26538, saving model to saved_models/ResNet_0deg_withTL/resnet_2.h5\n",
            "13/13 [==============================] - 6s 470ms/step - loss: 6.7376 - mae: 7.2180 - mse: 100.6177 - R2: 0.9254 - val_loss: 4.2654 - val_mae: 4.7442 - val_mse: 37.5594 - val_R2: 0.9717\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.4162 - mae: 5.8988 - mse: 66.0369 - R2: 0.9511\n",
            "Epoch 17: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 5.4162 - mae: 5.8988 - mse: 66.0369 - R2: 0.9511 - val_loss: 14.2763 - val_mae: 14.7637 - val_mse: 301.1047 - val_R2: 0.7731\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.7806 - mae: 6.2632 - mse: 65.9655 - R2: 0.9511\n",
            "Epoch 18: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 5.7806 - mae: 6.2632 - mse: 65.9655 - R2: 0.9511 - val_loss: 6.3698 - val_mae: 6.8505 - val_mse: 80.7951 - val_R2: 0.9391\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.3247 - mae: 5.8001 - mse: 55.9665 - R2: 0.9585\n",
            "Epoch 19: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 5.3247 - mae: 5.8001 - mse: 55.9665 - R2: 0.9585 - val_loss: 8.0914 - val_mae: 8.5767 - val_mse: 144.7820 - val_R2: 0.8909\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.5722 - mae: 6.0549 - mse: 67.2845 - R2: 0.9501\n",
            "Epoch 20: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 5.5722 - mae: 6.0549 - mse: 67.2845 - R2: 0.9501 - val_loss: 5.0689 - val_mae: 5.5392 - val_mse: 57.9798 - val_R2: 0.9563\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9928 - mae: 4.4624 - mse: 36.1863 - R2: 0.9732\n",
            "Epoch 21: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 3.9928 - mae: 4.4624 - mse: 36.1863 - R2: 0.9732 - val_loss: 11.2018 - val_mae: 11.6870 - val_mse: 254.3620 - val_R2: 0.8083\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.7913 - mae: 5.2552 - mse: 51.9918 - R2: 0.9615\n",
            "Epoch 22: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 401ms/step - loss: 4.7913 - mae: 5.2552 - mse: 51.9918 - R2: 0.9615 - val_loss: 25.6107 - val_mae: 26.0986 - val_mse: 1262.3860 - val_R2: 0.0488\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2812 - mae: 4.7516 - mse: 38.5832 - R2: 0.9714\n",
            "Epoch 23: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 4.2812 - mae: 4.7516 - mse: 38.5832 - R2: 0.9714 - val_loss: 20.7995 - val_mae: 21.2889 - val_mse: 666.1714 - val_R2: 0.4980\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2120 - mae: 4.6886 - mse: 40.1737 - R2: 0.9702\n",
            "Epoch 24: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 4.2120 - mae: 4.6886 - mse: 40.1737 - R2: 0.9702 - val_loss: 8.5296 - val_mae: 9.0011 - val_mse: 170.9354 - val_R2: 0.8712\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.5269 - mae: 6.0017 - mse: 68.9824 - R2: 0.9489\n",
            "Epoch 25: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 5.5269 - mae: 6.0017 - mse: 68.9824 - R2: 0.9489 - val_loss: 11.7014 - val_mae: 12.1973 - val_mse: 177.3017 - val_R2: 0.8664\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.3339 - mae: 4.7983 - mse: 45.2908 - R2: 0.9664\n",
            "Epoch 26: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 4.3339 - mae: 4.7983 - mse: 45.2908 - R2: 0.9664 - val_loss: 8.6166 - val_mae: 9.1025 - val_mse: 137.1694 - val_R2: 0.8966\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.4164 - mae: 5.8941 - mse: 68.9686 - R2: 0.9489\n",
            "Epoch 27: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 5.4164 - mae: 5.8941 - mse: 68.9686 - R2: 0.9489 - val_loss: 5.0627 - val_mae: 5.5448 - val_mse: 50.1872 - val_R2: 0.9622\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.3425 - mae: 5.8156 - mse: 56.6476 - R2: 0.9580\n",
            "Epoch 28: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 5.3425 - mae: 5.8156 - mse: 56.6476 - R2: 0.9580 - val_loss: 4.4046 - val_mae: 4.8901 - val_mse: 34.4891 - val_R2: 0.9740\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.1069 - mae: 6.5778 - mse: 102.1188 - R2: 0.9243\n",
            "Epoch 29: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 6.1069 - mae: 6.5778 - mse: 102.1188 - R2: 0.9243 - val_loss: 26.9083 - val_mae: 27.4082 - val_mse: 938.6202 - val_R2: 0.2928\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.1754 - mae: 4.6517 - mse: 39.3553 - R2: 0.9708\n",
            "Epoch 30: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 4.1754 - mae: 4.6517 - mse: 39.3553 - R2: 0.9708 - val_loss: 4.9452 - val_mae: 5.4253 - val_mse: 43.3891 - val_R2: 0.9673\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.4747 - mae: 4.9564 - mse: 41.4368 - R2: 0.9693\n",
            "Epoch 31: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 4.4747 - mae: 4.9564 - mse: 41.4368 - R2: 0.9693 - val_loss: 20.7036 - val_mae: 21.2036 - val_mse: 603.7956 - val_R2: 0.5450\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.4935 - mae: 4.9704 - mse: 44.7553 - R2: 0.9668\n",
            "Epoch 32: val_loss did not improve from 4.26538\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 4.4935 - mae: 4.9704 - mse: 44.7553 - R2: 0.9668 - val_loss: 9.6101 - val_mae: 10.1005 - val_mse: 134.9878 - val_R2: 0.8983\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1752 - mae: 3.6325 - mse: 28.0991 - R2: 0.9792\n",
            "Epoch 33: val_loss improved from 4.26538 to 4.01417, saving model to saved_models/ResNet_0deg_withTL/resnet_2.h5\n",
            "13/13 [==============================] - 6s 473ms/step - loss: 3.1752 - mae: 3.6325 - mse: 28.0991 - R2: 0.9792 - val_loss: 4.0142 - val_mae: 4.4895 - val_mse: 34.4833 - val_R2: 0.9740\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6485 - mae: 4.1077 - mse: 33.6322 - R2: 0.9751\n",
            "Epoch 34: val_loss did not improve from 4.01417\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 3.6485 - mae: 4.1077 - mse: 33.6322 - R2: 0.9751 - val_loss: 9.4343 - val_mae: 9.9257 - val_mse: 147.4141 - val_R2: 0.8889\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.3342 - mae: 5.8100 - mse: 63.9199 - R2: 0.9526\n",
            "Epoch 35: val_loss did not improve from 4.01417\n",
            "13/13 [==============================] - 5s 399ms/step - loss: 5.3342 - mae: 5.8100 - mse: 63.9199 - R2: 0.9526 - val_loss: 19.3773 - val_mae: 19.8698 - val_mse: 733.5745 - val_R2: 0.4473\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.0167 - mae: 5.4989 - mse: 50.0719 - R2: 0.9629\n",
            "Epoch 36: val_loss did not improve from 4.01417\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 5.0167 - mae: 5.4989 - mse: 50.0719 - R2: 0.9629 - val_loss: 14.4087 - val_mae: 14.9000 - val_mse: 375.0073 - val_R2: 0.7174\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0078 - mae: 4.4757 - mse: 40.5097 - R2: 0.9700\n",
            "Epoch 37: val_loss improved from 4.01417 to 3.43329, saving model to saved_models/ResNet_0deg_withTL/resnet_2.h5\n",
            "13/13 [==============================] - 6s 474ms/step - loss: 4.0078 - mae: 4.4757 - mse: 40.5097 - R2: 0.9700 - val_loss: 3.4333 - val_mae: 3.9078 - val_mse: 24.4702 - val_R2: 0.9816\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.6330 - mae: 5.1026 - mse: 46.6984 - R2: 0.9654\n",
            "Epoch 38: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 4.6330 - mae: 5.1026 - mse: 46.6984 - R2: 0.9654 - val_loss: 9.9748 - val_mae: 10.4585 - val_mse: 206.6065 - val_R2: 0.8443\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.3665 - mae: 4.8462 - mse: 44.8610 - R2: 0.9668\n",
            "Epoch 39: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 4.3665 - mae: 4.8462 - mse: 44.8610 - R2: 0.9668 - val_loss: 40.1278 - val_mae: 40.6223 - val_mse: 1912.5510 - val_R2: -0.4411\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.2446 - mae: 5.7177 - mse: 54.3524 - R2: 0.9597\n",
            "Epoch 40: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 5.2446 - mae: 5.7177 - mse: 54.3524 - R2: 0.9597 - val_loss: 27.7633 - val_mae: 28.2594 - val_mse: 936.9083 - val_R2: 0.2940\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3902 - mae: 3.8585 - mse: 27.2068 - R2: 0.9798\n",
            "Epoch 41: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 3.3902 - mae: 3.8585 - mse: 27.2068 - R2: 0.9798 - val_loss: 4.7148 - val_mae: 5.1914 - val_mse: 40.2706 - val_R2: 0.9697\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0968 - mae: 3.5540 - mse: 22.2584 - R2: 0.9835\n",
            "Epoch 42: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 3.0968 - mae: 3.5540 - mse: 22.2584 - R2: 0.9835 - val_loss: 7.1449 - val_mae: 7.6199 - val_mse: 118.2621 - val_R2: 0.9109\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0868 - mae: 4.5475 - mse: 45.6979 - R2: 0.9661\n",
            "Epoch 43: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 4.0868 - mae: 4.5475 - mse: 45.6979 - R2: 0.9661 - val_loss: 3.4867 - val_mae: 3.9467 - val_mse: 28.9408 - val_R2: 0.9782\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.3833 - mae: 4.8538 - mse: 42.3318 - R2: 0.9686\n",
            "Epoch 44: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 4.3833 - mae: 4.8538 - mse: 42.3318 - R2: 0.9686 - val_loss: 12.4712 - val_mae: 12.9580 - val_mse: 284.6135 - val_R2: 0.7855\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.4144 - mae: 4.8891 - mse: 42.0059 - R2: 0.9689\n",
            "Epoch 45: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 4.4144 - mae: 4.8891 - mse: 42.0059 - R2: 0.9689 - val_loss: 19.3077 - val_mae: 19.7894 - val_mse: 581.4402 - val_R2: 0.5619\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7967 - mae: 4.2675 - mse: 32.0655 - R2: 0.9762\n",
            "Epoch 46: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 3.7967 - mae: 4.2675 - mse: 32.0655 - R2: 0.9762 - val_loss: 9.7722 - val_mae: 10.2538 - val_mse: 168.8704 - val_R2: 0.8728\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.5006 - mae: 4.9785 - mse: 45.4245 - R2: 0.9663\n",
            "Epoch 47: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 4.5006 - mae: 4.9785 - mse: 45.4245 - R2: 0.9663 - val_loss: 7.0104 - val_mae: 7.4842 - val_mse: 87.1367 - val_R2: 0.9343\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.5577 - mae: 4.0153 - mse: 30.4893 - R2: 0.9774\n",
            "Epoch 48: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 397ms/step - loss: 3.5577 - mae: 4.0153 - mse: 30.4893 - R2: 0.9774 - val_loss: 8.0456 - val_mae: 8.5183 - val_mse: 121.4651 - val_R2: 0.9085\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2861 - mae: 3.7455 - mse: 27.6766 - R2: 0.9795\n",
            "Epoch 49: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 399ms/step - loss: 3.2861 - mae: 3.7455 - mse: 27.6766 - R2: 0.9795 - val_loss: 12.2207 - val_mae: 12.7114 - val_mse: 236.6379 - val_R2: 0.8217\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4810 - mae: 3.9480 - mse: 33.5629 - R2: 0.9751\n",
            "Epoch 50: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 3.4810 - mae: 3.9480 - mse: 33.5629 - R2: 0.9751 - val_loss: 5.4850 - val_mae: 5.9501 - val_mse: 56.9202 - val_R2: 0.9571\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2914 - mae: 4.7561 - mse: 39.4569 - R2: 0.9708\n",
            "Epoch 51: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 401ms/step - loss: 4.2914 - mae: 4.7561 - mse: 39.4569 - R2: 0.9708 - val_loss: 3.8994 - val_mae: 4.3810 - val_mse: 33.4964 - val_R2: 0.9748\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6771 - mae: 4.1395 - mse: 33.6227 - R2: 0.9751\n",
            "Epoch 52: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 3.6771 - mae: 4.1395 - mse: 33.6227 - R2: 0.9751 - val_loss: 7.1925 - val_mae: 7.6767 - val_mse: 107.1155 - val_R2: 0.9193\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.8500 - mae: 4.3212 - mse: 35.3176 - R2: 0.9738\n",
            "Epoch 53: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 3.8500 - mae: 4.3212 - mse: 35.3176 - R2: 0.9738 - val_loss: 8.4755 - val_mae: 8.9496 - val_mse: 122.2240 - val_R2: 0.9079\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9926 - mae: 4.4711 - mse: 33.6020 - R2: 0.9751\n",
            "Epoch 54: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 406ms/step - loss: 3.9926 - mae: 4.4711 - mse: 33.6020 - R2: 0.9751 - val_loss: 15.7719 - val_mae: 16.2606 - val_mse: 398.1535 - val_R2: 0.7000\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1773 - mae: 3.6432 - mse: 23.1232 - R2: 0.9829\n",
            "Epoch 55: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 3.1773 - mae: 3.6432 - mse: 23.1232 - R2: 0.9829 - val_loss: 8.8285 - val_mae: 9.3074 - val_mse: 165.9250 - val_R2: 0.8750\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9300 - mae: 4.4006 - mse: 33.2526 - R2: 0.9754\n",
            "Epoch 56: val_loss did not improve from 3.43329\n",
            "13/13 [==============================] - 5s 399ms/step - loss: 3.9300 - mae: 4.4006 - mse: 33.2526 - R2: 0.9754 - val_loss: 16.5105 - val_mae: 17.0077 - val_mse: 403.0110 - val_R2: 0.6963\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0415 - mae: 4.5128 - mse: 37.8005 - R2: 0.9720\n",
            "Epoch 57: val_loss improved from 3.43329 to 3.18283, saving model to saved_models/ResNet_0deg_withTL/resnet_2.h5\n",
            "13/13 [==============================] - 6s 495ms/step - loss: 4.0415 - mae: 4.5128 - mse: 37.8005 - R2: 0.9720 - val_loss: 3.1828 - val_mae: 3.6452 - val_mse: 23.0937 - val_R2: 0.9826\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0284 - mae: 4.4940 - mse: 37.4525 - R2: 0.9722\n",
            "Epoch 58: val_loss did not improve from 3.18283\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 4.0284 - mae: 4.4940 - mse: 37.4525 - R2: 0.9722 - val_loss: 8.1053 - val_mae: 8.5787 - val_mse: 106.2731 - val_R2: 0.9199\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8467 - mae: 3.3136 - mse: 18.2129 - R2: 0.9865\n",
            "Epoch 59: val_loss improved from 3.18283 to 3.00795, saving model to saved_models/ResNet_0deg_withTL/resnet_2.h5\n",
            "13/13 [==============================] - 6s 474ms/step - loss: 2.8467 - mae: 3.3136 - mse: 18.2129 - R2: 0.9865 - val_loss: 3.0079 - val_mae: 3.4772 - val_mse: 19.6376 - val_R2: 0.9852\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0480 - mae: 3.5095 - mse: 22.7073 - R2: 0.9832\n",
            "Epoch 60: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 3.0480 - mae: 3.5095 - mse: 22.7073 - R2: 0.9832 - val_loss: 5.9383 - val_mae: 6.4171 - val_mse: 61.3244 - val_R2: 0.9538\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1241 - mae: 3.5787 - mse: 25.1166 - R2: 0.9814\n",
            "Epoch 61: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 3.1241 - mae: 3.5787 - mse: 25.1166 - R2: 0.9814 - val_loss: 15.9741 - val_mae: 16.4539 - val_mse: 441.8099 - val_R2: 0.6671\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2628 - mae: 3.7303 - mse: 25.6338 - R2: 0.9810\n",
            "Epoch 62: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 3.2628 - mae: 3.7303 - mse: 25.6338 - R2: 0.9810 - val_loss: 9.9014 - val_mae: 10.3842 - val_mse: 145.0798 - val_R2: 0.8907\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4653 - mae: 3.9256 - mse: 28.4435 - R2: 0.9789\n",
            "Epoch 63: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 3.4653 - mae: 3.9256 - mse: 28.4435 - R2: 0.9789 - val_loss: 11.1258 - val_mae: 11.6005 - val_mse: 202.1186 - val_R2: 0.8477\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8549 - mae: 3.3183 - mse: 21.6763 - R2: 0.9839\n",
            "Epoch 64: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.8549 - mae: 3.3183 - mse: 21.6763 - R2: 0.9839 - val_loss: 22.7691 - val_mae: 23.2652 - val_mse: 689.3397 - val_R2: 0.4806\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4186 - mae: 3.8842 - mse: 26.8662 - R2: 0.9801\n",
            "Epoch 65: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 3.4186 - mae: 3.8842 - mse: 26.8662 - R2: 0.9801 - val_loss: 8.7537 - val_mae: 9.2458 - val_mse: 113.5631 - val_R2: 0.9144\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1250 - mae: 3.5933 - mse: 22.2299 - R2: 0.9835\n",
            "Epoch 66: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 3.1250 - mae: 3.5933 - mse: 22.2299 - R2: 0.9835 - val_loss: 5.5545 - val_mae: 6.0234 - val_mse: 67.6269 - val_R2: 0.9490\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9183 - mae: 4.3920 - mse: 33.9357 - R2: 0.9749\n",
            "Epoch 67: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 3.9183 - mae: 4.3920 - mse: 33.9357 - R2: 0.9749 - val_loss: 13.4881 - val_mae: 13.9736 - val_mse: 307.1443 - val_R2: 0.7686\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2600 - mae: 3.7184 - mse: 26.2362 - R2: 0.9806\n",
            "Epoch 68: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 401ms/step - loss: 3.2600 - mae: 3.7184 - mse: 26.2362 - R2: 0.9806 - val_loss: 7.7650 - val_mae: 8.2285 - val_mse: 108.9040 - val_R2: 0.9179\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8393 - mae: 3.2972 - mse: 18.7543 - R2: 0.9861\n",
            "Epoch 69: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.8393 - mae: 3.2972 - mse: 18.7543 - R2: 0.9861 - val_loss: 5.3690 - val_mae: 5.8325 - val_mse: 59.0388 - val_R2: 0.9555\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4076 - mae: 2.8669 - mse: 15.1747 - R2: 0.9888\n",
            "Epoch 70: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.4076 - mae: 2.8669 - mse: 15.1747 - R2: 0.9888 - val_loss: 4.5388 - val_mae: 5.0081 - val_mse: 39.3201 - val_R2: 0.9704\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8983 - mae: 3.3544 - mse: 20.7372 - R2: 0.9846\n",
            "Epoch 71: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.8983 - mae: 3.3544 - mse: 20.7372 - R2: 0.9846 - val_loss: 11.0705 - val_mae: 11.5627 - val_mse: 191.9129 - val_R2: 0.8554\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4124 - mae: 2.8547 - mse: 17.2768 - R2: 0.9872\n",
            "Epoch 72: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 2.4124 - mae: 2.8547 - mse: 17.2768 - R2: 0.9872 - val_loss: 25.0977 - val_mae: 25.5840 - val_mse: 951.4121 - val_R2: 0.2831\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6077 - mae: 3.0646 - mse: 17.1747 - R2: 0.9873\n",
            "Epoch 73: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.6077 - mae: 3.0646 - mse: 17.1747 - R2: 0.9873 - val_loss: 18.0785 - val_mae: 18.5687 - val_mse: 505.7337 - val_R2: 0.6189\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1124 - mae: 3.5750 - mse: 25.1335 - R2: 0.9814\n",
            "Epoch 74: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 3.1124 - mae: 3.5750 - mse: 25.1335 - R2: 0.9814 - val_loss: 5.7774 - val_mae: 6.2530 - val_mse: 61.0250 - val_R2: 0.9540\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5187 - mae: 2.9774 - mse: 14.9897 - R2: 0.9889\n",
            "Epoch 75: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.5187 - mae: 2.9774 - mse: 14.9897 - R2: 0.9889 - val_loss: 5.6143 - val_mae: 6.0934 - val_mse: 54.0147 - val_R2: 0.9593\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2913 - mae: 3.7534 - mse: 23.2431 - R2: 0.9828\n",
            "Epoch 76: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 3.2913 - mae: 3.7534 - mse: 23.2431 - R2: 0.9828 - val_loss: 7.2546 - val_mae: 7.7177 - val_mse: 88.3067 - val_R2: 0.9335\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1841 - mae: 2.6375 - mse: 12.2210 - R2: 0.9909\n",
            "Epoch 77: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.1841 - mae: 2.6375 - mse: 12.2210 - R2: 0.9909 - val_loss: 5.3710 - val_mae: 5.8503 - val_mse: 52.9186 - val_R2: 0.9601\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8374 - mae: 3.2921 - mse: 22.1741 - R2: 0.9836\n",
            "Epoch 78: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.8374 - mae: 3.2921 - mse: 22.1741 - R2: 0.9836 - val_loss: 10.9784 - val_mae: 11.4533 - val_mse: 242.5033 - val_R2: 0.8173\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4289 - mae: 3.8858 - mse: 32.8737 - R2: 0.9756\n",
            "Epoch 79: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 3.4289 - mae: 3.8858 - mse: 32.8737 - R2: 0.9756 - val_loss: 11.6825 - val_mae: 12.1606 - val_mse: 265.4382 - val_R2: 0.8000\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2302 - mae: 2.6824 - mse: 14.0107 - R2: 0.9896\n",
            "Epoch 80: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.2302 - mae: 2.6824 - mse: 14.0107 - R2: 0.9896 - val_loss: 3.5611 - val_mae: 4.0286 - val_mse: 26.5567 - val_R2: 0.9800\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4978 - mae: 2.9439 - mse: 17.8071 - R2: 0.9868\n",
            "Epoch 81: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.4978 - mae: 2.9439 - mse: 17.8071 - R2: 0.9868 - val_loss: 4.0862 - val_mae: 4.5618 - val_mse: 33.8870 - val_R2: 0.9745\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7363 - mae: 3.1911 - mse: 19.3890 - R2: 0.9856\n",
            "Epoch 82: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.7363 - mae: 3.1911 - mse: 19.3890 - R2: 0.9856 - val_loss: 19.6221 - val_mae: 20.1096 - val_mse: 518.0346 - val_R2: 0.6097\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9366 - mae: 3.3992 - mse: 20.3897 - R2: 0.9849\n",
            "Epoch 83: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.9366 - mae: 3.3992 - mse: 20.3897 - R2: 0.9849 - val_loss: 4.8193 - val_mae: 5.2898 - val_mse: 43.0694 - val_R2: 0.9675\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3330 - mae: 2.7905 - mse: 14.7992 - R2: 0.9890\n",
            "Epoch 84: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.3330 - mae: 2.7905 - mse: 14.7992 - R2: 0.9890 - val_loss: 3.0825 - val_mae: 3.5393 - val_mse: 22.5914 - val_R2: 0.9830\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2856 - mae: 2.7340 - mse: 14.6686 - R2: 0.9891\n",
            "Epoch 85: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 397ms/step - loss: 2.2856 - mae: 2.7340 - mse: 14.6686 - R2: 0.9891 - val_loss: 7.9508 - val_mae: 8.4129 - val_mse: 119.2142 - val_R2: 0.9102\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1585 - mae: 2.6015 - mse: 12.1818 - R2: 0.9910\n",
            "Epoch 86: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.1585 - mae: 2.6015 - mse: 12.1818 - R2: 0.9910 - val_loss: 31.4109 - val_mae: 31.9066 - val_mse: 1277.5499 - val_R2: 0.0374\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2651 - mae: 2.7183 - mse: 13.3922 - R2: 0.9901\n",
            "Epoch 87: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.2651 - mae: 2.7183 - mse: 13.3922 - R2: 0.9901 - val_loss: 4.4993 - val_mae: 4.9826 - val_mse: 34.2103 - val_R2: 0.9742\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9732 - mae: 3.4188 - mse: 26.9764 - R2: 0.9800\n",
            "Epoch 88: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.9732 - mae: 3.4188 - mse: 26.9764 - R2: 0.9800 - val_loss: 7.0108 - val_mae: 7.4794 - val_mse: 86.5526 - val_R2: 0.9348\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4510 - mae: 2.9079 - mse: 15.9676 - R2: 0.9882\n",
            "Epoch 89: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.4510 - mae: 2.9079 - mse: 15.9676 - R2: 0.9882 - val_loss: 3.7540 - val_mae: 4.2210 - val_mse: 28.2065 - val_R2: 0.9787\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9385 - mae: 3.3914 - mse: 23.5269 - R2: 0.9826\n",
            "Epoch 90: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.9385 - mae: 3.3914 - mse: 23.5269 - R2: 0.9826 - val_loss: 5.2715 - val_mae: 5.7490 - val_mse: 48.9425 - val_R2: 0.9631\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7159 - mae: 3.1745 - mse: 16.6984 - R2: 0.9876\n",
            "Epoch 91: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.7159 - mae: 3.1745 - mse: 16.6984 - R2: 0.9876 - val_loss: 11.9697 - val_mae: 12.4648 - val_mse: 216.9520 - val_R2: 0.8365\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9135 - mae: 3.3779 - mse: 21.2364 - R2: 0.9843\n",
            "Epoch 92: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.9135 - mae: 3.3779 - mse: 21.2364 - R2: 0.9843 - val_loss: 7.8389 - val_mae: 8.3177 - val_mse: 111.3786 - val_R2: 0.9161\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2640 - mae: 3.7224 - mse: 29.2230 - R2: 0.9783\n",
            "Epoch 93: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 3.2640 - mae: 3.7224 - mse: 29.2230 - R2: 0.9783 - val_loss: 4.9133 - val_mae: 5.3755 - val_mse: 52.7534 - val_R2: 0.9603\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3281 - mae: 3.7887 - mse: 25.5082 - R2: 0.9811\n",
            "Epoch 94: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 3.3281 - mae: 3.7887 - mse: 25.5082 - R2: 0.9811 - val_loss: 5.9573 - val_mae: 6.4200 - val_mse: 72.1183 - val_R2: 0.9457\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7352 - mae: 3.1914 - mse: 19.6229 - R2: 0.9855\n",
            "Epoch 95: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 398ms/step - loss: 2.7352 - mae: 3.1914 - mse: 19.6229 - R2: 0.9855 - val_loss: 22.6562 - val_mae: 23.1416 - val_mse: 834.8840 - val_R2: 0.3709\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4708 - mae: 2.9169 - mse: 17.6940 - R2: 0.9869\n",
            "Epoch 96: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.4708 - mae: 2.9169 - mse: 17.6940 - R2: 0.9869 - val_loss: 6.7784 - val_mae: 7.2678 - val_mse: 100.1915 - val_R2: 0.9245\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7064 - mae: 3.1709 - mse: 17.8126 - R2: 0.9868\n",
            "Epoch 97: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.7064 - mae: 3.1709 - mse: 17.8126 - R2: 0.9868 - val_loss: 3.1965 - val_mae: 3.6688 - val_mse: 22.1065 - val_R2: 0.9833\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4628 - mae: 2.9168 - mse: 16.4829 - R2: 0.9878\n",
            "Epoch 98: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.4628 - mae: 2.9168 - mse: 16.4829 - R2: 0.9878 - val_loss: 4.5758 - val_mae: 5.0440 - val_mse: 43.7200 - val_R2: 0.9671\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2287 - mae: 2.6668 - mse: 14.1849 - R2: 0.9895\n",
            "Epoch 99: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 2.2287 - mae: 2.6668 - mse: 14.1849 - R2: 0.9895 - val_loss: 4.2590 - val_mae: 4.7247 - val_mse: 37.6351 - val_R2: 0.9716\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3538 - mae: 2.7902 - mse: 15.2994 - R2: 0.9887\n",
            "Epoch 100: val_loss did not improve from 3.00795\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.3538 - mae: 2.7902 - mse: 15.2994 - R2: 0.9887 - val_loss: 4.1449 - val_mae: 4.5944 - val_mse: 37.7077 - val_R2: 0.9716\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0329 - mae: 2.4901 - mse: 10.8172 - R2: 0.9920\n",
            "Epoch 101: val_loss improved from 3.00795 to 2.26572, saving model to saved_models/ResNet_0deg_withTL/resnet_2.h5\n",
            "13/13 [==============================] - 6s 478ms/step - loss: 2.0329 - mae: 2.4901 - mse: 10.8172 - R2: 0.9920 - val_loss: 2.2657 - val_mae: 2.7109 - val_mse: 12.5837 - val_R2: 0.9905\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5777 - mae: 3.0255 - mse: 17.1206 - R2: 0.9873\n",
            "Epoch 102: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 374ms/step - loss: 2.5777 - mae: 3.0255 - mse: 17.1206 - R2: 0.9873 - val_loss: 3.9525 - val_mae: 4.4240 - val_mse: 32.0747 - val_R2: 0.9758\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1794 - mae: 2.6265 - mse: 13.6471 - R2: 0.9899\n",
            "Epoch 103: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.1794 - mae: 2.6265 - mse: 13.6471 - R2: 0.9899 - val_loss: 9.0947 - val_mae: 9.5815 - val_mse: 134.5060 - val_R2: 0.8987\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3182 - mae: 2.7700 - mse: 14.5433 - R2: 0.9892\n",
            "Epoch 104: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.3182 - mae: 2.7700 - mse: 14.5433 - R2: 0.9892 - val_loss: 3.9333 - val_mae: 4.4027 - val_mse: 33.6679 - val_R2: 0.9746\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8344 - mae: 2.2721 - mse: 10.0610 - R2: 0.9925\n",
            "Epoch 105: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.8344 - mae: 2.2721 - mse: 10.0610 - R2: 0.9925 - val_loss: 4.9078 - val_mae: 5.3936 - val_mse: 45.4449 - val_R2: 0.9658\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5001 - mae: 2.9671 - mse: 15.7981 - R2: 0.9883\n",
            "Epoch 106: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.5001 - mae: 2.9671 - mse: 15.7981 - R2: 0.9883 - val_loss: 3.3357 - val_mae: 3.8066 - val_mse: 21.9964 - val_R2: 0.9834\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5998 - mae: 3.0517 - mse: 16.2736 - R2: 0.9879\n",
            "Epoch 107: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.5998 - mae: 3.0517 - mse: 16.2736 - R2: 0.9879 - val_loss: 4.8042 - val_mae: 5.2728 - val_mse: 41.7747 - val_R2: 0.9685\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0765 - mae: 2.5406 - mse: 10.4742 - R2: 0.9922\n",
            "Epoch 108: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 2.0765 - mae: 2.5406 - mse: 10.4742 - R2: 0.9922 - val_loss: 25.5182 - val_mae: 26.0155 - val_mse: 917.9487 - val_R2: 0.3083\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9110 - mae: 2.3588 - mse: 10.4726 - R2: 0.9922\n",
            "Epoch 109: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.9110 - mae: 2.3588 - mse: 10.4726 - R2: 0.9922 - val_loss: 6.4652 - val_mae: 6.9489 - val_mse: 82.9663 - val_R2: 0.9375\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8246 - mae: 2.2700 - mse: 8.9323 - R2: 0.9934\n",
            "Epoch 110: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.8246 - mae: 2.2700 - mse: 8.9323 - R2: 0.9934 - val_loss: 12.3126 - val_mae: 12.8004 - val_mse: 270.4048 - val_R2: 0.7963\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2723 - mae: 2.7273 - mse: 13.0226 - R2: 0.9903\n",
            "Epoch 111: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.2723 - mae: 2.7273 - mse: 13.0226 - R2: 0.9903 - val_loss: 5.3017 - val_mae: 5.8012 - val_mse: 48.6633 - val_R2: 0.9633\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9656 - mae: 2.4021 - mse: 10.0880 - R2: 0.9925\n",
            "Epoch 112: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.9656 - mae: 2.4021 - mse: 10.0880 - R2: 0.9925 - val_loss: 8.1065 - val_mae: 8.5935 - val_mse: 112.6609 - val_R2: 0.9151\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3191 - mae: 2.7641 - mse: 17.1551 - R2: 0.9873\n",
            "Epoch 113: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.3191 - mae: 2.7641 - mse: 17.1551 - R2: 0.9873 - val_loss: 8.7452 - val_mae: 9.2315 - val_mse: 107.4463 - val_R2: 0.9190\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4269 - mae: 2.8743 - mse: 15.2783 - R2: 0.9887\n",
            "Epoch 114: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.4269 - mae: 2.8743 - mse: 15.2783 - R2: 0.9887 - val_loss: 3.2656 - val_mae: 3.7426 - val_mse: 25.2636 - val_R2: 0.9810\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8471 - mae: 2.2866 - mse: 8.9820 - R2: 0.9933\n",
            "Epoch 115: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.8471 - mae: 2.2866 - mse: 8.9820 - R2: 0.9933 - val_loss: 5.5866 - val_mae: 6.0762 - val_mse: 56.0351 - val_R2: 0.9578\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9524 - mae: 2.3995 - mse: 10.2151 - R2: 0.9924\n",
            "Epoch 116: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.9524 - mae: 2.3995 - mse: 10.2151 - R2: 0.9924 - val_loss: 3.8396 - val_mae: 4.3104 - val_mse: 29.1589 - val_R2: 0.9780\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1852 - mae: 2.6318 - mse: 13.9644 - R2: 0.9897\n",
            "Epoch 117: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.1852 - mae: 2.6318 - mse: 13.9644 - R2: 0.9897 - val_loss: 14.2519 - val_mae: 14.7437 - val_mse: 311.5726 - val_R2: 0.7652\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9105 - mae: 2.3491 - mse: 11.0625 - R2: 0.9918\n",
            "Epoch 118: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.9105 - mae: 2.3491 - mse: 11.0625 - R2: 0.9918 - val_loss: 5.6862 - val_mae: 6.1671 - val_mse: 55.1841 - val_R2: 0.9584\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1090 - mae: 2.5678 - mse: 10.6032 - R2: 0.9921\n",
            "Epoch 119: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.1090 - mae: 2.5678 - mse: 10.6032 - R2: 0.9921 - val_loss: 4.1727 - val_mae: 4.6462 - val_mse: 37.2029 - val_R2: 0.9720\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4959 - mae: 2.9479 - mse: 15.7819 - R2: 0.9883\n",
            "Epoch 120: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.4959 - mae: 2.9479 - mse: 15.7819 - R2: 0.9883 - val_loss: 8.5884 - val_mae: 9.0808 - val_mse: 119.3418 - val_R2: 0.9101\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9040 - mae: 2.3375 - mse: 11.2293 - R2: 0.9917\n",
            "Epoch 121: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.9040 - mae: 2.3375 - mse: 11.2293 - R2: 0.9917 - val_loss: 3.3595 - val_mae: 3.8365 - val_mse: 24.6946 - val_R2: 0.9814\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8857 - mae: 2.3199 - mse: 10.5397 - R2: 0.9922\n",
            "Epoch 122: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.8857 - mae: 2.3199 - mse: 10.5397 - R2: 0.9922 - val_loss: 4.7807 - val_mae: 5.2638 - val_mse: 42.2186 - val_R2: 0.9682\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6526 - mae: 2.0876 - mse: 8.8246 - R2: 0.9935\n",
            "Epoch 123: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.6526 - mae: 2.0876 - mse: 8.8246 - R2: 0.9935 - val_loss: 4.2344 - val_mae: 4.7062 - val_mse: 34.3349 - val_R2: 0.9741\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8392 - mae: 2.2814 - mse: 8.8622 - R2: 0.9934\n",
            "Epoch 124: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.8392 - mae: 2.2814 - mse: 8.8622 - R2: 0.9934 - val_loss: 4.4547 - val_mae: 4.9305 - val_mse: 35.9241 - val_R2: 0.9729\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1217 - mae: 2.5651 - mse: 11.9166 - R2: 0.9912\n",
            "Epoch 125: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 400ms/step - loss: 2.1217 - mae: 2.5651 - mse: 11.9166 - R2: 0.9912 - val_loss: 7.3653 - val_mae: 7.8499 - val_mse: 83.5525 - val_R2: 0.9370\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8187 - mae: 2.2623 - mse: 9.3703 - R2: 0.9931\n",
            "Epoch 126: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.8187 - mae: 2.2623 - mse: 9.3703 - R2: 0.9931 - val_loss: 3.7750 - val_mae: 4.2443 - val_mse: 30.6476 - val_R2: 0.9769\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9217 - mae: 2.3550 - mse: 12.1284 - R2: 0.9910\n",
            "Epoch 127: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.9217 - mae: 2.3550 - mse: 12.1284 - R2: 0.9910 - val_loss: 4.9331 - val_mae: 5.3989 - val_mse: 40.4222 - val_R2: 0.9695\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7553 - mae: 2.1869 - mse: 8.5756 - R2: 0.9936\n",
            "Epoch 128: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.7553 - mae: 2.1869 - mse: 8.5756 - R2: 0.9936 - val_loss: 6.1486 - val_mae: 6.6209 - val_mse: 73.9409 - val_R2: 0.9443\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1803 - mae: 3.6289 - mse: 37.8143 - R2: 0.9720\n",
            "Epoch 129: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 3.1803 - mae: 3.6289 - mse: 37.8143 - R2: 0.9720 - val_loss: 13.9427 - val_mae: 14.4397 - val_mse: 336.8652 - val_R2: 0.7462\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.5123 - mae: 3.9692 - mse: 36.6147 - R2: 0.9729\n",
            "Epoch 130: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 3.5123 - mae: 3.9692 - mse: 36.6147 - R2: 0.9729 - val_loss: 11.9433 - val_mae: 12.4382 - val_mse: 216.7063 - val_R2: 0.8367\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3231 - mae: 2.7693 - mse: 15.4855 - R2: 0.9885\n",
            "Epoch 131: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.3231 - mae: 2.7693 - mse: 15.4855 - R2: 0.9885 - val_loss: 10.0948 - val_mae: 10.5909 - val_mse: 179.5353 - val_R2: 0.8647\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2131 - mae: 2.6707 - mse: 14.3300 - R2: 0.9894\n",
            "Epoch 132: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.2131 - mae: 2.6707 - mse: 14.3300 - R2: 0.9894 - val_loss: 11.7174 - val_mae: 12.2002 - val_mse: 273.8818 - val_R2: 0.7936\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4421 - mae: 2.9053 - mse: 15.4938 - R2: 0.9885\n",
            "Epoch 133: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.4421 - mae: 2.9053 - mse: 15.4938 - R2: 0.9885 - val_loss: 6.4159 - val_mae: 6.8906 - val_mse: 78.5377 - val_R2: 0.9408\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3041 - mae: 2.7579 - mse: 15.0755 - R2: 0.9888\n",
            "Epoch 134: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.3041 - mae: 2.7579 - mse: 15.0755 - R2: 0.9888 - val_loss: 15.0288 - val_mae: 15.5062 - val_mse: 463.1031 - val_R2: 0.6511\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4023 - mae: 2.8499 - mse: 15.3767 - R2: 0.9886\n",
            "Epoch 135: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.4023 - mae: 2.8499 - mse: 15.3767 - R2: 0.9886 - val_loss: 11.7974 - val_mae: 12.2627 - val_mse: 275.8326 - val_R2: 0.7922\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2288 - mae: 2.6813 - mse: 12.7927 - R2: 0.9905\n",
            "Epoch 136: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.2288 - mae: 2.6813 - mse: 12.7927 - R2: 0.9905 - val_loss: 9.4656 - val_mae: 9.9350 - val_mse: 150.8509 - val_R2: 0.8863\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0894 - mae: 2.5305 - mse: 12.2685 - R2: 0.9909\n",
            "Epoch 137: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.0894 - mae: 2.5305 - mse: 12.2685 - R2: 0.9909 - val_loss: 5.4177 - val_mae: 5.8951 - val_mse: 60.1413 - val_R2: 0.9547\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1853 - mae: 2.6353 - mse: 12.4818 - R2: 0.9908\n",
            "Epoch 138: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.1853 - mae: 2.6353 - mse: 12.4818 - R2: 0.9908 - val_loss: 3.3205 - val_mae: 3.7905 - val_mse: 23.4180 - val_R2: 0.9824\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6242 - mae: 2.0613 - mse: 8.6294 - R2: 0.9936\n",
            "Epoch 139: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.6242 - mae: 2.0613 - mse: 8.6294 - R2: 0.9936 - val_loss: 8.5761 - val_mae: 9.0676 - val_mse: 108.9961 - val_R2: 0.9179\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2087 - mae: 2.6568 - mse: 12.4773 - R2: 0.9908\n",
            "Epoch 140: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 401ms/step - loss: 2.2087 - mae: 2.6568 - mse: 12.4773 - R2: 0.9908 - val_loss: 8.7669 - val_mae: 9.2363 - val_mse: 132.1748 - val_R2: 0.9004\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1744 - mae: 2.6237 - mse: 13.3371 - R2: 0.9901\n",
            "Epoch 141: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.1744 - mae: 2.6237 - mse: 13.3371 - R2: 0.9901 - val_loss: 12.1227 - val_mae: 12.6116 - val_mse: 250.7265 - val_R2: 0.8111\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3996 - mae: 2.8302 - mse: 16.3436 - R2: 0.9879\n",
            "Epoch 142: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.3996 - mae: 2.8302 - mse: 16.3436 - R2: 0.9879 - val_loss: 20.2646 - val_mae: 20.7455 - val_mse: 619.2950 - val_R2: 0.5334\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0136 - mae: 2.4386 - mse: 11.5822 - R2: 0.9914\n",
            "Epoch 143: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 375ms/step - loss: 2.0136 - mae: 2.4386 - mse: 11.5822 - R2: 0.9914 - val_loss: 4.9148 - val_mae: 5.3736 - val_mse: 49.9319 - val_R2: 0.9624\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3883 - mae: 1.8078 - mse: 6.1952 - R2: 0.9954\n",
            "Epoch 144: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.3883 - mae: 1.8078 - mse: 6.1952 - R2: 0.9954 - val_loss: 16.5993 - val_mae: 17.0892 - val_mse: 408.8796 - val_R2: 0.6919\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3230 - mae: 1.7454 - mse: 5.9849 - R2: 0.9956\n",
            "Epoch 145: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.3230 - mae: 1.7454 - mse: 5.9849 - R2: 0.9956 - val_loss: 2.6508 - val_mae: 3.1279 - val_mse: 15.5020 - val_R2: 0.9883\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3267 - mae: 1.7541 - mse: 5.6471 - R2: 0.9958\n",
            "Epoch 146: val_loss did not improve from 2.26572\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.3267 - mae: 1.7541 - mse: 5.6471 - R2: 0.9958 - val_loss: 6.4631 - val_mae: 6.9424 - val_mse: 72.9445 - val_R2: 0.9450\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4053 - mae: 1.8302 - mse: 6.1623 - R2: 0.9954\n",
            "Epoch 147: val_loss improved from 2.26572 to 1.96133, saving model to saved_models/ResNet_0deg_withTL/resnet_2.h5\n",
            "13/13 [==============================] - 6s 471ms/step - loss: 1.4053 - mae: 1.8302 - mse: 6.1623 - R2: 0.9954 - val_loss: 1.9613 - val_mae: 2.4065 - val_mse: 9.9508 - val_R2: 0.9925\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5491 - mae: 1.9787 - mse: 7.1270 - R2: 0.9947\n",
            "Epoch 148: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.5491 - mae: 1.9787 - mse: 7.1270 - R2: 0.9947 - val_loss: 10.4971 - val_mae: 10.9913 - val_mse: 153.3593 - val_R2: 0.8844\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1602 - mae: 2.6036 - mse: 12.5263 - R2: 0.9907\n",
            "Epoch 149: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.1602 - mae: 2.6036 - mse: 12.5263 - R2: 0.9907 - val_loss: 7.3519 - val_mae: 7.8310 - val_mse: 87.9934 - val_R2: 0.9337\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3018 - mae: 1.7340 - mse: 5.4065 - R2: 0.9960\n",
            "Epoch 150: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.3018 - mae: 1.7340 - mse: 5.4065 - R2: 0.9960 - val_loss: 12.9335 - val_mae: 13.4104 - val_mse: 301.3910 - val_R2: 0.7729\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5769 - mae: 2.0148 - mse: 7.3512 - R2: 0.9946\n",
            "Epoch 151: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.5769 - mae: 2.0148 - mse: 7.3512 - R2: 0.9946 - val_loss: 6.0741 - val_mae: 6.5523 - val_mse: 59.8148 - val_R2: 0.9549\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8830 - mae: 2.3397 - mse: 8.8321 - R2: 0.9935\n",
            "Epoch 152: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.8830 - mae: 2.3397 - mse: 8.8321 - R2: 0.9935 - val_loss: 7.8378 - val_mae: 8.3170 - val_mse: 92.6475 - val_R2: 0.9302\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9524 - mae: 2.4001 - mse: 10.6161 - R2: 0.9921\n",
            "Epoch 153: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 402ms/step - loss: 1.9524 - mae: 2.4001 - mse: 10.6161 - R2: 0.9921 - val_loss: 3.1636 - val_mae: 3.6347 - val_mse: 21.4511 - val_R2: 0.9838\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6028 - mae: 2.0382 - mse: 7.9652 - R2: 0.9941\n",
            "Epoch 154: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.6028 - mae: 2.0382 - mse: 7.9652 - R2: 0.9941 - val_loss: 5.4078 - val_mae: 5.8825 - val_mse: 56.7094 - val_R2: 0.9573\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5598 - mae: 2.0000 - mse: 7.5386 - R2: 0.9944\n",
            "Epoch 155: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.5598 - mae: 2.0000 - mse: 7.5386 - R2: 0.9944 - val_loss: 15.3942 - val_mae: 15.8737 - val_mse: 351.1333 - val_R2: 0.7354\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9248 - mae: 2.3724 - mse: 9.6386 - R2: 0.9929\n",
            "Epoch 156: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.9248 - mae: 2.3724 - mse: 9.6386 - R2: 0.9929 - val_loss: 5.0560 - val_mae: 5.5402 - val_mse: 46.9594 - val_R2: 0.9646\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6993 - mae: 2.1411 - mse: 8.4784 - R2: 0.9937\n",
            "Epoch 157: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.6993 - mae: 2.1411 - mse: 8.4784 - R2: 0.9937 - val_loss: 8.5121 - val_mae: 8.9953 - val_mse: 108.1613 - val_R2: 0.9185\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3830 - mae: 1.8096 - mse: 6.7545 - R2: 0.9950\n",
            "Epoch 158: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 401ms/step - loss: 1.3830 - mae: 1.8096 - mse: 6.7545 - R2: 0.9950 - val_loss: 6.0537 - val_mae: 6.5421 - val_mse: 67.1030 - val_R2: 0.9494\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4867 - mae: 1.9109 - mse: 6.6654 - R2: 0.9951\n",
            "Epoch 159: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.4867 - mae: 1.9109 - mse: 6.6654 - R2: 0.9951 - val_loss: 6.2915 - val_mae: 6.7687 - val_mse: 76.1199 - val_R2: 0.9426\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0985 - mae: 2.5417 - mse: 12.1186 - R2: 0.9910\n",
            "Epoch 160: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.0985 - mae: 2.5417 - mse: 12.1186 - R2: 0.9910 - val_loss: 2.8122 - val_mae: 3.2823 - val_mse: 18.0593 - val_R2: 0.9864\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8822 - mae: 2.3214 - mse: 8.8734 - R2: 0.9934\n",
            "Epoch 161: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.8822 - mae: 2.3214 - mse: 8.8734 - R2: 0.9934 - val_loss: 3.8145 - val_mae: 4.2913 - val_mse: 29.0458 - val_R2: 0.9781\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6530 - mae: 2.0935 - mse: 8.0154 - R2: 0.9941\n",
            "Epoch 162: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.6530 - mae: 2.0935 - mse: 8.0154 - R2: 0.9941 - val_loss: 4.2361 - val_mae: 4.7081 - val_mse: 34.4213 - val_R2: 0.9741\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2092 - mae: 1.6360 - mse: 4.9645 - R2: 0.9963\n",
            "Epoch 163: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.2092 - mae: 1.6360 - mse: 4.9645 - R2: 0.9963 - val_loss: 4.9306 - val_mae: 5.4093 - val_mse: 45.5935 - val_R2: 0.9656\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6743 - mae: 2.1228 - mse: 7.4792 - R2: 0.9945\n",
            "Epoch 164: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.6743 - mae: 2.1228 - mse: 7.4792 - R2: 0.9945 - val_loss: 3.2107 - val_mae: 3.6947 - val_mse: 20.1708 - val_R2: 0.9848\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3085 - mae: 1.7304 - mse: 5.7521 - R2: 0.9957\n",
            "Epoch 165: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.3085 - mae: 1.7304 - mse: 5.7521 - R2: 0.9957 - val_loss: 8.4114 - val_mae: 8.9020 - val_mse: 105.1037 - val_R2: 0.9208\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2932 - mae: 1.7284 - mse: 5.2656 - R2: 0.9961\n",
            "Epoch 166: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.2932 - mae: 1.7284 - mse: 5.2656 - R2: 0.9961 - val_loss: 4.6979 - val_mae: 5.1660 - val_mse: 46.7193 - val_R2: 0.9648\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2969 - mae: 1.7153 - mse: 5.4436 - R2: 0.9960\n",
            "Epoch 167: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.2969 - mae: 1.7153 - mse: 5.4436 - R2: 0.9960 - val_loss: 3.4661 - val_mae: 3.9343 - val_mse: 25.4427 - val_R2: 0.9808\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5782 - mae: 2.0046 - mse: 8.0384 - R2: 0.9940\n",
            "Epoch 168: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.5782 - mae: 2.0046 - mse: 8.0384 - R2: 0.9940 - val_loss: 3.7519 - val_mae: 4.2274 - val_mse: 28.0192 - val_R2: 0.9789\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9601 - mae: 1.3681 - mse: 3.3890 - R2: 0.9975\n",
            "Epoch 169: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 0.9601 - mae: 1.3681 - mse: 3.3890 - R2: 0.9975 - val_loss: 3.1413 - val_mae: 3.5975 - val_mse: 21.9668 - val_R2: 0.9834\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4305 - mae: 1.8524 - mse: 6.6975 - R2: 0.9950\n",
            "Epoch 170: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 402ms/step - loss: 1.4305 - mae: 1.8524 - mse: 6.6975 - R2: 0.9950 - val_loss: 5.9679 - val_mae: 6.4421 - val_mse: 59.2113 - val_R2: 0.9554\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6754 - mae: 2.1014 - mse: 9.2405 - R2: 0.9932\n",
            "Epoch 171: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 401ms/step - loss: 1.6754 - mae: 2.1014 - mse: 9.2405 - R2: 0.9932 - val_loss: 4.4684 - val_mae: 4.9410 - val_mse: 40.7875 - val_R2: 0.9693\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1574 - mae: 1.5776 - mse: 4.6644 - R2: 0.9965\n",
            "Epoch 172: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 402ms/step - loss: 1.1574 - mae: 1.5776 - mse: 4.6644 - R2: 0.9965 - val_loss: 2.1679 - val_mae: 2.6152 - val_mse: 11.8115 - val_R2: 0.9911\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2905 - mae: 1.7265 - mse: 5.2352 - R2: 0.9961\n",
            "Epoch 173: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.2905 - mae: 1.7265 - mse: 5.2352 - R2: 0.9961 - val_loss: 2.7723 - val_mae: 3.2307 - val_mse: 18.3705 - val_R2: 0.9862\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2489 - mae: 1.6726 - mse: 5.1192 - R2: 0.9962\n",
            "Epoch 174: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.2489 - mae: 1.6726 - mse: 5.1192 - R2: 0.9962 - val_loss: 4.0082 - val_mae: 4.4787 - val_mse: 29.2759 - val_R2: 0.9779\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4218 - mae: 1.8538 - mse: 6.3142 - R2: 0.9953\n",
            "Epoch 175: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.4218 - mae: 1.8538 - mse: 6.3142 - R2: 0.9953 - val_loss: 2.3589 - val_mae: 2.8176 - val_mse: 13.2330 - val_R2: 0.9900\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4758 - mae: 1.9009 - mse: 6.5296 - R2: 0.9952\n",
            "Epoch 176: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.4758 - mae: 1.9009 - mse: 6.5296 - R2: 0.9952 - val_loss: 7.0246 - val_mae: 7.5083 - val_mse: 81.0791 - val_R2: 0.9389\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3477 - mae: 1.7609 - mse: 6.7939 - R2: 0.9950\n",
            "Epoch 177: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 402ms/step - loss: 1.3477 - mae: 1.7609 - mse: 6.7939 - R2: 0.9950 - val_loss: 7.0611 - val_mae: 7.5476 - val_mse: 91.1058 - val_R2: 0.9314\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1978 - mae: 1.6187 - mse: 4.8725 - R2: 0.9964\n",
            "Epoch 178: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.1978 - mae: 1.6187 - mse: 4.8725 - R2: 0.9964 - val_loss: 4.3978 - val_mae: 4.8755 - val_mse: 37.9150 - val_R2: 0.9714\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2396 - mae: 1.6572 - mse: 6.6394 - R2: 0.9951\n",
            "Epoch 179: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.2396 - mae: 1.6572 - mse: 6.6394 - R2: 0.9951 - val_loss: 2.5845 - val_mae: 3.0395 - val_mse: 16.1400 - val_R2: 0.9878\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3651 - mae: 1.7891 - mse: 6.5880 - R2: 0.9951\n",
            "Epoch 180: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.3651 - mae: 1.7891 - mse: 6.5880 - R2: 0.9951 - val_loss: 2.6645 - val_mae: 3.1360 - val_mse: 17.4579 - val_R2: 0.9868\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3889 - mae: 1.8173 - mse: 6.1217 - R2: 0.9955\n",
            "Epoch 181: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.3889 - mae: 1.8173 - mse: 6.1217 - R2: 0.9955 - val_loss: 24.3117 - val_mae: 24.8006 - val_mse: 887.9443 - val_R2: 0.3309\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3761 - mae: 1.7943 - mse: 8.2114 - R2: 0.9939\n",
            "Epoch 182: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.3761 - mae: 1.7943 - mse: 8.2114 - R2: 0.9939 - val_loss: 3.4971 - val_mae: 3.9706 - val_mse: 24.1942 - val_R2: 0.9818\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5885 - mae: 2.0193 - mse: 7.0386 - R2: 0.9948\n",
            "Epoch 183: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 1.5885 - mae: 2.0193 - mse: 7.0386 - R2: 0.9948 - val_loss: 2.9690 - val_mae: 3.4278 - val_mse: 19.7741 - val_R2: 0.9851\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2250 - mae: 1.6472 - mse: 4.8238 - R2: 0.9964\n",
            "Epoch 184: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.2250 - mae: 1.6472 - mse: 4.8238 - R2: 0.9964 - val_loss: 2.2257 - val_mae: 2.6438 - val_mse: 13.5740 - val_R2: 0.9898\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5964 - mae: 2.0254 - mse: 7.8395 - R2: 0.9942\n",
            "Epoch 185: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.5964 - mae: 2.0254 - mse: 7.8395 - R2: 0.9942 - val_loss: 14.0500 - val_mae: 14.5268 - val_mse: 331.5353 - val_R2: 0.7502\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4518 - mae: 1.8739 - mse: 6.9122 - R2: 0.9949\n",
            "Epoch 186: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.4518 - mae: 1.8739 - mse: 6.9122 - R2: 0.9949 - val_loss: 6.2043 - val_mae: 6.6722 - val_mse: 85.5054 - val_R2: 0.9356\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7696 - mae: 2.2090 - mse: 8.9412 - R2: 0.9934\n",
            "Epoch 187: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.7696 - mae: 2.2090 - mse: 8.9412 - R2: 0.9934 - val_loss: 2.3984 - val_mae: 2.8625 - val_mse: 15.3516 - val_R2: 0.9884\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5455 - mae: 1.9739 - mse: 7.5522 - R2: 0.9944\n",
            "Epoch 188: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.5455 - mae: 1.9739 - mse: 7.5522 - R2: 0.9944 - val_loss: 6.9481 - val_mae: 7.4265 - val_mse: 100.0608 - val_R2: 0.9246\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2554 - mae: 1.6818 - mse: 5.0782 - R2: 0.9962\n",
            "Epoch 189: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.2554 - mae: 1.6818 - mse: 5.0782 - R2: 0.9962 - val_loss: 6.1001 - val_mae: 6.5767 - val_mse: 71.4769 - val_R2: 0.9461\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6053 - mae: 2.0278 - mse: 10.5243 - R2: 0.9922\n",
            "Epoch 190: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.6053 - mae: 2.0278 - mse: 10.5243 - R2: 0.9922 - val_loss: 14.5152 - val_mae: 14.9963 - val_mse: 371.5731 - val_R2: 0.7200\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5503 - mae: 1.9883 - mse: 6.8760 - R2: 0.9949\n",
            "Epoch 191: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.5503 - mae: 1.9883 - mse: 6.8760 - R2: 0.9949 - val_loss: 5.0519 - val_mae: 5.5213 - val_mse: 47.0435 - val_R2: 0.9646\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4641 - mae: 1.8981 - mse: 6.5468 - R2: 0.9951\n",
            "Epoch 192: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.4641 - mae: 1.8981 - mse: 6.5468 - R2: 0.9951 - val_loss: 8.6260 - val_mae: 9.1104 - val_mse: 112.2784 - val_R2: 0.9154\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1871 - mae: 1.5991 - mse: 5.0940 - R2: 0.9962\n",
            "Epoch 193: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.1871 - mae: 1.5991 - mse: 5.0940 - R2: 0.9962 - val_loss: 5.8208 - val_mae: 6.3103 - val_mse: 56.2707 - val_R2: 0.9576\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5668 - mae: 1.9998 - mse: 7.2121 - R2: 0.9947\n",
            "Epoch 194: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.5668 - mae: 1.9998 - mse: 7.2121 - R2: 0.9947 - val_loss: 3.6769 - val_mae: 4.1631 - val_mse: 25.9953 - val_R2: 0.9804\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4176 - mae: 1.8332 - mse: 7.3777 - R2: 0.9945\n",
            "Epoch 195: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.4176 - mae: 1.8332 - mse: 7.3777 - R2: 0.9945 - val_loss: 5.1695 - val_mae: 5.6481 - val_mse: 48.5442 - val_R2: 0.9634\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2709 - mae: 1.6937 - mse: 5.2224 - R2: 0.9961\n",
            "Epoch 196: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.2709 - mae: 1.6937 - mse: 5.2224 - R2: 0.9961 - val_loss: 7.1111 - val_mae: 7.5952 - val_mse: 89.3977 - val_R2: 0.9326\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5408 - mae: 1.9647 - mse: 8.0754 - R2: 0.9940\n",
            "Epoch 197: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.5408 - mae: 1.9647 - mse: 8.0754 - R2: 0.9940 - val_loss: 2.3586 - val_mae: 2.8218 - val_mse: 13.1709 - val_R2: 0.9901\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1714 - mae: 1.5755 - mse: 5.0403 - R2: 0.9963\n",
            "Epoch 198: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.1714 - mae: 1.5755 - mse: 5.0403 - R2: 0.9963 - val_loss: 3.0014 - val_mae: 3.4679 - val_mse: 21.4527 - val_R2: 0.9838\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3580 - mae: 1.7782 - mse: 6.2124 - R2: 0.9954\n",
            "Epoch 199: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.3580 - mae: 1.7782 - mse: 6.2124 - R2: 0.9954 - val_loss: 9.8408 - val_mae: 10.3258 - val_mse: 139.0915 - val_R2: 0.8952\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6395 - mae: 2.0658 - mse: 8.3014 - R2: 0.9938\n",
            "Epoch 200: val_loss did not improve from 1.96133\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.6395 - mae: 2.0658 - mse: 8.3014 - R2: 0.9938 - val_loss: 4.3175 - val_mae: 4.7911 - val_mse: 34.8975 - val_R2: 0.9737\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 2.0321 - mae: 2.4793 - mse: 10.7712 - R2: 0.9919\n",
            "Found 389 validated image filenames.\n",
            "Found 97 validated image filenames.\n",
            "Epoch 1/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 38.9134 - mae: 39.4104 - mse: 2473.0742 - R2: -0.8881\n",
            "Epoch 1: val_loss improved from inf to 524.73053, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 23s 577ms/step - loss: 38.9134 - mae: 39.4104 - mse: 2473.0742 - R2: -0.8881 - val_loss: 524.7305 - val_mae: 525.2305 - val_mse: 281251.8438 - val_R2: -189.5963\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 13.8931 - mae: 14.3860 - mse: 374.3673 - R2: 0.7142\n",
            "Epoch 2: val_loss did not improve from 524.73053\n",
            "13/13 [==============================] - 5s 399ms/step - loss: 13.8931 - mae: 14.3860 - mse: 374.3673 - R2: 0.7142 - val_loss: 864.3763 - val_mae: 864.8763 - val_mse: 757138.8750 - val_R2: -512.0908\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 9.2493 - mae: 9.7369 - mse: 175.9622 - R2: 0.8657\n",
            "Epoch 3: val_loss did not improve from 524.73053\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 9.2493 - mae: 9.7369 - mse: 175.9622 - R2: 0.8657 - val_loss: 2329.5698 - val_mae: 2330.0698 - val_mse: 5665453.0000 - val_R2: -3838.3154\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.9972 - mae: 8.4800 - mse: 133.3319 - R2: 0.8982\n",
            "Epoch 4: val_loss did not improve from 524.73053\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 7.9972 - mae: 8.4800 - mse: 133.3319 - R2: 0.8982 - val_loss: 744.1414 - val_mae: 744.6414 - val_mse: 579137.5625 - val_R2: -391.4650\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 9.6037 - mae: 10.0942 - mse: 188.6410 - R2: 0.8560\n",
            "Epoch 5: val_loss did not improve from 524.73053\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 9.6037 - mae: 10.0942 - mse: 188.6410 - R2: 0.8560 - val_loss: 4180.9502 - val_mae: 4181.4502 - val_mse: 24781328.0000 - val_R2: -16792.5977\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.3752 - mae: 7.8626 - mse: 117.5416 - R2: 0.9103\n",
            "Epoch 6: val_loss did not improve from 524.73053\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 7.3752 - mae: 7.8626 - mse: 117.5416 - R2: 0.9103 - val_loss: 1096.1360 - val_mae: 1096.6360 - val_mse: 1610846.5000 - val_R2: -1090.6239\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.2966 - mae: 6.7754 - mse: 78.2344 - R2: 0.9403\n",
            "Epoch 7: val_loss did not improve from 524.73053\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 6.2966 - mae: 6.7754 - mse: 78.2344 - R2: 0.9403 - val_loss: 630.3530 - val_mae: 630.8530 - val_mse: 511788.9062 - val_R2: -345.8247\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 8.0091 - mae: 8.4893 - mse: 130.7158 - R2: 0.9002\n",
            "Epoch 8: val_loss did not improve from 524.73053\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 8.0091 - mae: 8.4893 - mse: 130.7158 - R2: 0.9002 - val_loss: 551.7168 - val_mae: 552.2168 - val_mse: 378659.5312 - val_R2: -255.6066\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.9270 - mae: 7.4113 - mse: 97.5676 - R2: 0.9255 \n",
            "Epoch 9: val_loss improved from 524.73053 to 286.03183, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 479ms/step - loss: 6.9270 - mae: 7.4113 - mse: 97.5676 - R2: 0.9255 - val_loss: 286.0318 - val_mae: 286.5318 - val_mse: 109863.8984 - val_R2: -73.4516\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 8.5268 - mae: 9.0171 - mse: 151.7157 - R2: 0.8842\n",
            "Epoch 10: val_loss improved from 286.03183 to 210.94751, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 474ms/step - loss: 8.5268 - mae: 9.0171 - mse: 151.7157 - R2: 0.8842 - val_loss: 210.9475 - val_mae: 211.4475 - val_mse: 61213.2070 - val_R2: -40.4824\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.9985 - mae: 7.4835 - mse: 91.5611 - R2: 0.9301\n",
            "Epoch 11: val_loss improved from 210.94751 to 145.01042, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 471ms/step - loss: 6.9985 - mae: 7.4835 - mse: 91.5611 - R2: 0.9301 - val_loss: 145.0104 - val_mae: 145.5104 - val_mse: 27630.6562 - val_R2: -17.7245\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.8014 - mae: 5.2790 - mse: 46.8102 - R2: 0.9643\n",
            "Epoch 12: val_loss improved from 145.01042 to 141.48019, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 493ms/step - loss: 4.8014 - mae: 5.2790 - mse: 46.8102 - R2: 0.9643 - val_loss: 141.4802 - val_mae: 141.9802 - val_mse: 27331.8086 - val_R2: -17.5220\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.8196 - mae: 6.3019 - mse: 65.2269 - R2: 0.9502\n",
            "Epoch 13: val_loss improved from 141.48019 to 104.89894, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 477ms/step - loss: 5.8196 - mae: 6.3019 - mse: 65.2269 - R2: 0.9502 - val_loss: 104.8989 - val_mae: 105.3921 - val_mse: 17049.0332 - val_R2: -10.5536\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.4943 - mae: 5.9730 - mse: 63.6039 - R2: 0.9514\n",
            "Epoch 14: val_loss improved from 104.89894 to 83.91504, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 476ms/step - loss: 5.4943 - mae: 5.9730 - mse: 63.6039 - R2: 0.9514 - val_loss: 83.9150 - val_mae: 84.4150 - val_mse: 10157.4482 - val_R2: -5.8834\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.0291 - mae: 6.5049 - mse: 81.2369 - R2: 0.9380\n",
            "Epoch 15: val_loss improved from 83.91504 to 49.54820, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 472ms/step - loss: 6.0291 - mae: 6.5049 - mse: 81.2369 - R2: 0.9380 - val_loss: 49.5482 - val_mae: 50.0482 - val_mse: 3713.7800 - val_R2: -1.5167\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.4433 - mae: 6.9223 - mse: 96.2159 - R2: 0.9265\n",
            "Epoch 16: val_loss did not improve from 49.54820\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 6.4433 - mae: 6.9223 - mse: 96.2159 - R2: 0.9265 - val_loss: 74.2810 - val_mae: 74.7646 - val_mse: 11434.9199 - val_R2: -6.7491\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.6391 - mae: 7.1250 - mse: 84.7206 - R2: 0.9353\n",
            "Epoch 17: val_loss did not improve from 49.54820\n",
            "13/13 [==============================] - 5s 403ms/step - loss: 6.6391 - mae: 7.1250 - mse: 84.7206 - R2: 0.9353 - val_loss: 71.6238 - val_mae: 72.1144 - val_mse: 8590.2197 - val_R2: -4.8213\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.6333 - mae: 8.1231 - mse: 104.9474 - R2: 0.9199\n",
            "Epoch 18: val_loss improved from 49.54820 to 34.91396, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 479ms/step - loss: 7.6333 - mae: 8.1231 - mse: 104.9474 - R2: 0.9199 - val_loss: 34.9140 - val_mae: 35.4096 - val_mse: 2109.7725 - val_R2: -0.4297\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.8200 - mae: 5.2963 - mse: 55.9060 - R2: 0.9573\n",
            "Epoch 19: val_loss improved from 34.91396 to 25.05985, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 479ms/step - loss: 4.8200 - mae: 5.2963 - mse: 55.9060 - R2: 0.9573 - val_loss: 25.0598 - val_mae: 25.5421 - val_mse: 1526.4722 - val_R2: -0.0344\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.7461 - mae: 5.2184 - mse: 45.9249 - R2: 0.9649\n",
            "Epoch 20: val_loss improved from 25.05985 to 25.01652, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 477ms/step - loss: 4.7461 - mae: 5.2184 - mse: 45.9249 - R2: 0.9649 - val_loss: 25.0165 - val_mae: 25.5006 - val_mse: 1120.9930 - val_R2: 0.2403\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.6613 - mae: 6.1381 - mse: 65.5156 - R2: 0.9500\n",
            "Epoch 21: val_loss improved from 25.01652 to 9.21882, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 478ms/step - loss: 5.6613 - mae: 6.1381 - mse: 65.5156 - R2: 0.9500 - val_loss: 9.2188 - val_mae: 9.7036 - val_mse: 138.7041 - val_R2: 0.9060\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.1325 - mae: 5.6144 - mse: 56.8538 - R2: 0.9566\n",
            "Epoch 22: val_loss did not improve from 9.21882\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 5.1325 - mae: 5.6144 - mse: 56.8538 - R2: 0.9566 - val_loss: 24.8733 - val_mae: 25.3598 - val_mse: 1085.2373 - val_R2: 0.2646\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.7599 - mae: 5.2356 - mse: 51.4008 - R2: 0.9608\n",
            "Epoch 23: val_loss did not improve from 9.21882\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 4.7599 - mae: 5.2356 - mse: 51.4008 - R2: 0.9608 - val_loss: 12.4755 - val_mae: 12.9676 - val_mse: 249.2996 - val_R2: 0.8311\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.1795 - mae: 5.6594 - mse: 61.6095 - R2: 0.9530\n",
            "Epoch 24: val_loss did not improve from 9.21882\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 5.1795 - mae: 5.6594 - mse: 61.6095 - R2: 0.9530 - val_loss: 16.0657 - val_mae: 16.5610 - val_mse: 356.5975 - val_R2: 0.7583\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.1577 - mae: 4.6274 - mse: 41.5766 - R2: 0.9683\n",
            "Epoch 25: val_loss did not improve from 9.21882\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 4.1577 - mae: 4.6274 - mse: 41.5766 - R2: 0.9683 - val_loss: 11.0158 - val_mae: 11.5095 - val_mse: 265.3264 - val_R2: 0.8202\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0567 - mae: 4.5303 - mse: 34.7213 - R2: 0.9735\n",
            "Epoch 26: val_loss did not improve from 9.21882\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 4.0567 - mae: 4.5303 - mse: 34.7213 - R2: 0.9735 - val_loss: 10.2574 - val_mae: 10.7505 - val_mse: 182.2757 - val_R2: 0.8765\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.9084 - mae: 5.3783 - mse: 49.1514 - R2: 0.9625\n",
            "Epoch 27: val_loss did not improve from 9.21882\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 4.9084 - mae: 5.3783 - mse: 49.1514 - R2: 0.9625 - val_loss: 9.4350 - val_mae: 9.9254 - val_mse: 137.2622 - val_R2: 0.9070\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.1423 - mae: 4.6219 - mse: 34.7306 - R2: 0.9735\n",
            "Epoch 28: val_loss did not improve from 9.21882\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 4.1423 - mae: 4.6219 - mse: 34.7306 - R2: 0.9735 - val_loss: 18.1503 - val_mae: 18.6503 - val_mse: 434.6508 - val_R2: 0.7054\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.1480 - mae: 6.6296 - mse: 72.4460 - R2: 0.9447\n",
            "Epoch 29: val_loss improved from 9.21882 to 8.67030, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 478ms/step - loss: 6.1480 - mae: 6.6296 - mse: 72.4460 - R2: 0.9447 - val_loss: 8.6703 - val_mae: 9.1681 - val_mse: 117.1860 - val_R2: 0.9206\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.7004 - mae: 5.1760 - mse: 50.5532 - R2: 0.9614\n",
            "Epoch 30: val_loss did not improve from 8.67030\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 4.7004 - mae: 5.1760 - mse: 50.5532 - R2: 0.9614 - val_loss: 8.9085 - val_mae: 9.4044 - val_mse: 131.0514 - val_R2: 0.9112\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.6189 - mae: 5.0998 - mse: 44.2485 - R2: 0.9662\n",
            "Epoch 31: val_loss improved from 8.67030 to 8.22237, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 480ms/step - loss: 4.6189 - mae: 5.0998 - mse: 44.2485 - R2: 0.9662 - val_loss: 8.2224 - val_mae: 8.7111 - val_mse: 123.3829 - val_R2: 0.9164\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.5071 - mae: 4.9868 - mse: 44.1013 - R2: 0.9663\n",
            "Epoch 32: val_loss improved from 8.22237 to 3.82924, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 469ms/step - loss: 4.5071 - mae: 4.9868 - mse: 44.1013 - R2: 0.9663 - val_loss: 3.8292 - val_mae: 4.3054 - val_mse: 26.6350 - val_R2: 0.9820\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.8767 - mae: 4.3447 - mse: 31.5354 - R2: 0.9759\n",
            "Epoch 33: val_loss did not improve from 3.82924\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 3.8767 - mae: 4.3447 - mse: 31.5354 - R2: 0.9759 - val_loss: 15.4338 - val_mae: 15.9338 - val_mse: 345.8048 - val_R2: 0.7657\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2084 - mae: 4.6875 - mse: 36.5935 - R2: 0.9721\n",
            "Epoch 34: val_loss did not improve from 3.82924\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 4.2084 - mae: 4.6875 - mse: 36.5935 - R2: 0.9721 - val_loss: 9.0901 - val_mae: 9.5742 - val_mse: 157.3552 - val_R2: 0.8934\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.8085 - mae: 5.2878 - mse: 45.6025 - R2: 0.9652\n",
            "Epoch 35: val_loss did not improve from 3.82924\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 4.8085 - mae: 5.2878 - mse: 45.6025 - R2: 0.9652 - val_loss: 5.0416 - val_mae: 5.4996 - val_mse: 58.8641 - val_R2: 0.9601\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9559 - mae: 4.4306 - mse: 35.7580 - R2: 0.9727\n",
            "Epoch 36: val_loss did not improve from 3.82924\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 3.9559 - mae: 4.4306 - mse: 35.7580 - R2: 0.9727 - val_loss: 8.4875 - val_mae: 8.9608 - val_mse: 135.2307 - val_R2: 0.9084\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.6003 - mae: 6.0728 - mse: 75.4071 - R2: 0.9424\n",
            "Epoch 37: val_loss did not improve from 3.82924\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 5.6003 - mae: 6.0728 - mse: 75.4071 - R2: 0.9424 - val_loss: 4.8221 - val_mae: 5.2846 - val_mse: 60.4456 - val_R2: 0.9590\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.5151 - mae: 3.9832 - mse: 27.9565 - R2: 0.9787\n",
            "Epoch 38: val_loss did not improve from 3.82924\n",
            "13/13 [==============================] - 5s 409ms/step - loss: 3.5151 - mae: 3.9832 - mse: 27.9565 - R2: 0.9787 - val_loss: 9.7084 - val_mae: 10.2019 - val_mse: 157.3687 - val_R2: 0.8934\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0517 - mae: 3.5115 - mse: 23.0022 - R2: 0.9824\n",
            "Epoch 39: val_loss did not improve from 3.82924\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.0517 - mae: 3.5115 - mse: 23.0022 - R2: 0.9824 - val_loss: 14.6463 - val_mae: 15.1463 - val_mse: 322.6304 - val_R2: 0.7814\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7992 - mae: 4.2715 - mse: 30.7706 - R2: 0.9765\n",
            "Epoch 40: val_loss did not improve from 3.82924\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 3.7992 - mae: 4.2715 - mse: 30.7706 - R2: 0.9765 - val_loss: 40.5757 - val_mae: 41.0744 - val_mse: 3004.9775 - val_R2: -1.0364\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.1668 - mae: 5.6325 - mse: 65.1614 - R2: 0.9503\n",
            "Epoch 41: val_loss did not improve from 3.82924\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 5.1668 - mae: 5.6325 - mse: 65.1614 - R2: 0.9503 - val_loss: 9.6763 - val_mae: 10.1678 - val_mse: 157.8834 - val_R2: 0.8930\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2874 - mae: 4.7555 - mse: 44.6568 - R2: 0.9659\n",
            "Epoch 42: val_loss did not improve from 3.82924\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 4.2874 - mae: 4.7555 - mse: 44.6568 - R2: 0.9659 - val_loss: 11.8482 - val_mae: 12.3180 - val_mse: 280.7725 - val_R2: 0.8097\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2729 - mae: 4.7446 - mse: 39.9682 - R2: 0.9695\n",
            "Epoch 43: val_loss improved from 3.82924 to 3.80089, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 480ms/step - loss: 4.2729 - mae: 4.7446 - mse: 39.9682 - R2: 0.9695 - val_loss: 3.8009 - val_mae: 4.2852 - val_mse: 29.7600 - val_R2: 0.9798\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3785 - mae: 3.8483 - mse: 27.2916 - R2: 0.9792\n",
            "Epoch 44: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 3.3785 - mae: 3.8483 - mse: 27.2916 - R2: 0.9792 - val_loss: 4.2967 - val_mae: 4.7794 - val_mse: 37.1091 - val_R2: 0.9749\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.5163 - mae: 3.9760 - mse: 28.3941 - R2: 0.9783\n",
            "Epoch 45: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 398ms/step - loss: 3.5163 - mae: 3.9760 - mse: 28.3941 - R2: 0.9783 - val_loss: 11.7585 - val_mae: 12.2553 - val_mse: 189.4610 - val_R2: 0.8716\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.1768 - mae: 4.6497 - mse: 40.2704 - R2: 0.9693\n",
            "Epoch 46: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 4.1768 - mae: 4.6497 - mse: 40.2704 - R2: 0.9693 - val_loss: 13.7989 - val_mae: 14.2885 - val_mse: 326.3996 - val_R2: 0.7788\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7471 - mae: 4.2103 - mse: 35.3633 - R2: 0.9730\n",
            "Epoch 47: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 3.7471 - mae: 4.2103 - mse: 35.3633 - R2: 0.9730 - val_loss: 18.1154 - val_mae: 18.6084 - val_mse: 528.8840 - val_R2: 0.6416\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.5754 - mae: 4.0403 - mse: 29.1527 - R2: 0.9777\n",
            "Epoch 48: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 3.5754 - mae: 4.0403 - mse: 29.1527 - R2: 0.9777 - val_loss: 8.5771 - val_mae: 9.0697 - val_mse: 131.3750 - val_R2: 0.9110\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.5261 - mae: 3.9927 - mse: 28.1585 - R2: 0.9785\n",
            "Epoch 49: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.5261 - mae: 3.9927 - mse: 28.1585 - R2: 0.9785 - val_loss: 9.6481 - val_mae: 10.1302 - val_mse: 208.7501 - val_R2: 0.8585\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0713 - mae: 4.5330 - mse: 38.4290 - R2: 0.9707\n",
            "Epoch 50: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 4.0713 - mae: 4.5330 - mse: 38.4290 - R2: 0.9707 - val_loss: 7.2841 - val_mae: 7.7575 - val_mse: 129.9886 - val_R2: 0.9119\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8950 - mae: 3.3528 - mse: 19.3659 - R2: 0.9852\n",
            "Epoch 51: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.8950 - mae: 3.3528 - mse: 19.3659 - R2: 0.9852 - val_loss: 17.9453 - val_mae: 18.4316 - val_mse: 669.3259 - val_R2: 0.5464\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9733 - mae: 4.4372 - mse: 35.1440 - R2: 0.9732\n",
            "Epoch 52: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 3.9733 - mae: 4.4372 - mse: 35.1440 - R2: 0.9732 - val_loss: 5.5160 - val_mae: 6.0033 - val_mse: 61.1568 - val_R2: 0.9586\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3050 - mae: 3.7685 - mse: 25.1625 - R2: 0.9808\n",
            "Epoch 53: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.3050 - mae: 3.7685 - mse: 25.1625 - R2: 0.9808 - val_loss: 9.5541 - val_mae: 10.0418 - val_mse: 214.7980 - val_R2: 0.8544\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4746 - mae: 3.9322 - mse: 31.4256 - R2: 0.9760\n",
            "Epoch 54: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.4746 - mae: 3.9322 - mse: 31.4256 - R2: 0.9760 - val_loss: 5.9794 - val_mae: 6.4284 - val_mse: 80.6202 - val_R2: 0.9454\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6877 - mae: 4.1512 - mse: 33.1584 - R2: 0.9747\n",
            "Epoch 55: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.6877 - mae: 4.1512 - mse: 33.1584 - R2: 0.9747 - val_loss: 11.8892 - val_mae: 12.3867 - val_mse: 234.9553 - val_R2: 0.8408\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9498 - mae: 4.4059 - mse: 38.2756 - R2: 0.9708\n",
            "Epoch 56: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 3.9498 - mae: 4.4059 - mse: 38.2756 - R2: 0.9708 - val_loss: 4.2525 - val_mae: 4.7360 - val_mse: 34.6391 - val_R2: 0.9765\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9641 - mae: 3.4191 - mse: 24.4532 - R2: 0.9813\n",
            "Epoch 57: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.9641 - mae: 3.4191 - mse: 24.4532 - R2: 0.9813 - val_loss: 12.1263 - val_mae: 12.6053 - val_mse: 355.3254 - val_R2: 0.7592\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6328 - mae: 3.0840 - mse: 18.7348 - R2: 0.9857\n",
            "Epoch 58: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.6328 - mae: 3.0840 - mse: 18.7348 - R2: 0.9857 - val_loss: 6.7992 - val_mae: 7.2859 - val_mse: 98.3068 - val_R2: 0.9334\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.9578 - mae: 5.4357 - mse: 48.1809 - R2: 0.9632\n",
            "Epoch 59: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 4.9578 - mae: 5.4357 - mse: 48.1809 - R2: 0.9632 - val_loss: 7.1981 - val_mae: 7.6754 - val_mse: 116.5216 - val_R2: 0.9210\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1972 - mae: 3.6657 - mse: 22.5478 - R2: 0.9828\n",
            "Epoch 60: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.1972 - mae: 3.6657 - mse: 22.5478 - R2: 0.9828 - val_loss: 6.7754 - val_mae: 7.2571 - val_mse: 90.3538 - val_R2: 0.9388\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2226 - mae: 4.6847 - mse: 43.0869 - R2: 0.9671\n",
            "Epoch 61: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 4.2226 - mae: 4.6847 - mse: 43.0869 - R2: 0.9671 - val_loss: 9.4320 - val_mae: 9.9099 - val_mse: 174.4341 - val_R2: 0.8818\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1223 - mae: 3.5786 - mse: 26.7851 - R2: 0.9796\n",
            "Epoch 62: val_loss did not improve from 3.80089\n",
            "13/13 [==============================] - 5s 399ms/step - loss: 3.1223 - mae: 3.5786 - mse: 26.7851 - R2: 0.9796 - val_loss: 8.3562 - val_mae: 8.8388 - val_mse: 127.7943 - val_R2: 0.9134\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9015 - mae: 3.3578 - mse: 21.0486 - R2: 0.9839\n",
            "Epoch 63: val_loss improved from 3.80089 to 3.04491, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 477ms/step - loss: 2.9015 - mae: 3.3578 - mse: 21.0486 - R2: 0.9839 - val_loss: 3.0449 - val_mae: 3.5190 - val_mse: 21.3937 - val_R2: 0.9855\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7529 - mae: 3.2038 - mse: 19.0006 - R2: 0.9855\n",
            "Epoch 64: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.7529 - mae: 3.2038 - mse: 19.0006 - R2: 0.9855 - val_loss: 12.4100 - val_mae: 12.9021 - val_mse: 229.1969 - val_R2: 0.8447\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9248 - mae: 4.3967 - mse: 34.3416 - R2: 0.9738\n",
            "Epoch 65: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 404ms/step - loss: 3.9248 - mae: 4.3967 - mse: 34.3416 - R2: 0.9738 - val_loss: 12.1800 - val_mae: 12.6639 - val_mse: 331.4347 - val_R2: 0.7754\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2681 - mae: 4.7363 - mse: 41.0359 - R2: 0.9687\n",
            "Epoch 66: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 4.2681 - mae: 4.7363 - mse: 41.0359 - R2: 0.9687 - val_loss: 12.3168 - val_mae: 12.8031 - val_mse: 288.6781 - val_R2: 0.8044\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5152 - mae: 2.9746 - mse: 16.7033 - R2: 0.9872\n",
            "Epoch 67: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.5152 - mae: 2.9746 - mse: 16.7033 - R2: 0.9872 - val_loss: 8.4306 - val_mae: 8.9128 - val_mse: 113.0144 - val_R2: 0.9234\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9082 - mae: 3.3571 - mse: 24.6046 - R2: 0.9812\n",
            "Epoch 68: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.9082 - mae: 3.3571 - mse: 24.6046 - R2: 0.9812 - val_loss: 4.8558 - val_mae: 5.3331 - val_mse: 44.5373 - val_R2: 0.9698\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7225 - mae: 3.1707 - mse: 18.6103 - R2: 0.9858\n",
            "Epoch 69: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.7225 - mae: 3.1707 - mse: 18.6103 - R2: 0.9858 - val_loss: 8.4095 - val_mae: 8.9026 - val_mse: 106.0729 - val_R2: 0.9281\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7886 - mae: 3.2414 - mse: 20.0854 - R2: 0.9847\n",
            "Epoch 70: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.7886 - mae: 3.2414 - mse: 20.0854 - R2: 0.9847 - val_loss: 11.0063 - val_mae: 11.4858 - val_mse: 202.9517 - val_R2: 0.8625\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.8595 - mae: 4.3186 - mse: 38.5361 - R2: 0.9706\n",
            "Epoch 71: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.8595 - mae: 4.3186 - mse: 38.5361 - R2: 0.9706 - val_loss: 4.8217 - val_mae: 5.2890 - val_mse: 48.9754 - val_R2: 0.9668\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0710 - mae: 3.5341 - mse: 21.7668 - R2: 0.9834\n",
            "Epoch 72: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.0710 - mae: 3.5341 - mse: 21.7668 - R2: 0.9834 - val_loss: 5.5828 - val_mae: 6.0764 - val_mse: 56.1068 - val_R2: 0.9620\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4313 - mae: 2.8756 - mse: 15.1966 - R2: 0.9884\n",
            "Epoch 73: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.4313 - mae: 2.8756 - mse: 15.1966 - R2: 0.9884 - val_loss: 3.8994 - val_mae: 4.3612 - val_mse: 36.1974 - val_R2: 0.9755\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3181 - mae: 3.7807 - mse: 25.0600 - R2: 0.9809\n",
            "Epoch 74: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 3.3181 - mae: 3.7807 - mse: 25.0600 - R2: 0.9809 - val_loss: 4.0941 - val_mae: 4.5576 - val_mse: 36.4671 - val_R2: 0.9753\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1057 - mae: 3.5620 - mse: 23.6253 - R2: 0.9820\n",
            "Epoch 75: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.1057 - mae: 3.5620 - mse: 23.6253 - R2: 0.9820 - val_loss: 4.6406 - val_mae: 5.1199 - val_mse: 43.8437 - val_R2: 0.9703\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1658 - mae: 3.6183 - mse: 25.8388 - R2: 0.9803\n",
            "Epoch 76: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 3.1658 - mae: 3.6183 - mse: 25.8388 - R2: 0.9803 - val_loss: 10.8400 - val_mae: 11.3210 - val_mse: 193.6201 - val_R2: 0.8688\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9297 - mae: 3.3802 - mse: 19.8451 - R2: 0.9848\n",
            "Epoch 77: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.9297 - mae: 3.3802 - mse: 19.8451 - R2: 0.9848 - val_loss: 7.0715 - val_mae: 7.5486 - val_mse: 86.2161 - val_R2: 0.9416\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.8121 - mae: 4.2849 - mse: 32.9527 - R2: 0.9748\n",
            "Epoch 78: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 3.8121 - mae: 4.2849 - mse: 32.9527 - R2: 0.9748 - val_loss: 11.4628 - val_mae: 11.9569 - val_mse: 205.9454 - val_R2: 0.8604\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2507 - mae: 3.7115 - mse: 27.8394 - R2: 0.9787\n",
            "Epoch 79: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 3.2507 - mae: 3.7115 - mse: 27.8394 - R2: 0.9787 - val_loss: 3.7820 - val_mae: 4.2583 - val_mse: 30.0354 - val_R2: 0.9796\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8182 - mae: 3.2801 - mse: 19.9232 - R2: 0.9848\n",
            "Epoch 80: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.8182 - mae: 3.2801 - mse: 19.9232 - R2: 0.9848 - val_loss: 4.9251 - val_mae: 5.3944 - val_mse: 51.4855 - val_R2: 0.9651\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0398 - mae: 3.4961 - mse: 21.9522 - R2: 0.9832\n",
            "Epoch 81: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 399ms/step - loss: 3.0398 - mae: 3.4961 - mse: 21.9522 - R2: 0.9832 - val_loss: 3.4385 - val_mae: 3.9081 - val_mse: 24.9227 - val_R2: 0.9831\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8133 - mae: 3.2685 - mse: 19.7194 - R2: 0.9849\n",
            "Epoch 82: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.8133 - mae: 3.2685 - mse: 19.7194 - R2: 0.9849 - val_loss: 6.6065 - val_mae: 7.0980 - val_mse: 78.5258 - val_R2: 0.9468\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0325 - mae: 3.4891 - mse: 25.3599 - R2: 0.9806\n",
            "Epoch 83: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 3.0325 - mae: 3.4891 - mse: 25.3599 - R2: 0.9806 - val_loss: 8.5392 - val_mae: 9.0301 - val_mse: 122.3606 - val_R2: 0.9171\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1269 - mae: 3.5877 - mse: 22.1841 - R2: 0.9831\n",
            "Epoch 84: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 3.1269 - mae: 3.5877 - mse: 22.1841 - R2: 0.9831 - val_loss: 3.5492 - val_mae: 4.0060 - val_mse: 34.1957 - val_R2: 0.9768\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7738 - mae: 3.2196 - mse: 21.9557 - R2: 0.9832\n",
            "Epoch 85: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.7738 - mae: 3.2196 - mse: 21.9557 - R2: 0.9832 - val_loss: 10.2471 - val_mae: 10.7361 - val_mse: 178.5723 - val_R2: 0.8790\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.8778 - mae: 4.3287 - mse: 37.8925 - R2: 0.9711\n",
            "Epoch 86: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 405ms/step - loss: 3.8778 - mae: 4.3287 - mse: 37.8925 - R2: 0.9711 - val_loss: 13.2435 - val_mae: 13.7343 - val_mse: 249.3936 - val_R2: 0.8310\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0484 - mae: 2.4886 - mse: 11.5077 - R2: 0.9912\n",
            "Epoch 87: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.0484 - mae: 2.4886 - mse: 11.5077 - R2: 0.9912 - val_loss: 6.3634 - val_mae: 6.8476 - val_mse: 70.6496 - val_R2: 0.9521\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2394 - mae: 3.6956 - mse: 25.8122 - R2: 0.9803\n",
            "Epoch 88: val_loss did not improve from 3.04491\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 3.2394 - mae: 3.6956 - mse: 25.8122 - R2: 0.9803 - val_loss: 9.8285 - val_mae: 10.3207 - val_mse: 147.5982 - val_R2: 0.9000\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3586 - mae: 2.8035 - mse: 16.7873 - R2: 0.9872\n",
            "Epoch 89: val_loss improved from 3.04491 to 2.81703, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 479ms/step - loss: 2.3586 - mae: 2.8035 - mse: 16.7873 - R2: 0.9872 - val_loss: 2.8170 - val_mae: 3.2644 - val_mse: 17.8803 - val_R2: 0.9879\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2711 - mae: 2.7127 - mse: 13.7825 - R2: 0.9895\n",
            "Epoch 90: val_loss did not improve from 2.81703\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.2711 - mae: 2.7127 - mse: 13.7825 - R2: 0.9895 - val_loss: 5.8299 - val_mae: 6.3154 - val_mse: 62.6379 - val_R2: 0.9576\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3187 - mae: 2.7719 - mse: 16.3724 - R2: 0.9875\n",
            "Epoch 91: val_loss did not improve from 2.81703\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.3187 - mae: 2.7719 - mse: 16.3724 - R2: 0.9875 - val_loss: 5.2925 - val_mae: 5.7766 - val_mse: 51.9980 - val_R2: 0.9648\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6135 - mae: 3.0593 - mse: 19.4150 - R2: 0.9852\n",
            "Epoch 92: val_loss did not improve from 2.81703\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.6135 - mae: 3.0593 - mse: 19.4150 - R2: 0.9852 - val_loss: 8.2832 - val_mae: 8.7490 - val_mse: 114.4238 - val_R2: 0.9225\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1450 - mae: 3.5940 - mse: 29.6047 - R2: 0.9774\n",
            "Epoch 93: val_loss did not improve from 2.81703\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.1450 - mae: 3.5940 - mse: 29.6047 - R2: 0.9774 - val_loss: 3.4859 - val_mae: 3.9461 - val_mse: 24.3461 - val_R2: 0.9835\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3819 - mae: 2.8311 - mse: 14.9041 - R2: 0.9886\n",
            "Epoch 94: val_loss improved from 2.81703 to 2.74006, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 481ms/step - loss: 2.3819 - mae: 2.8311 - mse: 14.9041 - R2: 0.9886 - val_loss: 2.7401 - val_mae: 3.2122 - val_mse: 17.8320 - val_R2: 0.9879\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1402 - mae: 2.5943 - mse: 11.4270 - R2: 0.9913\n",
            "Epoch 95: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.1402 - mae: 2.5943 - mse: 11.4270 - R2: 0.9913 - val_loss: 4.6384 - val_mae: 5.1031 - val_mse: 51.6693 - val_R2: 0.9650\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8031 - mae: 3.2391 - mse: 21.4459 - R2: 0.9836\n",
            "Epoch 96: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.8031 - mae: 3.2391 - mse: 21.4459 - R2: 0.9836 - val_loss: 4.8406 - val_mae: 5.3237 - val_mse: 45.6563 - val_R2: 0.9691\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1640 - mae: 2.6176 - mse: 12.2802 - R2: 0.9906\n",
            "Epoch 97: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.1640 - mae: 2.6176 - mse: 12.2802 - R2: 0.9906 - val_loss: 2.9973 - val_mae: 3.4596 - val_mse: 21.8036 - val_R2: 0.9852\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6146 - mae: 3.0731 - mse: 16.9446 - R2: 0.9871\n",
            "Epoch 98: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.6146 - mae: 3.0731 - mse: 16.9446 - R2: 0.9871 - val_loss: 3.4362 - val_mae: 3.9088 - val_mse: 25.7070 - val_R2: 0.9826\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3361 - mae: 2.7906 - mse: 15.3218 - R2: 0.9883\n",
            "Epoch 99: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.3361 - mae: 2.7906 - mse: 15.3218 - R2: 0.9883 - val_loss: 14.1908 - val_mae: 14.6727 - val_mse: 379.0399 - val_R2: 0.7431\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4432 - mae: 2.8943 - mse: 17.6731 - R2: 0.9865\n",
            "Epoch 100: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.4432 - mae: 2.8943 - mse: 17.6731 - R2: 0.9865 - val_loss: 10.4443 - val_mae: 10.9424 - val_mse: 157.8088 - val_R2: 0.8931\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3454 - mae: 2.7907 - mse: 15.7263 - R2: 0.9880\n",
            "Epoch 101: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.3454 - mae: 2.7907 - mse: 15.7263 - R2: 0.9880 - val_loss: 10.5651 - val_mae: 11.0466 - val_mse: 202.5432 - val_R2: 0.8627\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3726 - mae: 2.8128 - mse: 16.5667 - R2: 0.9874\n",
            "Epoch 102: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.3726 - mae: 2.8128 - mse: 16.5667 - R2: 0.9874 - val_loss: 4.3428 - val_mae: 4.8183 - val_mse: 37.7748 - val_R2: 0.9744\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0399 - mae: 2.4859 - mse: 12.1697 - R2: 0.9907\n",
            "Epoch 103: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.0399 - mae: 2.4859 - mse: 12.1697 - R2: 0.9907 - val_loss: 4.0290 - val_mae: 4.5049 - val_mse: 30.5412 - val_R2: 0.9793\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6231 - mae: 3.0729 - mse: 17.9622 - R2: 0.9863\n",
            "Epoch 104: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.6231 - mae: 3.0729 - mse: 17.9622 - R2: 0.9863 - val_loss: 3.4385 - val_mae: 3.9098 - val_mse: 25.1732 - val_R2: 0.9829\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4560 - mae: 2.9129 - mse: 14.6385 - R2: 0.9888\n",
            "Epoch 105: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.4560 - mae: 2.9129 - mse: 14.6385 - R2: 0.9888 - val_loss: 3.8575 - val_mae: 4.3295 - val_mse: 32.7493 - val_R2: 0.9778\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8956 - mae: 2.3247 - mse: 9.8612 - R2: 0.9925\n",
            "Epoch 106: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 403ms/step - loss: 1.8956 - mae: 2.3247 - mse: 9.8612 - R2: 0.9925 - val_loss: 2.9822 - val_mae: 3.4503 - val_mse: 21.8076 - val_R2: 0.9852\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3258 - mae: 2.7825 - mse: 14.4319 - R2: 0.9890\n",
            "Epoch 107: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.3258 - mae: 2.7825 - mse: 14.4319 - R2: 0.9890 - val_loss: 9.0576 - val_mae: 9.5525 - val_mse: 125.5356 - val_R2: 0.9149\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9721 - mae: 3.4320 - mse: 22.6683 - R2: 0.9827\n",
            "Epoch 108: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.9721 - mae: 3.4320 - mse: 22.6683 - R2: 0.9827 - val_loss: 5.7592 - val_mae: 6.2453 - val_mse: 60.1627 - val_R2: 0.9592\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7381 - mae: 3.1855 - mse: 19.2214 - R2: 0.9853\n",
            "Epoch 109: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 401ms/step - loss: 2.7381 - mae: 3.1855 - mse: 19.2214 - R2: 0.9853 - val_loss: 3.2061 - val_mae: 3.6793 - val_mse: 21.6981 - val_R2: 0.9853\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8938 - mae: 3.3507 - mse: 20.2961 - R2: 0.9845\n",
            "Epoch 110: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 404ms/step - loss: 2.8938 - mae: 3.3507 - mse: 20.2961 - R2: 0.9845 - val_loss: 5.5921 - val_mae: 6.0738 - val_mse: 57.2029 - val_R2: 0.9612\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8044 - mae: 3.2557 - mse: 19.2148 - R2: 0.9853\n",
            "Epoch 111: val_loss did not improve from 2.74006\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.8044 - mae: 3.2557 - mse: 19.2148 - R2: 0.9853 - val_loss: 6.1169 - val_mae: 6.6071 - val_mse: 61.6692 - val_R2: 0.9582\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3630 - mae: 2.8147 - mse: 14.3107 - R2: 0.9891\n",
            "Epoch 112: val_loss improved from 2.74006 to 2.67775, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 476ms/step - loss: 2.3630 - mae: 2.8147 - mse: 14.3107 - R2: 0.9891 - val_loss: 2.6777 - val_mae: 3.1442 - val_mse: 17.7753 - val_R2: 0.9880\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9866 - mae: 2.4295 - mse: 11.1711 - R2: 0.9915\n",
            "Epoch 113: val_loss did not improve from 2.67775\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.9866 - mae: 2.4295 - mse: 11.1711 - R2: 0.9915 - val_loss: 9.9528 - val_mae: 10.4374 - val_mse: 171.0822 - val_R2: 0.8841\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5250 - mae: 2.9702 - mse: 16.4944 - R2: 0.9874\n",
            "Epoch 114: val_loss improved from 2.67775 to 2.17348, saving model to saved_models/ResNet_0deg_withTL/resnet_3.h5\n",
            "13/13 [==============================] - 6s 478ms/step - loss: 2.5250 - mae: 2.9702 - mse: 16.4944 - R2: 0.9874 - val_loss: 2.1735 - val_mae: 2.6386 - val_mse: 11.5290 - val_R2: 0.9922\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4178 - mae: 2.8731 - mse: 14.2475 - R2: 0.9891\n",
            "Epoch 115: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 2.4178 - mae: 2.8731 - mse: 14.2475 - R2: 0.9891 - val_loss: 3.8576 - val_mae: 4.3240 - val_mse: 28.6849 - val_R2: 0.9806\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3764 - mae: 2.8293 - mse: 15.3834 - R2: 0.9883\n",
            "Epoch 116: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.3764 - mae: 2.8293 - mse: 15.3834 - R2: 0.9883 - val_loss: 6.2881 - val_mae: 6.7686 - val_mse: 73.1260 - val_R2: 0.9504\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8362 - mae: 2.2823 - mse: 9.7685 - R2: 0.9925 \n",
            "Epoch 117: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.8362 - mae: 2.2823 - mse: 9.7685 - R2: 0.9925 - val_loss: 3.1619 - val_mae: 3.6337 - val_mse: 21.0612 - val_R2: 0.9857\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8417 - mae: 2.2825 - mse: 9.9895 - R2: 0.9924\n",
            "Epoch 118: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.8417 - mae: 2.2825 - mse: 9.9895 - R2: 0.9924 - val_loss: 3.7522 - val_mae: 4.2183 - val_mse: 30.7995 - val_R2: 0.9791\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5621 - mae: 3.0070 - mse: 17.5133 - R2: 0.9866\n",
            "Epoch 119: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.5621 - mae: 3.0070 - mse: 17.5133 - R2: 0.9866 - val_loss: 6.0687 - val_mae: 6.5600 - val_mse: 56.4653 - val_R2: 0.9617\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7597 - mae: 3.2150 - mse: 19.6959 - R2: 0.9850\n",
            "Epoch 120: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.7597 - mae: 3.2150 - mse: 19.6959 - R2: 0.9850 - val_loss: 5.4222 - val_mae: 5.8923 - val_mse: 59.3674 - val_R2: 0.9598\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3584 - mae: 2.7961 - mse: 16.9676 - R2: 0.9870\n",
            "Epoch 121: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.3584 - mae: 2.7961 - mse: 16.9676 - R2: 0.9870 - val_loss: 3.8934 - val_mae: 4.3654 - val_mse: 31.8760 - val_R2: 0.9784\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7956 - mae: 3.2559 - mse: 20.7212 - R2: 0.9842\n",
            "Epoch 122: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.7956 - mae: 3.2559 - mse: 20.7212 - R2: 0.9842 - val_loss: 3.1376 - val_mae: 3.6038 - val_mse: 20.6584 - val_R2: 0.9860\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1899 - mae: 2.6438 - mse: 12.4460 - R2: 0.9905\n",
            "Epoch 123: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.1899 - mae: 2.6438 - mse: 12.4460 - R2: 0.9905 - val_loss: 8.0191 - val_mae: 8.5027 - val_mse: 101.1414 - val_R2: 0.9315\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7601 - mae: 2.1936 - mse: 9.2746 - R2: 0.9929\n",
            "Epoch 124: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.7601 - mae: 2.1936 - mse: 9.2746 - R2: 0.9929 - val_loss: 7.8706 - val_mae: 8.3524 - val_mse: 111.8607 - val_R2: 0.9242\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8724 - mae: 3.3382 - mse: 18.3586 - R2: 0.9860\n",
            "Epoch 125: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.8724 - mae: 3.3382 - mse: 18.3586 - R2: 0.9860 - val_loss: 5.9512 - val_mae: 6.4165 - val_mse: 73.2304 - val_R2: 0.9504\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8723 - mae: 2.3110 - mse: 9.6267 - R2: 0.9927\n",
            "Epoch 126: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.8723 - mae: 2.3110 - mse: 9.6267 - R2: 0.9927 - val_loss: 11.6555 - val_mae: 12.1460 - val_mse: 221.4034 - val_R2: 0.8500\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9687 - mae: 2.4098 - mse: 10.5679 - R2: 0.9919\n",
            "Epoch 127: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.9687 - mae: 2.4098 - mse: 10.5679 - R2: 0.9919 - val_loss: 8.4038 - val_mae: 8.8772 - val_mse: 138.8192 - val_R2: 0.9059\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1966 - mae: 2.6406 - mse: 14.0216 - R2: 0.9893\n",
            "Epoch 128: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.1966 - mae: 2.6406 - mse: 14.0216 - R2: 0.9893 - val_loss: 16.1469 - val_mae: 16.6357 - val_mse: 413.8852 - val_R2: 0.7195\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2818 - mae: 2.7180 - mse: 16.8853 - R2: 0.9871\n",
            "Epoch 129: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.2818 - mae: 2.7180 - mse: 16.8853 - R2: 0.9871 - val_loss: 13.0702 - val_mae: 13.5629 - val_mse: 255.2675 - val_R2: 0.8270\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0548 - mae: 2.4926 - mse: 14.5068 - R2: 0.9889\n",
            "Epoch 130: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.0548 - mae: 2.4926 - mse: 14.5068 - R2: 0.9889 - val_loss: 7.5771 - val_mae: 8.0694 - val_mse: 86.3689 - val_R2: 0.9415\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9703 - mae: 2.4184 - mse: 10.6434 - R2: 0.9919\n",
            "Epoch 131: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.9703 - mae: 2.4184 - mse: 10.6434 - R2: 0.9919 - val_loss: 5.4544 - val_mae: 5.9415 - val_mse: 51.1944 - val_R2: 0.9653\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3642 - mae: 2.8241 - mse: 14.7849 - R2: 0.9887\n",
            "Epoch 132: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.3642 - mae: 2.8241 - mse: 14.7849 - R2: 0.9887 - val_loss: 6.0897 - val_mae: 6.5745 - val_mse: 76.4755 - val_R2: 0.9482\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3028 - mae: 2.7585 - mse: 13.6427 - R2: 0.9896\n",
            "Epoch 133: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 2.3028 - mae: 2.7585 - mse: 13.6427 - R2: 0.9896 - val_loss: 5.8345 - val_mae: 6.3084 - val_mse: 71.8667 - val_R2: 0.9513\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2038 - mae: 2.6511 - mse: 14.7358 - R2: 0.9887\n",
            "Epoch 134: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.2038 - mae: 2.6511 - mse: 14.7358 - R2: 0.9887 - val_loss: 3.3121 - val_mae: 3.7887 - val_mse: 22.4975 - val_R2: 0.9848\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1959 - mae: 2.6436 - mse: 13.8667 - R2: 0.9894\n",
            "Epoch 135: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 402ms/step - loss: 2.1959 - mae: 2.6436 - mse: 13.8667 - R2: 0.9894 - val_loss: 4.1760 - val_mae: 4.6476 - val_mse: 36.7102 - val_R2: 0.9751\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0101 - mae: 2.4575 - mse: 10.6105 - R2: 0.9919\n",
            "Epoch 136: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.0101 - mae: 2.4575 - mse: 10.6105 - R2: 0.9919 - val_loss: 3.7379 - val_mae: 4.2147 - val_mse: 26.7277 - val_R2: 0.9819\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8304 - mae: 2.2657 - mse: 11.3241 - R2: 0.9914\n",
            "Epoch 137: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.8304 - mae: 2.2657 - mse: 11.3241 - R2: 0.9914 - val_loss: 6.0159 - val_mae: 6.4972 - val_mse: 73.2004 - val_R2: 0.9504\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5710 - mae: 2.0074 - mse: 7.5712 - R2: 0.9942\n",
            "Epoch 138: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.5710 - mae: 2.0074 - mse: 7.5712 - R2: 0.9942 - val_loss: 9.0080 - val_mae: 9.4953 - val_mse: 170.5283 - val_R2: 0.8844\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3858 - mae: 2.8334 - mse: 17.2258 - R2: 0.9868\n",
            "Epoch 139: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.3858 - mae: 2.8334 - mse: 17.2258 - R2: 0.9868 - val_loss: 5.6598 - val_mae: 6.1387 - val_mse: 53.7781 - val_R2: 0.9636\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3991 - mae: 1.8303 - mse: 5.9756 - R2: 0.9954\n",
            "Epoch 140: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.3991 - mae: 1.8303 - mse: 5.9756 - R2: 0.9954 - val_loss: 4.6830 - val_mae: 5.1575 - val_mse: 46.1964 - val_R2: 0.9687\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7153 - mae: 2.1456 - mse: 9.9825 - R2: 0.9924 \n",
            "Epoch 141: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.7153 - mae: 2.1456 - mse: 9.9825 - R2: 0.9924 - val_loss: 7.3716 - val_mae: 7.8655 - val_mse: 80.1067 - val_R2: 0.9457\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1587 - mae: 2.6057 - mse: 11.5850 - R2: 0.9912\n",
            "Epoch 142: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.1587 - mae: 2.6057 - mse: 11.5850 - R2: 0.9912 - val_loss: 2.5785 - val_mae: 3.0517 - val_mse: 14.8730 - val_R2: 0.9899\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0974 - mae: 2.5493 - mse: 11.8442 - R2: 0.9910\n",
            "Epoch 143: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.0974 - mae: 2.5493 - mse: 11.8442 - R2: 0.9910 - val_loss: 2.2369 - val_mae: 2.6992 - val_mse: 11.6193 - val_R2: 0.9921\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1158 - mae: 2.5570 - mse: 13.3546 - R2: 0.9898\n",
            "Epoch 144: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.1158 - mae: 2.5570 - mse: 13.3546 - R2: 0.9898 - val_loss: 2.8556 - val_mae: 3.3090 - val_mse: 17.9612 - val_R2: 0.9878\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8054 - mae: 2.2559 - mse: 8.9679 - R2: 0.9932\n",
            "Epoch 145: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.8054 - mae: 2.2559 - mse: 8.9679 - R2: 0.9932 - val_loss: 4.1109 - val_mae: 4.5955 - val_mse: 31.0664 - val_R2: 0.9789\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9068 - mae: 2.3403 - mse: 11.3533 - R2: 0.9913\n",
            "Epoch 146: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.9068 - mae: 2.3403 - mse: 11.3533 - R2: 0.9913 - val_loss: 4.0116 - val_mae: 4.4719 - val_mse: 41.0877 - val_R2: 0.9722\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7037 - mae: 2.1302 - mse: 9.3943 - R2: 0.9928\n",
            "Epoch 147: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.7037 - mae: 2.1302 - mse: 9.3943 - R2: 0.9928 - val_loss: 4.9795 - val_mae: 5.4674 - val_mse: 46.7229 - val_R2: 0.9683\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9769 - mae: 2.4204 - mse: 10.4576 - R2: 0.9920\n",
            "Epoch 148: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.9769 - mae: 2.4204 - mse: 10.4576 - R2: 0.9920 - val_loss: 4.8070 - val_mae: 5.2881 - val_mse: 45.7901 - val_R2: 0.9690\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3490 - mae: 2.8019 - mse: 14.6596 - R2: 0.9888\n",
            "Epoch 149: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.3490 - mae: 2.8019 - mse: 14.6596 - R2: 0.9888 - val_loss: 4.6146 - val_mae: 5.0898 - val_mse: 43.6593 - val_R2: 0.9704\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8793 - mae: 2.3213 - mse: 10.7372 - R2: 0.9918\n",
            "Epoch 150: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.8793 - mae: 2.3213 - mse: 10.7372 - R2: 0.9918 - val_loss: 4.4857 - val_mae: 4.9739 - val_mse: 41.4870 - val_R2: 0.9719\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6338 - mae: 2.0885 - mse: 7.4852 - R2: 0.9943\n",
            "Epoch 151: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.6338 - mae: 2.0885 - mse: 7.4852 - R2: 0.9943 - val_loss: 4.3452 - val_mae: 4.8170 - val_mse: 38.0631 - val_R2: 0.9742\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1655 - mae: 2.6169 - mse: 13.7674 - R2: 0.9895\n",
            "Epoch 152: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.1655 - mae: 2.6169 - mse: 13.7674 - R2: 0.9895 - val_loss: 2.7128 - val_mae: 3.1734 - val_mse: 15.3683 - val_R2: 0.9896\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3977 - mae: 2.8428 - mse: 15.8396 - R2: 0.9879\n",
            "Epoch 153: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.3977 - mae: 2.8428 - mse: 15.8396 - R2: 0.9879 - val_loss: 2.6734 - val_mae: 3.1317 - val_mse: 14.4861 - val_R2: 0.9902\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9484 - mae: 2.3753 - mse: 10.5653 - R2: 0.9919\n",
            "Epoch 154: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.9484 - mae: 2.3753 - mse: 10.5653 - R2: 0.9919 - val_loss: 3.4871 - val_mae: 3.9694 - val_mse: 28.1009 - val_R2: 0.9810\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6177 - mae: 2.0467 - mse: 7.8260 - R2: 0.9940\n",
            "Epoch 155: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.6177 - mae: 2.0467 - mse: 7.8260 - R2: 0.9940 - val_loss: 9.0073 - val_mae: 9.4800 - val_mse: 140.3557 - val_R2: 0.9049\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6983 - mae: 2.1275 - mse: 8.2905 - R2: 0.9937\n",
            "Epoch 156: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.6983 - mae: 2.1275 - mse: 8.2905 - R2: 0.9937 - val_loss: 5.2559 - val_mae: 5.7343 - val_mse: 54.6214 - val_R2: 0.9630\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6397 - mae: 3.0957 - mse: 16.5628 - R2: 0.9874\n",
            "Epoch 157: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.6397 - mae: 3.0957 - mse: 16.5628 - R2: 0.9874 - val_loss: 5.4739 - val_mae: 5.9498 - val_mse: 64.4636 - val_R2: 0.9563\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7965 - mae: 2.2404 - mse: 9.0073 - R2: 0.9931\n",
            "Epoch 158: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.7965 - mae: 2.2404 - mse: 9.0073 - R2: 0.9931 - val_loss: 3.1156 - val_mae: 3.5811 - val_mse: 21.6240 - val_R2: 0.9853\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6279 - mae: 2.0557 - mse: 8.2622 - R2: 0.9937\n",
            "Epoch 159: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.6279 - mae: 2.0557 - mse: 8.2622 - R2: 0.9937 - val_loss: 11.1665 - val_mae: 11.6450 - val_mse: 216.0035 - val_R2: 0.8536\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9497 - mae: 2.3830 - mse: 11.0005 - R2: 0.9916\n",
            "Epoch 160: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 404ms/step - loss: 1.9497 - mae: 2.3830 - mse: 11.0005 - R2: 0.9916 - val_loss: 6.6803 - val_mae: 7.1636 - val_mse: 84.2552 - val_R2: 0.9429\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4335 - mae: 1.8576 - mse: 6.5205 - R2: 0.9950\n",
            "Epoch 161: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.4335 - mae: 1.8576 - mse: 6.5205 - R2: 0.9950 - val_loss: 2.7217 - val_mae: 3.1869 - val_mse: 16.9290 - val_R2: 0.9885\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7513 - mae: 2.1899 - mse: 8.2765 - R2: 0.9937\n",
            "Epoch 162: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.7513 - mae: 2.1899 - mse: 8.2765 - R2: 0.9937 - val_loss: 3.1801 - val_mae: 3.6430 - val_mse: 24.1508 - val_R2: 0.9836\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4010 - mae: 1.8294 - mse: 6.5444 - R2: 0.9950\n",
            "Epoch 163: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.4010 - mae: 1.8294 - mse: 6.5444 - R2: 0.9950 - val_loss: 2.3707 - val_mae: 2.8311 - val_mse: 13.3544 - val_R2: 0.9910\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5225 - mae: 1.9535 - mse: 8.4476 - R2: 0.9936\n",
            "Epoch 164: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.5225 - mae: 1.9535 - mse: 8.4476 - R2: 0.9936 - val_loss: 2.6103 - val_mae: 3.0736 - val_mse: 16.3433 - val_R2: 0.9889\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3114 - mae: 1.7344 - mse: 5.4271 - R2: 0.9959\n",
            "Epoch 165: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.3114 - mae: 1.7344 - mse: 5.4271 - R2: 0.9959 - val_loss: 2.6712 - val_mae: 3.1346 - val_mse: 14.9565 - val_R2: 0.9899\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3018 - mae: 1.7216 - mse: 5.7599 - R2: 0.9956\n",
            "Epoch 166: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.3018 - mae: 1.7216 - mse: 5.7599 - R2: 0.9956 - val_loss: 3.6165 - val_mae: 4.0949 - val_mse: 25.8964 - val_R2: 0.9825\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5857 - mae: 2.0159 - mse: 7.5600 - R2: 0.9942\n",
            "Epoch 167: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.5857 - mae: 2.0159 - mse: 7.5600 - R2: 0.9942 - val_loss: 8.7722 - val_mae: 9.2552 - val_mse: 135.8928 - val_R2: 0.9079\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7480 - mae: 2.1860 - mse: 8.5600 - R2: 0.9935\n",
            "Epoch 168: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.7480 - mae: 2.1860 - mse: 8.5600 - R2: 0.9935 - val_loss: 4.2489 - val_mae: 4.7186 - val_mse: 35.7149 - val_R2: 0.9758\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3493 - mae: 2.8012 - mse: 13.5338 - R2: 0.9897\n",
            "Epoch 169: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.3493 - mae: 2.8012 - mse: 13.5338 - R2: 0.9897 - val_loss: 2.3453 - val_mae: 2.7832 - val_mse: 13.8119 - val_R2: 0.9906\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7609 - mae: 2.1857 - mse: 9.6205 - R2: 0.9927\n",
            "Epoch 170: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.7609 - mae: 2.1857 - mse: 9.6205 - R2: 0.9927 - val_loss: 10.0867 - val_mae: 10.5618 - val_mse: 163.9850 - val_R2: 0.8889\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7841 - mae: 2.2163 - mse: 9.6229 - R2: 0.9927\n",
            "Epoch 171: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 6s 446ms/step - loss: 1.7841 - mae: 2.2163 - mse: 9.6229 - R2: 0.9927 - val_loss: 3.7710 - val_mae: 4.2488 - val_mse: 27.5037 - val_R2: 0.9814\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9726 - mae: 2.4043 - mse: 10.9348 - R2: 0.9917\n",
            "Epoch 172: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.9726 - mae: 2.4043 - mse: 10.9348 - R2: 0.9917 - val_loss: 2.3349 - val_mae: 2.8051 - val_mse: 12.0083 - val_R2: 0.9919\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6731 - mae: 2.1137 - mse: 8.6242 - R2: 0.9934\n",
            "Epoch 173: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.6731 - mae: 2.1137 - mse: 8.6242 - R2: 0.9934 - val_loss: 2.3190 - val_mae: 2.7636 - val_mse: 12.3468 - val_R2: 0.9916\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5804 - mae: 2.0100 - mse: 8.2762 - R2: 0.9937\n",
            "Epoch 174: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.5804 - mae: 2.0100 - mse: 8.2762 - R2: 0.9937 - val_loss: 6.0722 - val_mae: 6.5536 - val_mse: 60.8141 - val_R2: 0.9588\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7386 - mae: 2.1713 - mse: 9.7052 - R2: 0.9926 \n",
            "Epoch 175: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.7386 - mae: 2.1713 - mse: 9.7052 - R2: 0.9926 - val_loss: 2.8425 - val_mae: 3.2857 - val_mse: 18.5439 - val_R2: 0.9874\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7548 - mae: 2.1993 - mse: 8.5619 - R2: 0.9935\n",
            "Epoch 176: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.7548 - mae: 2.1993 - mse: 8.5619 - R2: 0.9935 - val_loss: 2.8508 - val_mae: 3.3180 - val_mse: 17.1093 - val_R2: 0.9884\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4234 - mae: 1.8564 - mse: 5.9301 - R2: 0.9955\n",
            "Epoch 177: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.4234 - mae: 1.8564 - mse: 5.9301 - R2: 0.9955 - val_loss: 7.5011 - val_mae: 7.9989 - val_mse: 100.0548 - val_R2: 0.9322\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0189 - mae: 2.4509 - mse: 11.0584 - R2: 0.9916\n",
            "Epoch 178: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 404ms/step - loss: 2.0189 - mae: 2.4509 - mse: 11.0584 - R2: 0.9916 - val_loss: 10.0006 - val_mae: 10.4883 - val_mse: 160.5067 - val_R2: 0.8912\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7841 - mae: 2.2241 - mse: 9.2791 - R2: 0.9929\n",
            "Epoch 179: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.7841 - mae: 2.2241 - mse: 9.2791 - R2: 0.9929 - val_loss: 2.2618 - val_mae: 2.7304 - val_mse: 11.8679 - val_R2: 0.9920\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8100 - mae: 2.2494 - mse: 9.6746 - R2: 0.9926\n",
            "Epoch 180: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.8100 - mae: 2.2494 - mse: 9.6746 - R2: 0.9926 - val_loss: 5.0442 - val_mae: 5.5247 - val_mse: 47.1914 - val_R2: 0.9680\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7993 - mae: 2.2286 - mse: 9.3169 - R2: 0.9929\n",
            "Epoch 181: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.7993 - mae: 2.2286 - mse: 9.3169 - R2: 0.9929 - val_loss: 2.9034 - val_mae: 3.3706 - val_mse: 19.0442 - val_R2: 0.9871\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3708 - mae: 1.7968 - mse: 5.9353 - R2: 0.9955\n",
            "Epoch 182: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.3708 - mae: 1.7968 - mse: 5.9353 - R2: 0.9955 - val_loss: 3.5406 - val_mae: 4.0018 - val_mse: 26.0035 - val_R2: 0.9824\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0879 - mae: 2.5265 - mse: 12.9724 - R2: 0.9901\n",
            "Epoch 183: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.0879 - mae: 2.5265 - mse: 12.9724 - R2: 0.9901 - val_loss: 2.9192 - val_mae: 3.3935 - val_mse: 18.1235 - val_R2: 0.9877\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1093 - mae: 1.5245 - mse: 4.4177 - R2: 0.9966\n",
            "Epoch 184: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 390ms/step - loss: 1.1093 - mae: 1.5245 - mse: 4.4177 - R2: 0.9966 - val_loss: 3.2331 - val_mae: 3.7144 - val_mse: 21.8189 - val_R2: 0.9852\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3539 - mae: 1.7770 - mse: 5.7298 - R2: 0.9956\n",
            "Epoch 185: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 376ms/step - loss: 1.3539 - mae: 1.7770 - mse: 5.7298 - R2: 0.9956 - val_loss: 3.7383 - val_mae: 4.2047 - val_mse: 29.4897 - val_R2: 0.9800\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1736 - mae: 2.6270 - mse: 11.6026 - R2: 0.9911\n",
            "Epoch 186: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.1736 - mae: 2.6270 - mse: 11.6026 - R2: 0.9911 - val_loss: 6.0723 - val_mae: 6.5544 - val_mse: 65.1227 - val_R2: 0.9559\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4478 - mae: 1.8771 - mse: 6.2767 - R2: 0.9952\n",
            "Epoch 187: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 1.4478 - mae: 1.8771 - mse: 6.2767 - R2: 0.9952 - val_loss: 2.4760 - val_mae: 2.9426 - val_mse: 15.1679 - val_R2: 0.9897\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4391 - mae: 1.8661 - mse: 6.4295 - R2: 0.9951\n",
            "Epoch 188: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.4391 - mae: 1.8661 - mse: 6.4295 - R2: 0.9951 - val_loss: 4.0831 - val_mae: 4.5719 - val_mse: 31.2031 - val_R2: 0.9789\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7350 - mae: 2.1595 - mse: 8.9801 - R2: 0.9931\n",
            "Epoch 189: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.7350 - mae: 2.1595 - mse: 8.9801 - R2: 0.9931 - val_loss: 3.0580 - val_mae: 3.5287 - val_mse: 20.2557 - val_R2: 0.9863\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0812 - mae: 2.5276 - mse: 13.1376 - R2: 0.9900\n",
            "Epoch 190: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 409ms/step - loss: 2.0812 - mae: 2.5276 - mse: 13.1376 - R2: 0.9900 - val_loss: 2.7571 - val_mae: 3.2274 - val_mse: 15.4498 - val_R2: 0.9895\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4844 - mae: 1.9108 - mse: 7.4995 - R2: 0.9943\n",
            "Epoch 191: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.4844 - mae: 1.9108 - mse: 7.4995 - R2: 0.9943 - val_loss: 2.7628 - val_mae: 3.2379 - val_mse: 16.7560 - val_R2: 0.9886\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8256 - mae: 2.2606 - mse: 9.4850 - R2: 0.9928\n",
            "Epoch 192: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.8256 - mae: 2.2606 - mse: 9.4850 - R2: 0.9928 - val_loss: 6.4613 - val_mae: 6.9536 - val_mse: 72.2319 - val_R2: 0.9511\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0751 - mae: 2.5236 - mse: 12.5908 - R2: 0.9904\n",
            "Epoch 193: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.0751 - mae: 2.5236 - mse: 12.5908 - R2: 0.9904 - val_loss: 7.1494 - val_mae: 7.6233 - val_mse: 91.1290 - val_R2: 0.9382\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5547 - mae: 1.9937 - mse: 6.7917 - R2: 0.9948\n",
            "Epoch 194: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.5547 - mae: 1.9937 - mse: 6.7917 - R2: 0.9948 - val_loss: 3.3204 - val_mae: 3.7802 - val_mse: 22.3985 - val_R2: 0.9848\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8160 - mae: 2.2459 - mse: 10.7123 - R2: 0.9918\n",
            "Epoch 195: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.8160 - mae: 2.2459 - mse: 10.7123 - R2: 0.9918 - val_loss: 4.4301 - val_mae: 4.9204 - val_mse: 37.0529 - val_R2: 0.9749\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3144 - mae: 1.7274 - mse: 5.5513 - R2: 0.9958\n",
            "Epoch 196: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.3144 - mae: 1.7274 - mse: 5.5513 - R2: 0.9958 - val_loss: 3.0888 - val_mae: 3.5558 - val_mse: 22.3680 - val_R2: 0.9848\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7232 - mae: 2.1631 - mse: 8.2992 - R2: 0.9937\n",
            "Epoch 197: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.7232 - mae: 2.1631 - mse: 8.2992 - R2: 0.9937 - val_loss: 2.9565 - val_mae: 3.4116 - val_mse: 19.9502 - val_R2: 0.9865\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4921 - mae: 1.9264 - mse: 7.2469 - R2: 0.9945\n",
            "Epoch 198: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.4921 - mae: 1.9264 - mse: 7.2469 - R2: 0.9945 - val_loss: 8.1611 - val_mae: 8.6535 - val_mse: 132.6168 - val_R2: 0.9101\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8151 - mae: 2.2468 - mse: 10.3696 - R2: 0.9921\n",
            "Epoch 199: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 378ms/step - loss: 1.8151 - mae: 2.2468 - mse: 10.3696 - R2: 0.9921 - val_loss: 3.3200 - val_mae: 3.7793 - val_mse: 30.6512 - val_R2: 0.9792\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4908 - mae: 1.9165 - mse: 8.1855 - R2: 0.9938\n",
            "Epoch 200: val_loss did not improve from 2.17348\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.4908 - mae: 1.9165 - mse: 8.1855 - R2: 0.9938 - val_loss: 4.0077 - val_mae: 4.4805 - val_mse: 29.9012 - val_R2: 0.9797\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 2.1860 - mae: 2.6396 - mse: 11.4809 - R2: 0.9922\n",
            "Found 389 validated image filenames.\n",
            "Found 97 validated image filenames.\n",
            "Epoch 1/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 32.1059 - mae: 32.6008 - mse: 1935.8024 - R2: -0.4550\n",
            "Epoch 1: val_loss improved from inf to 743.61011, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 24s 561ms/step - loss: 32.1059 - mae: 32.6008 - mse: 1935.8024 - R2: -0.4550 - val_loss: 743.6101 - val_mae: 744.1101 - val_mse: 556686.1250 - val_R2: -399.8012\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 10.9618 - mae: 11.4497 - mse: 278.8591 - R2: 0.7904\n",
            "Epoch 2: val_loss improved from 743.61011 to 118.42737, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 497ms/step - loss: 10.9618 - mae: 11.4497 - mse: 278.8591 - R2: 0.7904 - val_loss: 118.4274 - val_mae: 118.9274 - val_mse: 15436.4824 - val_R2: -10.1139\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 10.0927 - mae: 10.5793 - mse: 198.5096 - R2: 0.8508\n",
            "Epoch 3: val_loss improved from 118.42737 to 114.78268, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 482ms/step - loss: 10.0927 - mae: 10.5793 - mse: 198.5096 - R2: 0.8508 - val_loss: 114.7827 - val_mae: 115.2827 - val_mse: 14610.7588 - val_R2: -9.5194\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 8.4521 - mae: 8.9346 - mse: 141.6962 - R2: 0.8935\n",
            "Epoch 4: val_loss improved from 114.78268 to 33.14284, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 480ms/step - loss: 8.4521 - mae: 8.9346 - mse: 141.6962 - R2: 0.8935 - val_loss: 33.1428 - val_mae: 33.6424 - val_mse: 1524.7529 - val_R2: -0.0978\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 9.0239 - mae: 9.5038 - mse: 154.1391 - R2: 0.8841\n",
            "Epoch 5: val_loss did not improve from 33.14284\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 9.0239 - mae: 9.5038 - mse: 154.1391 - R2: 0.8841 - val_loss: 110.2193 - val_mae: 110.7193 - val_mse: 12867.3301 - val_R2: -8.2642\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 8.4763 - mae: 8.9528 - mse: 160.2454 - R2: 0.8796\n",
            "Epoch 6: val_loss did not improve from 33.14284\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 8.4763 - mae: 8.9528 - mse: 160.2454 - R2: 0.8796 - val_loss: 146.9379 - val_mae: 147.4379 - val_mse: 22250.4785 - val_R2: -15.0199\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.0947 - mae: 6.5767 - mse: 92.1394 - R2: 0.9307\n",
            "Epoch 7: val_loss did not improve from 33.14284\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 6.0947 - mae: 6.5767 - mse: 92.1394 - R2: 0.9307 - val_loss: 153.1702 - val_mae: 153.6702 - val_mse: 25204.7090 - val_R2: -17.1468\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.2377 - mae: 6.7229 - mse: 79.2932 - R2: 0.9404\n",
            "Epoch 8: val_loss did not improve from 33.14284\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 6.2377 - mae: 6.7229 - mse: 79.2932 - R2: 0.9404 - val_loss: 107.1584 - val_mae: 107.6584 - val_mse: 13622.5488 - val_R2: -8.8079\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.5363 - mae: 7.0252 - mse: 90.4498 - R2: 0.9320\n",
            "Epoch 9: val_loss improved from 33.14284 to 25.67064, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 483ms/step - loss: 6.5363 - mae: 7.0252 - mse: 90.4498 - R2: 0.9320 - val_loss: 25.6706 - val_mae: 26.1706 - val_mse: 783.8404 - val_R2: 0.4357\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.1973 - mae: 5.6750 - mse: 62.1719 - R2: 0.9533\n",
            "Epoch 10: val_loss improved from 25.67064 to 17.30496, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 477ms/step - loss: 5.1973 - mae: 5.6750 - mse: 62.1719 - R2: 0.9533 - val_loss: 17.3050 - val_mae: 17.8044 - val_mse: 473.2744 - val_R2: 0.6593\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.6959 - mae: 7.1774 - mse: 90.0882 - R2: 0.9323\n",
            "Epoch 11: val_loss improved from 17.30496 to 11.16944, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 475ms/step - loss: 6.6959 - mae: 7.1774 - mse: 90.0882 - R2: 0.9323 - val_loss: 11.1694 - val_mae: 11.6534 - val_mse: 277.0570 - val_R2: 0.8005\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.4916 - mae: 6.9744 - mse: 85.8759 - R2: 0.9355\n",
            "Epoch 12: val_loss did not improve from 11.16944\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 6.4916 - mae: 6.9744 - mse: 85.8759 - R2: 0.9355 - val_loss: 71.6783 - val_mae: 72.1783 - val_mse: 6632.6719 - val_R2: -3.7754\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.9781 - mae: 5.4483 - mse: 57.8426 - R2: 0.9565\n",
            "Epoch 13: val_loss did not improve from 11.16944\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 4.9781 - mae: 5.4483 - mse: 57.8426 - R2: 0.9565 - val_loss: 11.5548 - val_mae: 12.0427 - val_mse: 266.2994 - val_R2: 0.8083\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.0085 - mae: 7.4930 - mse: 96.4975 - R2: 0.9275\n",
            "Epoch 14: val_loss did not improve from 11.16944\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 7.0085 - mae: 7.4930 - mse: 96.4975 - R2: 0.9275 - val_loss: 13.7631 - val_mae: 14.2594 - val_mse: 302.7258 - val_R2: 0.7820\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.6244 - mae: 6.0980 - mse: 71.6541 - R2: 0.9461\n",
            "Epoch 15: val_loss improved from 11.16944 to 7.03276, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 497ms/step - loss: 5.6244 - mae: 6.0980 - mse: 71.6541 - R2: 0.9461 - val_loss: 7.0328 - val_mae: 7.5152 - val_mse: 88.0581 - val_R2: 0.9366\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.6705 - mae: 6.1500 - mse: 64.4594 - R2: 0.9515\n",
            "Epoch 16: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 5.6705 - mae: 6.1500 - mse: 64.4594 - R2: 0.9515 - val_loss: 12.3720 - val_mae: 12.8688 - val_mse: 230.5722 - val_R2: 0.8340\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2069 - mae: 4.6826 - mse: 39.5885 - R2: 0.9702\n",
            "Epoch 17: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 4.2069 - mae: 4.6826 - mse: 39.5885 - R2: 0.9702 - val_loss: 15.4533 - val_mae: 15.9429 - val_mse: 373.6602 - val_R2: 0.7310\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.7714 - mae: 6.2548 - mse: 76.2726 - R2: 0.9427\n",
            "Epoch 18: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 403ms/step - loss: 5.7714 - mae: 6.2548 - mse: 76.2726 - R2: 0.9427 - val_loss: 11.4981 - val_mae: 11.9842 - val_mse: 277.2389 - val_R2: 0.8004\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.6941 - mae: 6.1758 - mse: 65.5591 - R2: 0.9507\n",
            "Epoch 19: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 5.6941 - mae: 6.1758 - mse: 65.5591 - R2: 0.9507 - val_loss: 7.6245 - val_mae: 8.0961 - val_mse: 111.1591 - val_R2: 0.9200\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.7958 - mae: 6.2692 - mse: 75.4135 - R2: 0.9433\n",
            "Epoch 20: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 5.7958 - mae: 6.2692 - mse: 75.4135 - R2: 0.9433 - val_loss: 14.0854 - val_mae: 14.5737 - val_mse: 302.3283 - val_R2: 0.7823\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.2250 - mae: 5.7037 - mse: 60.6753 - R2: 0.9544\n",
            "Epoch 21: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 5.2250 - mae: 5.7037 - mse: 60.6753 - R2: 0.9544 - val_loss: 8.1881 - val_mae: 8.6786 - val_mse: 141.6461 - val_R2: 0.8980\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.9196 - mae: 5.3971 - mse: 48.9235 - R2: 0.9632\n",
            "Epoch 22: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 4.9196 - mae: 5.3971 - mse: 48.9235 - R2: 0.9632 - val_loss: 9.3917 - val_mae: 9.8853 - val_mse: 145.4122 - val_R2: 0.8953\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.9483 - mae: 6.4179 - mse: 78.1628 - R2: 0.9412\n",
            "Epoch 23: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 5.9483 - mae: 6.4179 - mse: 78.1628 - R2: 0.9412 - val_loss: 13.0828 - val_mae: 13.5622 - val_mse: 281.0255 - val_R2: 0.7977\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.4386 - mae: 5.9106 - mse: 59.7339 - R2: 0.9551\n",
            "Epoch 24: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 5.4386 - mae: 5.9106 - mse: 59.7339 - R2: 0.9551 - val_loss: 45.5918 - val_mae: 46.0836 - val_mse: 3662.7358 - val_R2: -1.6371\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.4090 - mae: 5.8848 - mse: 66.4796 - R2: 0.9500\n",
            "Epoch 25: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 5.4090 - mae: 5.8848 - mse: 66.4796 - R2: 0.9500 - val_loss: 20.6280 - val_mae: 21.1206 - val_mse: 598.3295 - val_R2: 0.5692\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.1238 - mae: 4.5952 - mse: 35.2673 - R2: 0.9735\n",
            "Epoch 26: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 4.1238 - mae: 4.5952 - mse: 35.2673 - R2: 0.9735 - val_loss: 7.6117 - val_mae: 8.0952 - val_mse: 115.9900 - val_R2: 0.9165\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.8441 - mae: 4.3113 - mse: 36.6200 - R2: 0.9725\n",
            "Epoch 27: val_loss did not improve from 7.03276\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.8441 - mae: 4.3113 - mse: 36.6200 - R2: 0.9725 - val_loss: 25.5117 - val_mae: 26.0071 - val_mse: 848.5047 - val_R2: 0.3891\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7260 - mae: 4.1932 - mse: 34.6566 - R2: 0.9740\n",
            "Epoch 28: val_loss improved from 7.03276 to 5.82659, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 479ms/step - loss: 3.7260 - mae: 4.1932 - mse: 34.6566 - R2: 0.9740 - val_loss: 5.8266 - val_mae: 6.3010 - val_mse: 64.0286 - val_R2: 0.9539\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4781 - mae: 3.9420 - mse: 30.5736 - R2: 0.9770\n",
            "Epoch 29: val_loss did not improve from 5.82659\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.4781 - mae: 3.9420 - mse: 30.5736 - R2: 0.9770 - val_loss: 16.6162 - val_mae: 17.0946 - val_mse: 561.3367 - val_R2: 0.5959\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.6390 - mae: 5.1142 - mse: 44.5034 - R2: 0.9665\n",
            "Epoch 30: val_loss did not improve from 5.82659\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 4.6390 - mae: 5.1142 - mse: 44.5034 - R2: 0.9665 - val_loss: 12.5844 - val_mae: 13.0706 - val_mse: 251.3029 - val_R2: 0.8191\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2865 - mae: 4.7607 - mse: 39.6958 - R2: 0.9702\n",
            "Epoch 31: val_loss improved from 5.82659 to 5.18692, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 478ms/step - loss: 4.2865 - mae: 4.7607 - mse: 39.6958 - R2: 0.9702 - val_loss: 5.1869 - val_mae: 5.6693 - val_mse: 50.2230 - val_R2: 0.9638\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.8185 - mae: 6.2974 - mse: 84.4163 - R2: 0.9365\n",
            "Epoch 32: val_loss did not improve from 5.18692\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 5.8185 - mae: 6.2974 - mse: 84.4163 - R2: 0.9365 - val_loss: 5.6189 - val_mae: 6.0975 - val_mse: 71.2743 - val_R2: 0.9487\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7951 - mae: 4.2609 - mse: 35.6122 - R2: 0.9732\n",
            "Epoch 33: val_loss improved from 5.18692 to 4.36024, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 481ms/step - loss: 3.7951 - mae: 4.2609 - mse: 35.6122 - R2: 0.9732 - val_loss: 4.3602 - val_mae: 4.8476 - val_mse: 37.1062 - val_R2: 0.9733\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2068 - mae: 4.6715 - mse: 57.2232 - R2: 0.9570\n",
            "Epoch 34: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 4.2068 - mae: 4.6715 - mse: 57.2232 - R2: 0.9570 - val_loss: 8.4842 - val_mae: 8.9761 - val_mse: 113.6598 - val_R2: 0.9182\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.7599 - mae: 5.2304 - mse: 55.4121 - R2: 0.9584\n",
            "Epoch 35: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 4.7599 - mae: 5.2304 - mse: 55.4121 - R2: 0.9584 - val_loss: 5.7136 - val_mae: 6.1896 - val_mse: 63.6747 - val_R2: 0.9542\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7200 - mae: 4.1656 - mse: 38.2901 - R2: 0.9712\n",
            "Epoch 36: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 3.7200 - mae: 4.1656 - mse: 38.2901 - R2: 0.9712 - val_loss: 24.8624 - val_mae: 25.3546 - val_mse: 949.0902 - val_R2: 0.3167\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.5426 - mae: 4.0073 - mse: 28.8553 - R2: 0.9783\n",
            "Epoch 37: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 3.5426 - mae: 4.0073 - mse: 28.8553 - R2: 0.9783 - val_loss: 24.4325 - val_mae: 24.9184 - val_mse: 932.8163 - val_R2: 0.3284\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.8298 - mae: 4.3041 - mse: 30.0419 - R2: 0.9774\n",
            "Epoch 38: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 3.8298 - mae: 4.3041 - mse: 30.0419 - R2: 0.9774 - val_loss: 9.5728 - val_mae: 10.0651 - val_mse: 135.8813 - val_R2: 0.9022\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9325 - mae: 3.3811 - mse: 22.2673 - R2: 0.9833\n",
            "Epoch 39: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.9325 - mae: 3.3811 - mse: 22.2673 - R2: 0.9833 - val_loss: 22.0048 - val_mae: 22.4972 - val_mse: 778.5502 - val_R2: 0.4395\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6459 - mae: 4.1094 - mse: 33.3114 - R2: 0.9750\n",
            "Epoch 40: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.6459 - mae: 4.1094 - mse: 33.3114 - R2: 0.9750 - val_loss: 7.6768 - val_mae: 8.1496 - val_mse: 95.4410 - val_R2: 0.9313\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6951 - mae: 4.1648 - mse: 31.0868 - R2: 0.9766\n",
            "Epoch 41: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.6951 - mae: 4.1648 - mse: 31.0868 - R2: 0.9766 - val_loss: 6.5667 - val_mae: 7.0489 - val_mse: 79.7311 - val_R2: 0.9426\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.1153 - mae: 4.5831 - mse: 35.5570 - R2: 0.9733\n",
            "Epoch 42: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 4.1153 - mae: 4.5831 - mse: 35.5570 - R2: 0.9733 - val_loss: 6.9101 - val_mae: 7.4016 - val_mse: 74.0439 - val_R2: 0.9467\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9048 - mae: 3.3636 - mse: 22.0580 - R2: 0.9834\n",
            "Epoch 43: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.9048 - mae: 3.3636 - mse: 22.0580 - R2: 0.9834 - val_loss: 15.5993 - val_mae: 16.0944 - val_mse: 380.4586 - val_R2: 0.7261\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.8279 - mae: 4.2947 - mse: 36.4466 - R2: 0.9726\n",
            "Epoch 44: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.8279 - mae: 4.2947 - mse: 36.4466 - R2: 0.9726 - val_loss: 19.5204 - val_mae: 20.0125 - val_mse: 624.9319 - val_R2: 0.5501\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8840 - mae: 3.3400 - mse: 22.1232 - R2: 0.9834\n",
            "Epoch 45: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.8840 - mae: 3.3400 - mse: 22.1232 - R2: 0.9834 - val_loss: 13.9224 - val_mae: 14.4079 - val_mse: 275.3034 - val_R2: 0.8018\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2465 - mae: 3.6990 - mse: 28.7300 - R2: 0.9784\n",
            "Epoch 46: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.2465 - mae: 3.6990 - mse: 28.7300 - R2: 0.9784 - val_loss: 13.1570 - val_mae: 13.6445 - val_mse: 260.6273 - val_R2: 0.8124\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7989 - mae: 3.2618 - mse: 20.2940 - R2: 0.9847\n",
            "Epoch 47: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.7989 - mae: 3.2618 - mse: 20.2940 - R2: 0.9847 - val_loss: 8.6810 - val_mae: 9.1735 - val_mse: 117.3257 - val_R2: 0.9155\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6145 - mae: 3.0652 - mse: 18.6773 - R2: 0.9860\n",
            "Epoch 48: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.6145 - mae: 3.0652 - mse: 18.6773 - R2: 0.9860 - val_loss: 11.2322 - val_mae: 11.7071 - val_mse: 230.7925 - val_R2: 0.8338\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0616 - mae: 3.5223 - mse: 22.4888 - R2: 0.9831\n",
            "Epoch 49: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 3.0616 - mae: 3.5223 - mse: 22.4888 - R2: 0.9831 - val_loss: 13.1702 - val_mae: 13.6625 - val_mse: 253.2306 - val_R2: 0.8177\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1704 - mae: 3.6398 - mse: 23.0299 - R2: 0.9827\n",
            "Epoch 50: val_loss did not improve from 4.36024\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 3.1704 - mae: 3.6398 - mse: 23.0299 - R2: 0.9827 - val_loss: 11.5647 - val_mae: 12.0439 - val_mse: 209.7289 - val_R2: 0.8490\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6271 - mae: 4.0921 - mse: 37.8306 - R2: 0.9716\n",
            "Epoch 51: val_loss improved from 4.36024 to 4.00337, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 479ms/step - loss: 3.6271 - mae: 4.0921 - mse: 37.8306 - R2: 0.9716 - val_loss: 4.0034 - val_mae: 4.4838 - val_mse: 32.0967 - val_R2: 0.9769\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4073 - mae: 2.8571 - mse: 14.6003 - R2: 0.9890\n",
            "Epoch 52: val_loss did not improve from 4.00337\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.4073 - mae: 2.8571 - mse: 14.6003 - R2: 0.9890 - val_loss: 7.6657 - val_mae: 8.1566 - val_mse: 88.5948 - val_R2: 0.9362\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8313 - mae: 3.2977 - mse: 20.2672 - R2: 0.9848\n",
            "Epoch 53: val_loss did not improve from 4.00337\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.8313 - mae: 3.2977 - mse: 20.2672 - R2: 0.9848 - val_loss: 21.8675 - val_mae: 22.3472 - val_mse: 807.3198 - val_R2: 0.4187\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4657 - mae: 3.9313 - mse: 30.3298 - R2: 0.9772\n",
            "Epoch 54: val_loss did not improve from 4.00337\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.4657 - mae: 3.9313 - mse: 30.3298 - R2: 0.9772 - val_loss: 10.6763 - val_mae: 11.1483 - val_mse: 230.4539 - val_R2: 0.8341\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7135 - mae: 3.1624 - mse: 17.8332 - R2: 0.9866\n",
            "Epoch 55: val_loss did not improve from 4.00337\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.7135 - mae: 3.1624 - mse: 17.8332 - R2: 0.9866 - val_loss: 5.9225 - val_mae: 6.4033 - val_mse: 70.0805 - val_R2: 0.9495\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1189 - mae: 3.5853 - mse: 23.7821 - R2: 0.9821\n",
            "Epoch 56: val_loss did not improve from 4.00337\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.1189 - mae: 3.5853 - mse: 23.7821 - R2: 0.9821 - val_loss: 5.2123 - val_mae: 5.6829 - val_mse: 52.1951 - val_R2: 0.9624\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5237 - mae: 2.9784 - mse: 16.1915 - R2: 0.9878\n",
            "Epoch 57: val_loss did not improve from 4.00337\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.5237 - mae: 2.9784 - mse: 16.1915 - R2: 0.9878 - val_loss: 7.5864 - val_mae: 8.0755 - val_mse: 101.9475 - val_R2: 0.9266\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6114 - mae: 3.0693 - mse: 17.5751 - R2: 0.9868\n",
            "Epoch 58: val_loss did not improve from 4.00337\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.6114 - mae: 3.0693 - mse: 17.5751 - R2: 0.9868 - val_loss: 9.3215 - val_mae: 9.8086 - val_mse: 149.0506 - val_R2: 0.8927\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2764 - mae: 2.7311 - mse: 13.3898 - R2: 0.9899\n",
            "Epoch 59: val_loss did not improve from 4.00337\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.2764 - mae: 2.7311 - mse: 13.3898 - R2: 0.9899 - val_loss: 12.4182 - val_mae: 12.8924 - val_mse: 304.8781 - val_R2: 0.7805\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9915 - mae: 3.4592 - mse: 23.6062 - R2: 0.9823\n",
            "Epoch 60: val_loss improved from 4.00337 to 2.74903, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 478ms/step - loss: 2.9915 - mae: 3.4592 - mse: 23.6062 - R2: 0.9823 - val_loss: 2.7490 - val_mae: 3.2078 - val_mse: 16.8269 - val_R2: 0.9879\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3485 - mae: 3.8087 - mse: 25.7409 - R2: 0.9807\n",
            "Epoch 61: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 3.3485 - mae: 3.8087 - mse: 25.7409 - R2: 0.9807 - val_loss: 11.4928 - val_mae: 11.9819 - val_mse: 195.6280 - val_R2: 0.8592\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8005 - mae: 3.2505 - mse: 20.0178 - R2: 0.9850\n",
            "Epoch 62: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.8005 - mae: 3.2505 - mse: 20.0178 - R2: 0.9850 - val_loss: 14.3319 - val_mae: 14.8197 - val_mse: 334.3663 - val_R2: 0.7593\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7397 - mae: 3.2009 - mse: 18.9265 - R2: 0.9858\n",
            "Epoch 63: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 379ms/step - loss: 2.7397 - mae: 3.2009 - mse: 18.9265 - R2: 0.9858 - val_loss: 8.6190 - val_mae: 9.1043 - val_mse: 123.1380 - val_R2: 0.9113\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5135 - mae: 2.9653 - mse: 16.6492 - R2: 0.9875\n",
            "Epoch 64: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 409ms/step - loss: 2.5135 - mae: 2.9653 - mse: 16.6492 - R2: 0.9875 - val_loss: 3.7209 - val_mae: 4.1982 - val_mse: 29.8392 - val_R2: 0.9785\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3456 - mae: 2.7971 - mse: 14.0041 - R2: 0.9895\n",
            "Epoch 65: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 2.3456 - mae: 2.7971 - mse: 14.0041 - R2: 0.9895 - val_loss: 5.6680 - val_mae: 6.1421 - val_mse: 59.2517 - val_R2: 0.9573\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9511 - mae: 3.4089 - mse: 21.6306 - R2: 0.9837\n",
            "Epoch 66: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.9511 - mae: 3.4089 - mse: 21.6306 - R2: 0.9837 - val_loss: 4.7033 - val_mae: 5.1861 - val_mse: 42.3819 - val_R2: 0.9695\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5942 - mae: 3.0545 - mse: 17.3497 - R2: 0.9870\n",
            "Epoch 67: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.5942 - mae: 3.0545 - mse: 17.3497 - R2: 0.9870 - val_loss: 5.7344 - val_mae: 6.2024 - val_mse: 60.1110 - val_R2: 0.9567\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9095 - mae: 3.3704 - mse: 20.0656 - R2: 0.9849\n",
            "Epoch 68: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 395ms/step - loss: 2.9095 - mae: 3.3704 - mse: 20.0656 - R2: 0.9849 - val_loss: 13.7551 - val_mae: 14.2410 - val_mse: 338.1163 - val_R2: 0.7566\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5925 - mae: 3.0434 - mse: 19.4474 - R2: 0.9854\n",
            "Epoch 69: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.5925 - mae: 3.0434 - mse: 19.4474 - R2: 0.9854 - val_loss: 7.2367 - val_mae: 7.7142 - val_mse: 102.3871 - val_R2: 0.9263\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1254 - mae: 2.5740 - mse: 11.5967 - R2: 0.9913\n",
            "Epoch 70: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.1254 - mae: 2.5740 - mse: 11.5967 - R2: 0.9913 - val_loss: 9.6965 - val_mae: 10.1828 - val_mse: 132.1290 - val_R2: 0.9049\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5477 - mae: 2.9952 - mse: 19.7411 - R2: 0.9852\n",
            "Epoch 71: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.5477 - mae: 2.9952 - mse: 19.7411 - R2: 0.9852 - val_loss: 5.3825 - val_mae: 5.8620 - val_mse: 53.1759 - val_R2: 0.9617\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8198 - mae: 3.2788 - mse: 20.1673 - R2: 0.9848\n",
            "Epoch 72: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.8198 - mae: 3.2788 - mse: 20.1673 - R2: 0.9848 - val_loss: 5.5197 - val_mae: 5.9774 - val_mse: 58.2239 - val_R2: 0.9581\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1038 - mae: 3.5644 - mse: 21.1000 - R2: 0.9841\n",
            "Epoch 73: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.1038 - mae: 3.5644 - mse: 21.1000 - R2: 0.9841 - val_loss: 9.9916 - val_mae: 10.4826 - val_mse: 141.0038 - val_R2: 0.8985\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7281 - mae: 3.1814 - mse: 20.1228 - R2: 0.9849\n",
            "Epoch 74: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 2.7281 - mae: 3.1814 - mse: 20.1228 - R2: 0.9849 - val_loss: 7.1263 - val_mae: 7.6045 - val_mse: 97.5494 - val_R2: 0.9298\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4669 - mae: 2.9286 - mse: 14.5556 - R2: 0.9891\n",
            "Epoch 75: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 2.4669 - mae: 2.9286 - mse: 14.5556 - R2: 0.9891 - val_loss: 3.2493 - val_mae: 3.7269 - val_mse: 22.6082 - val_R2: 0.9837\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2402 - mae: 2.6973 - mse: 14.3327 - R2: 0.9892\n",
            "Epoch 76: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.2402 - mae: 2.6973 - mse: 14.3327 - R2: 0.9892 - val_loss: 10.8058 - val_mae: 11.2941 - val_mse: 180.1904 - val_R2: 0.8703\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9856 - mae: 2.4183 - mse: 10.6097 - R2: 0.9920\n",
            "Epoch 77: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.9856 - mae: 2.4183 - mse: 10.6097 - R2: 0.9920 - val_loss: 12.5408 - val_mae: 13.0376 - val_mse: 212.6767 - val_R2: 0.8469\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8298 - mae: 3.2867 - mse: 19.5569 - R2: 0.9853\n",
            "Epoch 78: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 402ms/step - loss: 2.8298 - mae: 3.2867 - mse: 19.5569 - R2: 0.9853 - val_loss: 8.5475 - val_mae: 9.0472 - val_mse: 102.6574 - val_R2: 0.9261\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2133 - mae: 2.6604 - mse: 13.2780 - R2: 0.9900\n",
            "Epoch 79: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.2133 - mae: 2.6604 - mse: 13.2780 - R2: 0.9900 - val_loss: 6.6383 - val_mae: 7.1200 - val_mse: 73.8006 - val_R2: 0.9469\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2691 - mae: 2.7171 - mse: 13.6828 - R2: 0.9897\n",
            "Epoch 80: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 404ms/step - loss: 2.2691 - mae: 2.7171 - mse: 13.6828 - R2: 0.9897 - val_loss: 2.7598 - val_mae: 3.2128 - val_mse: 17.6802 - val_R2: 0.9873\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9690 - mae: 2.4089 - mse: 10.8820 - R2: 0.9918\n",
            "Epoch 81: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.9690 - mae: 2.4089 - mse: 10.8820 - R2: 0.9918 - val_loss: 13.4354 - val_mae: 13.9219 - val_mse: 309.7441 - val_R2: 0.7770\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8107 - mae: 3.2703 - mse: 18.2608 - R2: 0.9863\n",
            "Epoch 82: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.8107 - mae: 3.2703 - mse: 18.2608 - R2: 0.9863 - val_loss: 10.6689 - val_mae: 11.1527 - val_mse: 203.3937 - val_R2: 0.8536\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2716 - mae: 2.7105 - mse: 13.6803 - R2: 0.9897\n",
            "Epoch 83: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.2716 - mae: 2.7105 - mse: 13.6803 - R2: 0.9897 - val_loss: 10.1710 - val_mae: 10.6507 - val_mse: 161.3484 - val_R2: 0.8838\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0635 - mae: 3.5297 - mse: 21.6240 - R2: 0.9837\n",
            "Epoch 84: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 3.0635 - mae: 3.5297 - mse: 21.6240 - R2: 0.9837 - val_loss: 12.2413 - val_mae: 12.7199 - val_mse: 255.4907 - val_R2: 0.8161\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9180 - mae: 2.3547 - mse: 10.5529 - R2: 0.9921\n",
            "Epoch 85: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.9180 - mae: 2.3547 - mse: 10.5529 - R2: 0.9921 - val_loss: 4.0428 - val_mae: 4.5238 - val_mse: 30.7055 - val_R2: 0.9779\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5606 - mae: 3.0092 - mse: 17.8827 - R2: 0.9866\n",
            "Epoch 86: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 405ms/step - loss: 2.5606 - mae: 3.0092 - mse: 17.8827 - R2: 0.9866 - val_loss: 8.9328 - val_mae: 9.4233 - val_mse: 119.2568 - val_R2: 0.9141\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8766 - mae: 2.3054 - mse: 10.8224 - R2: 0.9919\n",
            "Epoch 87: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 405ms/step - loss: 1.8766 - mae: 2.3054 - mse: 10.8224 - R2: 0.9919 - val_loss: 4.1082 - val_mae: 4.5750 - val_mse: 34.3938 - val_R2: 0.9752\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3051 - mae: 2.7612 - mse: 14.0081 - R2: 0.9895\n",
            "Epoch 88: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.3051 - mae: 2.7612 - mse: 14.0081 - R2: 0.9895 - val_loss: 7.9881 - val_mae: 8.4633 - val_mse: 98.2302 - val_R2: 0.9293\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1235 - mae: 2.5629 - mse: 15.8181 - R2: 0.9881\n",
            "Epoch 89: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.1235 - mae: 2.5629 - mse: 15.8181 - R2: 0.9881 - val_loss: 3.8576 - val_mae: 4.3287 - val_mse: 35.3364 - val_R2: 0.9746\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1235 - mae: 2.5673 - mse: 12.8396 - R2: 0.9903\n",
            "Epoch 90: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.1235 - mae: 2.5673 - mse: 12.8396 - R2: 0.9903 - val_loss: 9.7230 - val_mae: 10.1974 - val_mse: 169.1824 - val_R2: 0.8782\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2025 - mae: 2.6418 - mse: 13.2315 - R2: 0.9901\n",
            "Epoch 91: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 2.2025 - mae: 2.6418 - mse: 13.2315 - R2: 0.9901 - val_loss: 7.9073 - val_mae: 8.3810 - val_mse: 102.4823 - val_R2: 0.9262\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9055 - mae: 2.3533 - mse: 10.7641 - R2: 0.9919\n",
            "Epoch 92: val_loss did not improve from 2.74903\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.9055 - mae: 2.3533 - mse: 10.7641 - R2: 0.9919 - val_loss: 3.0006 - val_mae: 3.4546 - val_mse: 20.0010 - val_R2: 0.9856\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3960 - mae: 2.8398 - mse: 18.2599 - R2: 0.9863\n",
            "Epoch 93: val_loss improved from 2.74903 to 2.72908, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 480ms/step - loss: 2.3960 - mae: 2.8398 - mse: 18.2599 - R2: 0.9863 - val_loss: 2.7291 - val_mae: 3.2101 - val_mse: 15.5273 - val_R2: 0.9888\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1619 - mae: 2.6108 - mse: 12.0833 - R2: 0.9909\n",
            "Epoch 94: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 377ms/step - loss: 2.1619 - mae: 2.6108 - mse: 12.0833 - R2: 0.9909 - val_loss: 14.0862 - val_mae: 14.5697 - val_mse: 307.8935 - val_R2: 0.7783\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9416 - mae: 2.3904 - mse: 10.5166 - R2: 0.9921\n",
            "Epoch 95: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.9416 - mae: 2.3904 - mse: 10.5166 - R2: 0.9921 - val_loss: 7.5367 - val_mae: 8.0040 - val_mse: 97.6171 - val_R2: 0.9297\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4109 - mae: 2.8624 - mse: 14.9040 - R2: 0.9888\n",
            "Epoch 96: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 400ms/step - loss: 2.4109 - mae: 2.8624 - mse: 14.9040 - R2: 0.9888 - val_loss: 3.7456 - val_mae: 4.2242 - val_mse: 27.0568 - val_R2: 0.9805\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7758 - mae: 2.2095 - mse: 9.4694 - R2: 0.9929\n",
            "Epoch 97: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.7758 - mae: 2.2095 - mse: 9.4694 - R2: 0.9929 - val_loss: 3.7177 - val_mae: 4.1941 - val_mse: 27.1178 - val_R2: 0.9805\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1170 - mae: 2.5631 - mse: 12.5657 - R2: 0.9906\n",
            "Epoch 98: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.1170 - mae: 2.5631 - mse: 12.5657 - R2: 0.9906 - val_loss: 15.7882 - val_mae: 16.2796 - val_mse: 363.4091 - val_R2: 0.7384\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0135 - mae: 2.4638 - mse: 10.7454 - R2: 0.9919\n",
            "Epoch 99: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 2.0135 - mae: 2.4638 - mse: 10.7454 - R2: 0.9919 - val_loss: 20.0058 - val_mae: 20.5007 - val_mse: 618.2045 - val_R2: 0.5549\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9237 - mae: 2.3709 - mse: 10.4035 - R2: 0.9922\n",
            "Epoch 100: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.9237 - mae: 2.3709 - mse: 10.4035 - R2: 0.9922 - val_loss: 6.2414 - val_mae: 6.7204 - val_mse: 82.0069 - val_R2: 0.9410\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7612 - mae: 2.1896 - mse: 11.3190 - R2: 0.9915\n",
            "Epoch 101: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.7612 - mae: 2.1896 - mse: 11.3190 - R2: 0.9915 - val_loss: 7.7803 - val_mae: 8.2677 - val_mse: 112.1811 - val_R2: 0.9192\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6724 - mae: 2.1041 - mse: 8.2540 - R2: 0.9938\n",
            "Epoch 102: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.6724 - mae: 2.1041 - mse: 8.2540 - R2: 0.9938 - val_loss: 8.6191 - val_mae: 9.1107 - val_mse: 122.0290 - val_R2: 0.9121\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8684 - mae: 2.3172 - mse: 9.3892 - R2: 0.9929\n",
            "Epoch 103: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 403ms/step - loss: 1.8684 - mae: 2.3172 - mse: 9.3892 - R2: 0.9929 - val_loss: 10.7998 - val_mae: 11.2968 - val_mse: 212.8488 - val_R2: 0.8468\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7098 - mae: 2.1424 - mse: 8.5721 - R2: 0.9936\n",
            "Epoch 104: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.7098 - mae: 2.1424 - mse: 8.5721 - R2: 0.9936 - val_loss: 9.0657 - val_mae: 9.5509 - val_mse: 176.5824 - val_R2: 0.8729\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9091 - mae: 2.3478 - mse: 15.2537 - R2: 0.9885\n",
            "Epoch 105: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.9091 - mae: 2.3478 - mse: 15.2537 - R2: 0.9885 - val_loss: 10.3305 - val_mae: 10.8278 - val_mse: 181.9805 - val_R2: 0.8690\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5781 - mae: 2.0048 - mse: 7.6825 - R2: 0.9942\n",
            "Epoch 106: val_loss did not improve from 2.72908\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.5781 - mae: 2.0048 - mse: 7.6825 - R2: 0.9942 - val_loss: 9.0312 - val_mae: 9.5199 - val_mse: 137.7436 - val_R2: 0.9008\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9720 - mae: 2.4132 - mse: 11.9377 - R2: 0.9910\n",
            "Epoch 107: val_loss improved from 2.72908 to 2.64977, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 481ms/step - loss: 1.9720 - mae: 2.4132 - mse: 11.9377 - R2: 0.9910 - val_loss: 2.6498 - val_mae: 3.1108 - val_mse: 16.3509 - val_R2: 0.9882\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1287 - mae: 2.5815 - mse: 11.8398 - R2: 0.9911\n",
            "Epoch 108: val_loss did not improve from 2.64977\n",
            "13/13 [==============================] - 5s 402ms/step - loss: 2.1287 - mae: 2.5815 - mse: 11.8398 - R2: 0.9911 - val_loss: 10.8575 - val_mae: 11.3299 - val_mse: 200.9657 - val_R2: 0.8553\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7240 - mae: 2.1636 - mse: 8.2959 - R2: 0.9938\n",
            "Epoch 109: val_loss did not improve from 2.64977\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.7240 - mae: 2.1636 - mse: 8.2959 - R2: 0.9938 - val_loss: 12.8627 - val_mae: 13.3537 - val_mse: 253.7604 - val_R2: 0.8173\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8269 - mae: 2.2518 - mse: 10.5087 - R2: 0.9921\n",
            "Epoch 110: val_loss did not improve from 2.64977\n",
            "13/13 [==============================] - 5s 427ms/step - loss: 1.8269 - mae: 2.2518 - mse: 10.5087 - R2: 0.9921 - val_loss: 9.7394 - val_mae: 10.2304 - val_mse: 137.8348 - val_R2: 0.9008\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7445 - mae: 2.1847 - mse: 8.3885 - R2: 0.9937\n",
            "Epoch 111: val_loss did not improve from 2.64977\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.7445 - mae: 2.1847 - mse: 8.3885 - R2: 0.9937 - val_loss: 4.4103 - val_mae: 4.8902 - val_mse: 36.5591 - val_R2: 0.9737\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1238 - mae: 2.5616 - mse: 13.3545 - R2: 0.9900\n",
            "Epoch 112: val_loss did not improve from 2.64977\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 2.1238 - mae: 2.5616 - mse: 13.3545 - R2: 0.9900 - val_loss: 3.5018 - val_mae: 3.9729 - val_mse: 26.0042 - val_R2: 0.9813\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6274 - mae: 2.0648 - mse: 7.5879 - R2: 0.9943\n",
            "Epoch 113: val_loss did not improve from 2.64977\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.6274 - mae: 2.0648 - mse: 7.5879 - R2: 0.9943 - val_loss: 4.4150 - val_mae: 4.8892 - val_mse: 35.1331 - val_R2: 0.9747\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6930 - mae: 2.1163 - mse: 8.8737 - R2: 0.9933\n",
            "Epoch 114: val_loss improved from 2.64977 to 2.54793, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 480ms/step - loss: 1.6930 - mae: 2.1163 - mse: 8.8737 - R2: 0.9933 - val_loss: 2.5479 - val_mae: 3.0073 - val_mse: 14.5758 - val_R2: 0.9895\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9009 - mae: 2.3355 - mse: 10.0245 - R2: 0.9925\n",
            "Epoch 115: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.9009 - mae: 2.3355 - mse: 10.0245 - R2: 0.9925 - val_loss: 3.6555 - val_mae: 4.1202 - val_mse: 28.2230 - val_R2: 0.9797\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9581 - mae: 2.4071 - mse: 9.9431 - R2: 0.9925 \n",
            "Epoch 116: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.9581 - mae: 2.4071 - mse: 9.9431 - R2: 0.9925 - val_loss: 9.9210 - val_mae: 10.4172 - val_mse: 154.9537 - val_R2: 0.8884\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0463 - mae: 2.4986 - mse: 11.6271 - R2: 0.9913\n",
            "Epoch 117: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.0463 - mae: 2.4986 - mse: 11.6271 - R2: 0.9913 - val_loss: 4.5265 - val_mae: 4.9966 - val_mse: 39.4399 - val_R2: 0.9716\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3441 - mae: 2.7922 - mse: 16.9895 - R2: 0.9872\n",
            "Epoch 118: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 2.3441 - mae: 2.7922 - mse: 16.9895 - R2: 0.9872 - val_loss: 16.1871 - val_mae: 16.6723 - val_mse: 474.5640 - val_R2: 0.6583\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0644 - mae: 2.5186 - mse: 12.1642 - R2: 0.9909\n",
            "Epoch 119: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.0644 - mae: 2.5186 - mse: 12.1642 - R2: 0.9909 - val_loss: 9.9424 - val_mae: 10.4311 - val_mse: 157.2658 - val_R2: 0.8868\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1542 - mae: 2.5971 - mse: 11.3693 - R2: 0.9915\n",
            "Epoch 120: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 402ms/step - loss: 2.1542 - mae: 2.5971 - mse: 11.3693 - R2: 0.9915 - val_loss: 4.6851 - val_mae: 5.1577 - val_mse: 44.4215 - val_R2: 0.9680\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8582 - mae: 2.2831 - mse: 9.8874 - R2: 0.9926 \n",
            "Epoch 121: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.8582 - mae: 2.2831 - mse: 9.8874 - R2: 0.9926 - val_loss: 8.1842 - val_mae: 8.6769 - val_mse: 135.4051 - val_R2: 0.9025\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5603 - mae: 1.9947 - mse: 7.7816 - R2: 0.9942\n",
            "Epoch 122: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.5603 - mae: 1.9947 - mse: 7.7816 - R2: 0.9942 - val_loss: 11.7293 - val_mae: 12.2073 - val_mse: 205.2495 - val_R2: 0.8522\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3584 - mae: 2.8126 - mse: 13.8470 - R2: 0.9896\n",
            "Epoch 123: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.3584 - mae: 2.8126 - mse: 13.8470 - R2: 0.9896 - val_loss: 15.0341 - val_mae: 15.5331 - val_mse: 306.2159 - val_R2: 0.7795\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6708 - mae: 2.1064 - mse: 7.8651 - R2: 0.9941\n",
            "Epoch 124: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.6708 - mae: 2.1064 - mse: 7.8651 - R2: 0.9941 - val_loss: 15.8916 - val_mae: 16.3863 - val_mse: 398.8369 - val_R2: 0.7128\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2154 - mae: 2.6522 - mse: 13.6508 - R2: 0.9897\n",
            "Epoch 125: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 408ms/step - loss: 2.2154 - mae: 2.6522 - mse: 13.6508 - R2: 0.9897 - val_loss: 10.1067 - val_mae: 10.5820 - val_mse: 198.5358 - val_R2: 0.8571\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4200 - mae: 1.8458 - mse: 6.5098 - R2: 0.9951\n",
            "Epoch 126: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.4200 - mae: 1.8458 - mse: 6.5098 - R2: 0.9951 - val_loss: 8.9966 - val_mae: 9.4724 - val_mse: 145.5965 - val_R2: 0.8952\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3415 - mae: 1.7660 - mse: 6.1518 - R2: 0.9954\n",
            "Epoch 127: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.3415 - mae: 1.7660 - mse: 6.1518 - R2: 0.9954 - val_loss: 3.3536 - val_mae: 3.8234 - val_mse: 23.1420 - val_R2: 0.9833\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7373 - mae: 2.1758 - mse: 8.7319 - R2: 0.9934\n",
            "Epoch 128: val_loss did not improve from 2.54793\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.7373 - mae: 2.1758 - mse: 8.7319 - R2: 0.9934 - val_loss: 7.5134 - val_mae: 8.0067 - val_mse: 86.4988 - val_R2: 0.9377\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4348 - mae: 1.8729 - mse: 6.4725 - R2: 0.9951\n",
            "Epoch 129: val_loss improved from 2.54793 to 2.54600, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 500ms/step - loss: 1.4348 - mae: 1.8729 - mse: 6.4725 - R2: 0.9951 - val_loss: 2.5460 - val_mae: 3.0123 - val_mse: 15.2104 - val_R2: 0.9890\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2968 - mae: 1.7228 - mse: 5.5718 - R2: 0.9958\n",
            "Epoch 130: val_loss did not improve from 2.54600\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.2968 - mae: 1.7228 - mse: 5.5718 - R2: 0.9958 - val_loss: 2.6069 - val_mae: 3.0668 - val_mse: 16.4874 - val_R2: 0.9881\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6367 - mae: 2.0674 - mse: 7.8745 - R2: 0.9941\n",
            "Epoch 131: val_loss did not improve from 2.54600\n",
            "13/13 [==============================] - 5s 404ms/step - loss: 1.6367 - mae: 2.0674 - mse: 7.8745 - R2: 0.9941 - val_loss: 4.3534 - val_mae: 4.8374 - val_mse: 33.8245 - val_R2: 0.9756\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3684 - mae: 1.7785 - mse: 7.0004 - R2: 0.9947\n",
            "Epoch 132: val_loss did not improve from 2.54600\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.3684 - mae: 1.7785 - mse: 7.0004 - R2: 0.9947 - val_loss: 4.6453 - val_mae: 5.1282 - val_mse: 44.0946 - val_R2: 0.9683\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8215 - mae: 2.2631 - mse: 9.3266 - R2: 0.9930\n",
            "Epoch 133: val_loss improved from 2.54600 to 2.01121, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 476ms/step - loss: 1.8215 - mae: 2.2631 - mse: 9.3266 - R2: 0.9930 - val_loss: 2.0112 - val_mae: 2.4539 - val_mse: 11.8221 - val_R2: 0.9915\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6650 - mae: 2.1025 - mse: 7.9756 - R2: 0.9940\n",
            "Epoch 134: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 403ms/step - loss: 1.6650 - mae: 2.1025 - mse: 7.9756 - R2: 0.9940 - val_loss: 23.3485 - val_mae: 23.8409 - val_mse: 812.5121 - val_R2: 0.4150\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9099 - mae: 2.3554 - mse: 10.0431 - R2: 0.9925\n",
            "Epoch 135: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.9099 - mae: 2.3554 - mse: 10.0431 - R2: 0.9925 - val_loss: 6.7834 - val_mae: 7.2691 - val_mse: 81.4451 - val_R2: 0.9414\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5895 - mae: 2.0179 - mse: 8.1496 - R2: 0.9939\n",
            "Epoch 136: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 404ms/step - loss: 1.5895 - mae: 2.0179 - mse: 8.1496 - R2: 0.9939 - val_loss: 3.1080 - val_mae: 3.5608 - val_mse: 20.9894 - val_R2: 0.9849\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3947 - mae: 1.8275 - mse: 5.9548 - R2: 0.9955\n",
            "Epoch 137: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.3947 - mae: 1.8275 - mse: 5.9548 - R2: 0.9955 - val_loss: 6.7903 - val_mae: 7.2630 - val_mse: 80.9354 - val_R2: 0.9417\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3966 - mae: 1.8162 - mse: 5.9202 - R2: 0.9956\n",
            "Epoch 138: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.3966 - mae: 1.8162 - mse: 5.9202 - R2: 0.9956 - val_loss: 10.9143 - val_mae: 11.4079 - val_mse: 194.7815 - val_R2: 0.8598\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4502 - mae: 1.8888 - mse: 6.2398 - R2: 0.9953\n",
            "Epoch 139: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.4502 - mae: 1.8888 - mse: 6.2398 - R2: 0.9953 - val_loss: 8.9769 - val_mae: 9.4528 - val_mse: 211.5684 - val_R2: 0.8477\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2856 - mae: 1.7114 - mse: 5.4205 - R2: 0.9959\n",
            "Epoch 140: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 405ms/step - loss: 1.2856 - mae: 1.7114 - mse: 5.4205 - R2: 0.9959 - val_loss: 6.9140 - val_mae: 7.4025 - val_mse: 84.8582 - val_R2: 0.9389\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7632 - mae: 2.1986 - mse: 10.0927 - R2: 0.9924\n",
            "Epoch 141: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.7632 - mae: 2.1986 - mse: 10.0927 - R2: 0.9924 - val_loss: 6.8553 - val_mae: 7.3283 - val_mse: 91.0906 - val_R2: 0.9344\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6194 - mae: 2.0314 - mse: 9.0763 - R2: 0.9932\n",
            "Epoch 142: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.6194 - mae: 2.0314 - mse: 9.0763 - R2: 0.9932 - val_loss: 5.2020 - val_mae: 5.6961 - val_mse: 46.6179 - val_R2: 0.9664\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2989 - mae: 1.7301 - mse: 5.5551 - R2: 0.9958\n",
            "Epoch 143: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.2989 - mae: 1.7301 - mse: 5.5551 - R2: 0.9958 - val_loss: 6.1021 - val_mae: 6.5800 - val_mse: 74.0635 - val_R2: 0.9467\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2661 - mae: 1.6998 - mse: 5.1851 - R2: 0.9961\n",
            "Epoch 144: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.2661 - mae: 1.6998 - mse: 5.1851 - R2: 0.9961 - val_loss: 3.9908 - val_mae: 4.4747 - val_mse: 33.2735 - val_R2: 0.9760\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3927 - mae: 1.8269 - mse: 5.9395 - R2: 0.9955\n",
            "Epoch 145: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.3927 - mae: 1.8269 - mse: 5.9395 - R2: 0.9955 - val_loss: 17.5740 - val_mae: 18.0654 - val_mse: 428.3714 - val_R2: 0.6916\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5255 - mae: 1.9571 - mse: 8.7833 - R2: 0.9934\n",
            "Epoch 146: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.5255 - mae: 1.9571 - mse: 8.7833 - R2: 0.9934 - val_loss: 7.4681 - val_mae: 7.9605 - val_mse: 84.0005 - val_R2: 0.9395\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6715 - mae: 2.0927 - mse: 7.9531 - R2: 0.9940\n",
            "Epoch 147: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.6715 - mae: 2.0927 - mse: 7.9531 - R2: 0.9940 - val_loss: 3.2714 - val_mae: 3.7383 - val_mse: 22.6985 - val_R2: 0.9837\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3071 - mae: 1.7266 - mse: 5.9161 - R2: 0.9956\n",
            "Epoch 148: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.3071 - mae: 1.7266 - mse: 5.9161 - R2: 0.9956 - val_loss: 6.1071 - val_mae: 6.5944 - val_mse: 68.3639 - val_R2: 0.9508\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7228 - mae: 2.1419 - mse: 8.8511 - R2: 0.9933\n",
            "Epoch 149: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.7228 - mae: 2.1419 - mse: 8.8511 - R2: 0.9933 - val_loss: 7.3194 - val_mae: 7.8084 - val_mse: 82.0707 - val_R2: 0.9409\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6244 - mae: 2.0463 - mse: 8.0621 - R2: 0.9939\n",
            "Epoch 150: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.6244 - mae: 2.0463 - mse: 8.0621 - R2: 0.9939 - val_loss: 3.4080 - val_mae: 3.8749 - val_mse: 23.8723 - val_R2: 0.9828\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3058 - mae: 1.7182 - mse: 5.5241 - R2: 0.9958\n",
            "Epoch 151: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.3058 - mae: 1.7182 - mse: 5.5241 - R2: 0.9958 - val_loss: 4.0990 - val_mae: 4.5814 - val_mse: 35.1529 - val_R2: 0.9747\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8949 - mae: 2.3322 - mse: 10.2440 - R2: 0.9923\n",
            "Epoch 152: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.8949 - mae: 2.3322 - mse: 10.2440 - R2: 0.9923 - val_loss: 13.0237 - val_mae: 13.5111 - val_mse: 281.4954 - val_R2: 0.7973\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2000 - mae: 1.6283 - mse: 4.7401 - R2: 0.9964\n",
            "Epoch 153: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.2000 - mae: 1.6283 - mse: 4.7401 - R2: 0.9964 - val_loss: 10.7647 - val_mae: 11.2512 - val_mse: 186.2160 - val_R2: 0.8659\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4523 - mae: 1.8714 - mse: 6.5476 - R2: 0.9951\n",
            "Epoch 154: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.4523 - mae: 1.8714 - mse: 6.5476 - R2: 0.9951 - val_loss: 5.4664 - val_mae: 5.9313 - val_mse: 58.5445 - val_R2: 0.9578\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3687 - mae: 1.7915 - mse: 6.1104 - R2: 0.9954\n",
            "Epoch 155: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.3687 - mae: 1.7915 - mse: 6.1104 - R2: 0.9954 - val_loss: 9.6961 - val_mae: 10.1834 - val_mse: 196.8023 - val_R2: 0.8583\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7683 - mae: 2.1993 - mse: 10.1855 - R2: 0.9923\n",
            "Epoch 156: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.7683 - mae: 2.1993 - mse: 10.1855 - R2: 0.9923 - val_loss: 8.0180 - val_mae: 8.5064 - val_mse: 97.9832 - val_R2: 0.9295\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1034 - mae: 1.4991 - mse: 4.9161 - R2: 0.9963\n",
            "Epoch 157: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.1034 - mae: 1.4991 - mse: 4.9161 - R2: 0.9963 - val_loss: 7.7426 - val_mae: 8.2374 - val_mse: 127.2187 - val_R2: 0.9084\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5738 - mae: 2.0056 - mse: 7.8278 - R2: 0.9941\n",
            "Epoch 158: val_loss did not improve from 2.01121\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.5738 - mae: 2.0056 - mse: 7.8278 - R2: 0.9941 - val_loss: 4.0102 - val_mae: 4.4826 - val_mse: 36.7156 - val_R2: 0.9736\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5877 - mae: 2.0133 - mse: 8.5499 - R2: 0.9936\n",
            "Epoch 159: val_loss improved from 2.01121 to 1.97540, saving model to saved_models/ResNet_0deg_withTL/resnet_4.h5\n",
            "13/13 [==============================] - 6s 479ms/step - loss: 1.5877 - mae: 2.0133 - mse: 8.5499 - R2: 0.9936 - val_loss: 1.9754 - val_mae: 2.4445 - val_mse: 10.0173 - val_R2: 0.9928\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3925 - mae: 1.8059 - mse: 6.4335 - R2: 0.9952\n",
            "Epoch 160: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.3925 - mae: 1.8059 - mse: 6.4335 - R2: 0.9952 - val_loss: 8.2034 - val_mae: 8.6874 - val_mse: 149.7612 - val_R2: 0.8922\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5647 - mae: 1.9923 - mse: 9.4146 - R2: 0.9929\n",
            "Epoch 161: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.5647 - mae: 1.9923 - mse: 9.4146 - R2: 0.9929 - val_loss: 9.0809 - val_mae: 9.5582 - val_mse: 174.3923 - val_R2: 0.8744\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5547 - mae: 1.9826 - mse: 7.6988 - R2: 0.9942\n",
            "Epoch 162: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.5547 - mae: 1.9826 - mse: 7.6988 - R2: 0.9942 - val_loss: 2.9321 - val_mae: 3.4131 - val_mse: 19.5742 - val_R2: 0.9859\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2461 - mae: 1.6743 - mse: 5.0251 - R2: 0.9962\n",
            "Epoch 163: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.2461 - mae: 1.6743 - mse: 5.0251 - R2: 0.9962 - val_loss: 2.6841 - val_mae: 3.1638 - val_mse: 17.1386 - val_R2: 0.9877\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1958 - mae: 1.6201 - mse: 4.7738 - R2: 0.9964\n",
            "Epoch 164: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.1958 - mae: 1.6201 - mse: 4.7738 - R2: 0.9964 - val_loss: 4.3897 - val_mae: 4.8365 - val_mse: 40.0282 - val_R2: 0.9712\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5379 - mae: 1.9567 - mse: 8.1509 - R2: 0.9939\n",
            "Epoch 165: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.5379 - mae: 1.9567 - mse: 8.1509 - R2: 0.9939 - val_loss: 6.4486 - val_mae: 6.9381 - val_mse: 75.9177 - val_R2: 0.9453\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2061 - mae: 1.6043 - mse: 5.3799 - R2: 0.9960\n",
            "Epoch 166: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.2061 - mae: 1.6043 - mse: 5.3799 - R2: 0.9960 - val_loss: 3.9739 - val_mae: 4.4494 - val_mse: 34.7630 - val_R2: 0.9750\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4176 - mae: 1.8577 - mse: 6.2903 - R2: 0.9953\n",
            "Epoch 167: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 390ms/step - loss: 1.4176 - mae: 1.8577 - mse: 6.2903 - R2: 0.9953 - val_loss: 12.7475 - val_mae: 13.2300 - val_mse: 233.5174 - val_R2: 0.8319\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6225 - mae: 2.0514 - mse: 8.0441 - R2: 0.9940\n",
            "Epoch 168: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.6225 - mae: 2.0514 - mse: 8.0441 - R2: 0.9940 - val_loss: 12.0464 - val_mae: 12.5360 - val_mse: 219.8871 - val_R2: 0.8417\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5872 - mae: 1.9994 - mse: 10.1196 - R2: 0.9924\n",
            "Epoch 169: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 403ms/step - loss: 1.5872 - mae: 1.9994 - mse: 10.1196 - R2: 0.9924 - val_loss: 11.4158 - val_mae: 11.8995 - val_mse: 225.8715 - val_R2: 0.8374\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5663 - mae: 1.9893 - mse: 7.0777 - R2: 0.9947\n",
            "Epoch 170: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 1.5663 - mae: 1.9893 - mse: 7.0777 - R2: 0.9947 - val_loss: 8.2041 - val_mae: 8.6777 - val_mse: 125.9039 - val_R2: 0.9094\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8016 - mae: 2.2446 - mse: 8.9652 - R2: 0.9933\n",
            "Epoch 171: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 407ms/step - loss: 1.8016 - mae: 2.2446 - mse: 8.9652 - R2: 0.9933 - val_loss: 3.8777 - val_mae: 4.3502 - val_mse: 32.1689 - val_R2: 0.9768\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5004 - mae: 1.9348 - mse: 7.1172 - R2: 0.9947\n",
            "Epoch 172: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.5004 - mae: 1.9348 - mse: 7.1172 - R2: 0.9947 - val_loss: 11.1535 - val_mae: 11.6420 - val_mse: 217.9828 - val_R2: 0.8431\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2094 - mae: 1.6302 - mse: 4.8709 - R2: 0.9963\n",
            "Epoch 173: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.2094 - mae: 1.6302 - mse: 4.8709 - R2: 0.9963 - val_loss: 8.1590 - val_mae: 8.6390 - val_mse: 123.9740 - val_R2: 0.9107\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3664 - mae: 1.7866 - mse: 5.9495 - R2: 0.9955\n",
            "Epoch 174: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 1.3664 - mae: 1.7866 - mse: 5.9495 - R2: 0.9955 - val_loss: 3.2275 - val_mae: 3.6895 - val_mse: 23.0378 - val_R2: 0.9834\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3151 - mae: 1.7331 - mse: 5.3579 - R2: 0.9960\n",
            "Epoch 175: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.3151 - mae: 1.7331 - mse: 5.3579 - R2: 0.9960 - val_loss: 3.2288 - val_mae: 3.6813 - val_mse: 22.8075 - val_R2: 0.9836\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0893 - mae: 2.5375 - mse: 13.1046 - R2: 0.9902\n",
            "Epoch 176: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 2.0893 - mae: 2.5375 - mse: 13.1046 - R2: 0.9902 - val_loss: 4.4656 - val_mae: 4.9369 - val_mse: 39.3847 - val_R2: 0.9716\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4298 - mae: 1.8569 - mse: 6.7271 - R2: 0.9949\n",
            "Epoch 177: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.4298 - mae: 1.8569 - mse: 6.7271 - R2: 0.9949 - val_loss: 2.9126 - val_mae: 3.3633 - val_mse: 19.5384 - val_R2: 0.9859\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3163 - mae: 1.7385 - mse: 5.6034 - R2: 0.9958\n",
            "Epoch 178: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.3163 - mae: 1.7385 - mse: 5.6034 - R2: 0.9958 - val_loss: 3.8116 - val_mae: 4.2743 - val_mse: 30.7245 - val_R2: 0.9779\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4053 - mae: 1.8462 - mse: 7.0548 - R2: 0.9947\n",
            "Epoch 179: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.4053 - mae: 1.8462 - mse: 7.0548 - R2: 0.9947 - val_loss: 12.5130 - val_mae: 12.9939 - val_mse: 261.2022 - val_R2: 0.8119\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2920 - mae: 1.7085 - mse: 5.6983 - R2: 0.9957\n",
            "Epoch 180: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 390ms/step - loss: 1.2920 - mae: 1.7085 - mse: 5.6983 - R2: 0.9957 - val_loss: 19.5544 - val_mae: 20.0460 - val_mse: 669.3809 - val_R2: 0.5181\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5126 - mae: 1.9434 - mse: 6.7890 - R2: 0.9949\n",
            "Epoch 181: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.5126 - mae: 1.9434 - mse: 6.7890 - R2: 0.9949 - val_loss: 13.2523 - val_mae: 13.7364 - val_mse: 308.9486 - val_R2: 0.7776\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3076 - mae: 1.7266 - mse: 6.2063 - R2: 0.9953\n",
            "Epoch 182: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.3076 - mae: 1.7266 - mse: 6.2063 - R2: 0.9953 - val_loss: 21.1848 - val_mae: 21.6711 - val_mse: 922.0585 - val_R2: 0.3361\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4788 - mae: 1.8944 - mse: 7.2495 - R2: 0.9946\n",
            "Epoch 183: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.4788 - mae: 1.8944 - mse: 7.2495 - R2: 0.9946 - val_loss: 7.1306 - val_mae: 7.6157 - val_mse: 92.2967 - val_R2: 0.9335\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9576 - mae: 2.3851 - mse: 11.9727 - R2: 0.9910\n",
            "Epoch 184: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 404ms/step - loss: 1.9576 - mae: 2.3851 - mse: 11.9727 - R2: 0.9910 - val_loss: 8.9494 - val_mae: 9.4165 - val_mse: 197.3453 - val_R2: 0.8579\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4463 - mae: 1.8696 - mse: 6.6982 - R2: 0.9950\n",
            "Epoch 185: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.4463 - mae: 1.8696 - mse: 6.6982 - R2: 0.9950 - val_loss: 4.2166 - val_mae: 4.7084 - val_mse: 30.9908 - val_R2: 0.9777\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1935 - mae: 1.5979 - mse: 4.9226 - R2: 0.9963\n",
            "Epoch 186: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.1935 - mae: 1.5979 - mse: 4.9226 - R2: 0.9963 - val_loss: 18.9795 - val_mae: 19.4795 - val_mse: 431.9875 - val_R2: 0.6890\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3564 - mae: 1.7786 - mse: 5.8854 - R2: 0.9956\n",
            "Epoch 187: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.3564 - mae: 1.7786 - mse: 5.8854 - R2: 0.9956 - val_loss: 5.2751 - val_mae: 5.7689 - val_mse: 48.3516 - val_R2: 0.9652\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4228 - mae: 1.8468 - mse: 6.5936 - R2: 0.9950\n",
            "Epoch 188: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.4228 - mae: 1.8468 - mse: 6.5936 - R2: 0.9950 - val_loss: 8.1274 - val_mae: 8.6225 - val_mse: 90.8456 - val_R2: 0.9346\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9919 - mae: 1.4030 - mse: 3.8893 - R2: 0.9971\n",
            "Epoch 189: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 380ms/step - loss: 0.9919 - mae: 1.4030 - mse: 3.8893 - R2: 0.9971 - val_loss: 12.7367 - val_mae: 13.2321 - val_mse: 205.7233 - val_R2: 0.8519\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0837 - mae: 1.4834 - mse: 4.4583 - R2: 0.9966\n",
            "Epoch 190: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.0837 - mae: 1.4834 - mse: 4.4583 - R2: 0.9966 - val_loss: 3.2572 - val_mae: 3.7341 - val_mse: 20.5740 - val_R2: 0.9852\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1999 - mae: 1.6250 - mse: 4.8946 - R2: 0.9963\n",
            "Epoch 191: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.1999 - mae: 1.6250 - mse: 4.8946 - R2: 0.9963 - val_loss: 7.2458 - val_mae: 7.7223 - val_mse: 86.8798 - val_R2: 0.9374\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0279 - mae: 1.4361 - mse: 4.3363 - R2: 0.9967\n",
            "Epoch 192: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.0279 - mae: 1.4361 - mse: 4.3363 - R2: 0.9967 - val_loss: 7.0081 - val_mae: 7.4850 - val_mse: 87.8407 - val_R2: 0.9368\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8290 - mae: 2.2694 - mse: 9.9740 - R2: 0.9925 \n",
            "Epoch 193: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.8290 - mae: 2.2694 - mse: 9.9740 - R2: 0.9925 - val_loss: 7.5948 - val_mae: 8.0722 - val_mse: 103.7260 - val_R2: 0.9253\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0623 - mae: 1.4719 - mse: 4.3134 - R2: 0.9968\n",
            "Epoch 194: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 382ms/step - loss: 1.0623 - mae: 1.4719 - mse: 4.3134 - R2: 0.9968 - val_loss: 3.8380 - val_mae: 4.3151 - val_mse: 30.0786 - val_R2: 0.9783\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5627 - mae: 1.9884 - mse: 7.9018 - R2: 0.9941\n",
            "Epoch 195: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 1.5627 - mae: 1.9884 - mse: 7.9018 - R2: 0.9941 - val_loss: 4.2227 - val_mae: 4.6955 - val_mse: 33.6940 - val_R2: 0.9757\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1116 - mae: 1.5369 - mse: 4.0447 - R2: 0.9970\n",
            "Epoch 196: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.1116 - mae: 1.5369 - mse: 4.0447 - R2: 0.9970 - val_loss: 5.2520 - val_mae: 5.7327 - val_mse: 52.6610 - val_R2: 0.9621\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3845 - mae: 1.8030 - mse: 6.4697 - R2: 0.9951\n",
            "Epoch 197: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.3845 - mae: 1.8030 - mse: 6.4697 - R2: 0.9951 - val_loss: 9.2726 - val_mae: 9.7559 - val_mse: 130.1883 - val_R2: 0.9063\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2349 - mae: 1.6435 - mse: 5.8793 - R2: 0.9956\n",
            "Epoch 198: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.2349 - mae: 1.6435 - mse: 5.8793 - R2: 0.9956 - val_loss: 6.6106 - val_mae: 7.0900 - val_mse: 95.5904 - val_R2: 0.9312\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9757 - mae: 1.3824 - mse: 3.6218 - R2: 0.9973\n",
            "Epoch 199: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 0.9757 - mae: 1.3824 - mse: 3.6218 - R2: 0.9973 - val_loss: 10.0960 - val_mae: 10.5852 - val_mse: 196.5512 - val_R2: 0.8585\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2701 - mae: 1.6872 - mse: 5.3499 - R2: 0.9960\n",
            "Epoch 200: val_loss did not improve from 1.97540\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.2701 - mae: 1.6872 - mse: 5.3499 - R2: 0.9960 - val_loss: 5.2691 - val_mae: 5.7280 - val_mse: 55.5842 - val_R2: 0.9600\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 1.9208 - mae: 2.3924 - mse: 10.3586 - R2: 0.9925\n",
            "Found 389 validated image filenames.\n",
            "Found 97 validated image filenames.\n",
            "Epoch 1/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 31.8733 - mae: 32.3670 - mse: 1869.0728 - R2: -0.3614\n",
            "Epoch 1: val_loss improved from inf to 117.06250, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 24s 554ms/step - loss: 31.8733 - mae: 32.3670 - mse: 1869.0728 - R2: -0.3614 - val_loss: 117.0625 - val_mae: 117.5625 - val_mse: 14208.1279 - val_R2: -10.5335\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 10.8596 - mae: 11.3442 - mse: 243.2714 - R2: 0.8228\n",
            "Epoch 2: val_loss did not improve from 117.06250\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 10.8596 - mae: 11.3442 - mse: 243.2714 - R2: 0.8228 - val_loss: 568.3328 - val_mae: 568.8328 - val_mse: 426065.9688 - val_R2: -344.8607\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 8.0498 - mae: 8.5329 - mse: 128.9207 - R2: 0.9061\n",
            "Epoch 3: val_loss did not improve from 117.06250\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 8.0498 - mae: 8.5329 - mse: 128.9207 - R2: 0.9061 - val_loss: 1197.2317 - val_mae: 1197.7317 - val_mse: 2391492.7500 - val_R2: -1940.3036\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 9.1408 - mae: 9.6293 - mse: 161.5961 - R2: 0.8823\n",
            "Epoch 4: val_loss improved from 117.06250 to 79.98032, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 487ms/step - loss: 9.1408 - mae: 9.6293 - mse: 161.5961 - R2: 0.8823 - val_loss: 79.9803 - val_mae: 80.4803 - val_mse: 8481.6826 - val_R2: -5.8850\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 8.0378 - mae: 8.5264 - mse: 121.5188 - R2: 0.9115\n",
            "Epoch 5: val_loss did not improve from 79.98032\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 8.0378 - mae: 8.5264 - mse: 121.5188 - R2: 0.9115 - val_loss: 321.3620 - val_mae: 321.8620 - val_mse: 137739.5625 - val_R2: -110.8106\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.2595 - mae: 7.7514 - mse: 103.4913 - R2: 0.9246\n",
            "Epoch 6: val_loss did not improve from 79.98032\n",
            "13/13 [==============================] - 5s 395ms/step - loss: 7.2595 - mae: 7.7514 - mse: 103.4913 - R2: 0.9246 - val_loss: 107.8871 - val_mae: 108.3871 - val_mse: 14902.0557 - val_R2: -11.0968\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.9950 - mae: 8.4831 - mse: 116.1831 - R2: 0.9154\n",
            "Epoch 7: val_loss improved from 79.98032 to 16.68564, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 483ms/step - loss: 7.9950 - mae: 8.4831 - mse: 116.1831 - R2: 0.9154 - val_loss: 16.6856 - val_mae: 17.1800 - val_mse: 567.4420 - val_R2: 0.5394\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.4042 - mae: 7.8887 - mse: 120.1239 - R2: 0.9125\n",
            "Epoch 8: val_loss did not improve from 16.68564\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 7.4042 - mae: 7.8887 - mse: 120.1239 - R2: 0.9125 - val_loss: 76.5982 - val_mae: 77.0845 - val_mse: 15072.1699 - val_R2: -11.2349\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.0663 - mae: 7.5487 - mse: 95.2371 - R2: 0.9306\n",
            "Epoch 9: val_loss did not improve from 16.68564\n",
            "13/13 [==============================] - 5s 403ms/step - loss: 7.0663 - mae: 7.5487 - mse: 95.2371 - R2: 0.9306 - val_loss: 98.9053 - val_mae: 99.4040 - val_mse: 16383.7246 - val_R2: -12.2995\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.2694 - mae: 7.7484 - mse: 103.9737 - R2: 0.9243\n",
            "Epoch 10: val_loss did not improve from 16.68564\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 7.2694 - mae: 7.7484 - mse: 103.9737 - R2: 0.9243 - val_loss: 122.0616 - val_mae: 122.5616 - val_mse: 18389.0586 - val_R2: -13.9274\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.9358 - mae: 6.4127 - mse: 71.1647 - R2: 0.9482\n",
            "Epoch 11: val_loss did not improve from 16.68564\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 5.9358 - mae: 6.4127 - mse: 71.1647 - R2: 0.9482 - val_loss: 89.7354 - val_mae: 90.2354 - val_mse: 10958.5801 - val_R2: -7.8957\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.9817 - mae: 5.4535 - mse: 54.4531 - R2: 0.9603\n",
            "Epoch 12: val_loss did not improve from 16.68564\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 4.9817 - mae: 5.4535 - mse: 54.4531 - R2: 0.9603 - val_loss: 49.6961 - val_mae: 50.1958 - val_mse: 2791.9255 - val_R2: -1.2664\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.1342 - mae: 6.6092 - mse: 73.0379 - R2: 0.9468\n",
            "Epoch 13: val_loss did not improve from 16.68564\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 6.1342 - mae: 6.6092 - mse: 73.0379 - R2: 0.9468 - val_loss: 37.4067 - val_mae: 37.9063 - val_mse: 2045.6442 - val_R2: -0.6606\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.6859 - mae: 7.1653 - mse: 87.4430 - R2: 0.9363\n",
            "Epoch 14: val_loss did not improve from 16.68564\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 6.6859 - mae: 7.1653 - mse: 87.4430 - R2: 0.9363 - val_loss: 17.1946 - val_mae: 17.6896 - val_mse: 447.7255 - val_R2: 0.6366\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.9101 - mae: 6.3899 - mse: 79.1827 - R2: 0.9423\n",
            "Epoch 15: val_loss did not improve from 16.68564\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 5.9101 - mae: 6.3899 - mse: 79.1827 - R2: 0.9423 - val_loss: 26.5377 - val_mae: 27.0377 - val_mse: 861.4005 - val_R2: 0.3008\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.5772 - mae: 5.0480 - mse: 49.7821 - R2: 0.9637\n",
            "Epoch 16: val_loss improved from 16.68564 to 13.81111, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 499ms/step - loss: 4.5772 - mae: 5.0480 - mse: 49.7821 - R2: 0.9637 - val_loss: 13.8111 - val_mae: 14.3080 - val_mse: 350.9360 - val_R2: 0.7151\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.5896 - mae: 7.0735 - mse: 94.1101 - R2: 0.9315\n",
            "Epoch 17: val_loss did not improve from 13.81111\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 6.5896 - mae: 7.0735 - mse: 94.1101 - R2: 0.9315 - val_loss: 44.5958 - val_mae: 45.0958 - val_mse: 2325.7739 - val_R2: -0.8880\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.1723 - mae: 6.6499 - mse: 77.8439 - R2: 0.9433\n",
            "Epoch 18: val_loss improved from 13.81111 to 11.27046, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 485ms/step - loss: 6.1723 - mae: 6.6499 - mse: 77.8439 - R2: 0.9433 - val_loss: 11.2705 - val_mae: 11.7613 - val_mse: 198.9201 - val_R2: 0.8385\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.6094 - mae: 6.0923 - mse: 68.2156 - R2: 0.9503\n",
            "Epoch 19: val_loss did not improve from 11.27046\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 5.6094 - mae: 6.0923 - mse: 68.2156 - R2: 0.9503 - val_loss: 16.4366 - val_mae: 16.9358 - val_mse: 392.4100 - val_R2: 0.6815\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.4315 - mae: 6.9114 - mse: 87.6081 - R2: 0.9362\n",
            "Epoch 20: val_loss improved from 11.27046 to 11.21790, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 489ms/step - loss: 6.4315 - mae: 6.9114 - mse: 87.6081 - R2: 0.9362 - val_loss: 11.2179 - val_mae: 11.7055 - val_mse: 283.6272 - val_R2: 0.7698\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.1207 - mae: 6.6073 - mse: 74.2492 - R2: 0.9459\n",
            "Epoch 21: val_loss improved from 11.21790 to 3.96210, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 486ms/step - loss: 6.1207 - mae: 6.6073 - mse: 74.2492 - R2: 0.9459 - val_loss: 3.9621 - val_mae: 4.4340 - val_mse: 30.5128 - val_R2: 0.9752\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.1618 - mae: 6.6383 - mse: 82.3452 - R2: 0.9400\n",
            "Epoch 22: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 6.1618 - mae: 6.6383 - mse: 82.3452 - R2: 0.9400 - val_loss: 60.0327 - val_mae: 60.5327 - val_mse: 3984.5818 - val_R2: -2.2345\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7484 - mae: 4.2204 - mse: 33.9764 - R2: 0.9753\n",
            "Epoch 23: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 3.7484 - mae: 4.2204 - mse: 33.9764 - R2: 0.9753 - val_loss: 23.0005 - val_mae: 23.4999 - val_mse: 643.9248 - val_R2: 0.4773\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9897 - mae: 4.4624 - mse: 35.2179 - R2: 0.9743\n",
            "Epoch 24: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 3.9897 - mae: 4.4624 - mse: 35.2179 - R2: 0.9743 - val_loss: 5.2016 - val_mae: 5.6860 - val_mse: 48.6130 - val_R2: 0.9605\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.3030 - mae: 5.7809 - mse: 57.0028 - R2: 0.9585\n",
            "Epoch 25: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 5.3030 - mae: 5.7809 - mse: 57.0028 - R2: 0.9585 - val_loss: 8.7519 - val_mae: 9.2406 - val_mse: 154.2765 - val_R2: 0.8748\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.5179 - mae: 5.9966 - mse: 65.6031 - R2: 0.9522\n",
            "Epoch 26: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 5.5179 - mae: 5.9966 - mse: 65.6031 - R2: 0.9522 - val_loss: 22.2627 - val_mae: 22.7478 - val_mse: 918.7711 - val_R2: 0.2542\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.2199 - mae: 5.6978 - mse: 59.2016 - R2: 0.9569\n",
            "Epoch 27: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 392ms/step - loss: 5.2199 - mae: 5.6978 - mse: 59.2016 - R2: 0.9569 - val_loss: 8.9836 - val_mae: 9.4581 - val_mse: 189.3320 - val_R2: 0.8463\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.9797 - mae: 5.4593 - mse: 48.6266 - R2: 0.9646\n",
            "Epoch 28: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 4.9797 - mae: 5.4593 - mse: 48.6266 - R2: 0.9646 - val_loss: 5.5384 - val_mae: 6.0147 - val_mse: 67.1758 - val_R2: 0.9455\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9594 - mae: 4.4363 - mse: 35.6455 - R2: 0.9740\n",
            "Epoch 29: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 3.9594 - mae: 4.4363 - mse: 35.6455 - R2: 0.9740 - val_loss: 6.2873 - val_mae: 6.7650 - val_mse: 70.0980 - val_R2: 0.9431\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.3485 - mae: 4.8256 - mse: 40.0565 - R2: 0.9708\n",
            "Epoch 30: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 4.3485 - mae: 4.8256 - mse: 40.0565 - R2: 0.9708 - val_loss: 12.0912 - val_mae: 12.5890 - val_mse: 245.1379 - val_R2: 0.8010\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6815 - mae: 4.1432 - mse: 28.9735 - R2: 0.9789\n",
            "Epoch 31: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 3.6815 - mae: 4.1432 - mse: 28.9735 - R2: 0.9789 - val_loss: 9.5490 - val_mae: 10.0246 - val_mse: 146.0564 - val_R2: 0.8814\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.1898 - mae: 4.6540 - mse: 37.7972 - R2: 0.9725\n",
            "Epoch 32: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 4.1898 - mae: 4.6540 - mse: 37.7972 - R2: 0.9725 - val_loss: 8.3649 - val_mae: 8.8528 - val_mse: 120.0451 - val_R2: 0.9026\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.7910 - mae: 5.2635 - mse: 42.9576 - R2: 0.9687\n",
            "Epoch 33: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 4.7910 - mae: 5.2635 - mse: 42.9576 - R2: 0.9687 - val_loss: 13.8734 - val_mae: 14.3610 - val_mse: 323.7755 - val_R2: 0.7372\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3648 - mae: 3.8365 - mse: 25.9708 - R2: 0.9811\n",
            "Epoch 34: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 381ms/step - loss: 3.3648 - mae: 3.8365 - mse: 25.9708 - R2: 0.9811 - val_loss: 9.3592 - val_mae: 9.8590 - val_mse: 150.8524 - val_R2: 0.8775\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9989 - mae: 4.4704 - mse: 34.7944 - R2: 0.9747\n",
            "Epoch 35: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 3.9989 - mae: 4.4704 - mse: 34.7944 - R2: 0.9747 - val_loss: 4.5145 - val_mae: 4.9966 - val_mse: 39.9568 - val_R2: 0.9676\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1340 - mae: 3.6014 - mse: 24.2335 - R2: 0.9823\n",
            "Epoch 36: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 3.1340 - mae: 3.6014 - mse: 24.2335 - R2: 0.9823 - val_loss: 5.4677 - val_mae: 5.9567 - val_mse: 57.0874 - val_R2: 0.9537\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0134 - mae: 4.4801 - mse: 38.3855 - R2: 0.9720\n",
            "Epoch 37: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 390ms/step - loss: 4.0134 - mae: 4.4801 - mse: 38.3855 - R2: 0.9720 - val_loss: 5.5770 - val_mae: 6.0578 - val_mse: 55.2597 - val_R2: 0.9551\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0825 - mae: 4.5477 - mse: 47.3635 - R2: 0.9655\n",
            "Epoch 38: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 4.0825 - mae: 4.5477 - mse: 47.3635 - R2: 0.9655 - val_loss: 5.9053 - val_mae: 6.3841 - val_mse: 65.2120 - val_R2: 0.9471\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.1342 - mae: 5.6018 - mse: 62.4149 - R2: 0.9545\n",
            "Epoch 39: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 5.1342 - mae: 5.6018 - mse: 62.4149 - R2: 0.9545 - val_loss: 6.3869 - val_mae: 6.8853 - val_mse: 81.7067 - val_R2: 0.9337\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0628 - mae: 3.5282 - mse: 24.2388 - R2: 0.9823\n",
            "Epoch 40: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 3.0628 - mae: 3.5282 - mse: 24.2388 - R2: 0.9823 - val_loss: 36.0172 - val_mae: 36.5172 - val_mse: 1487.1115 - val_R2: -0.2072\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9540 - mae: 4.4280 - mse: 38.5407 - R2: 0.9719\n",
            "Epoch 41: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 3.9540 - mae: 4.4280 - mse: 38.5407 - R2: 0.9719 - val_loss: 21.3010 - val_mae: 21.8000 - val_mse: 602.5501 - val_R2: 0.5109\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4687 - mae: 3.9328 - mse: 28.7549 - R2: 0.9791\n",
            "Epoch 42: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 392ms/step - loss: 3.4687 - mae: 3.9328 - mse: 28.7549 - R2: 0.9791 - val_loss: 6.6329 - val_mae: 7.1110 - val_mse: 92.2138 - val_R2: 0.9251\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6370 - mae: 4.1065 - mse: 34.9340 - R2: 0.9746\n",
            "Epoch 43: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 3.6370 - mae: 4.1065 - mse: 34.9340 - R2: 0.9746 - val_loss: 5.2371 - val_mae: 5.7164 - val_mse: 59.1524 - val_R2: 0.9520\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.4380 - mae: 4.9056 - mse: 46.0456 - R2: 0.9665\n",
            "Epoch 44: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 4.4380 - mae: 4.9056 - mse: 46.0456 - R2: 0.9665 - val_loss: 4.7064 - val_mae: 5.1825 - val_mse: 46.6162 - val_R2: 0.9622\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2673 - mae: 3.7289 - mse: 26.0682 - R2: 0.9810\n",
            "Epoch 45: val_loss did not improve from 3.96210\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 3.2673 - mae: 3.7289 - mse: 26.0682 - R2: 0.9810 - val_loss: 8.9512 - val_mae: 9.4370 - val_mse: 117.6508 - val_R2: 0.9045\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.3355 - mae: 4.8149 - mse: 40.0324 - R2: 0.9708\n",
            "Epoch 46: val_loss improved from 3.96210 to 3.11868, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 483ms/step - loss: 4.3355 - mae: 4.8149 - mse: 40.0324 - R2: 0.9708 - val_loss: 3.1187 - val_mae: 3.5821 - val_mse: 21.2345 - val_R2: 0.9828\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9239 - mae: 3.3964 - mse: 19.7849 - R2: 0.9856\n",
            "Epoch 47: val_loss did not improve from 3.11868\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.9239 - mae: 3.3964 - mse: 19.7849 - R2: 0.9856 - val_loss: 5.6258 - val_mae: 6.1014 - val_mse: 56.5374 - val_R2: 0.9541\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2271 - mae: 4.7007 - mse: 38.6582 - R2: 0.9718\n",
            "Epoch 48: val_loss did not improve from 3.11868\n",
            "13/13 [==============================] - 5s 405ms/step - loss: 4.2271 - mae: 4.7007 - mse: 38.6582 - R2: 0.9718 - val_loss: 14.0488 - val_mae: 14.5409 - val_mse: 279.3486 - val_R2: 0.7732\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3605 - mae: 3.8223 - mse: 29.2462 - R2: 0.9787\n",
            "Epoch 49: val_loss did not improve from 3.11868\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 3.3605 - mae: 3.8223 - mse: 29.2462 - R2: 0.9787 - val_loss: 3.9687 - val_mae: 4.4532 - val_mse: 30.0202 - val_R2: 0.9756\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.7412 - mae: 5.2202 - mse: 48.6908 - R2: 0.9645\n",
            "Epoch 50: val_loss did not improve from 3.11868\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 4.7412 - mae: 5.2202 - mse: 48.6908 - R2: 0.9645 - val_loss: 3.1344 - val_mae: 3.6081 - val_mse: 24.6034 - val_R2: 0.9800\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7835 - mae: 4.2471 - mse: 36.7486 - R2: 0.9732\n",
            "Epoch 51: val_loss improved from 3.11868 to 2.78186, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 485ms/step - loss: 3.7835 - mae: 4.2471 - mse: 36.7486 - R2: 0.9732 - val_loss: 2.7819 - val_mae: 3.2380 - val_mse: 17.8000 - val_R2: 0.9856\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2422 - mae: 3.7010 - mse: 28.0739 - R2: 0.9796\n",
            "Epoch 52: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 404ms/step - loss: 3.2422 - mae: 3.7010 - mse: 28.0739 - R2: 0.9796 - val_loss: 4.5528 - val_mae: 5.0425 - val_mse: 37.0725 - val_R2: 0.9699\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9490 - mae: 3.4023 - mse: 21.1023 - R2: 0.9846\n",
            "Epoch 53: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.9490 - mae: 3.4023 - mse: 21.1023 - R2: 0.9846 - val_loss: 4.6493 - val_mae: 5.1266 - val_mse: 45.8960 - val_R2: 0.9627\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.2032 - mae: 3.6736 - mse: 23.6402 - R2: 0.9828\n",
            "Epoch 54: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 3.2032 - mae: 3.6736 - mse: 23.6402 - R2: 0.9828 - val_loss: 4.2441 - val_mae: 4.7200 - val_mse: 34.5929 - val_R2: 0.9719\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6141 - mae: 3.0714 - mse: 17.7626 - R2: 0.9871\n",
            "Epoch 55: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.6141 - mae: 3.0714 - mse: 17.7626 - R2: 0.9871 - val_loss: 5.5632 - val_mae: 6.0537 - val_mse: 50.9630 - val_R2: 0.9586\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1805 - mae: 3.6386 - mse: 25.0871 - R2: 0.9817\n",
            "Epoch 56: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.1805 - mae: 3.6386 - mse: 25.0871 - R2: 0.9817 - val_loss: 12.2571 - val_mae: 12.7538 - val_mse: 217.1968 - val_R2: 0.8237\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6229 - mae: 4.0809 - mse: 30.6653 - R2: 0.9777\n",
            "Epoch 57: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 392ms/step - loss: 3.6229 - mae: 4.0809 - mse: 30.6653 - R2: 0.9777 - val_loss: 19.6710 - val_mae: 20.1663 - val_mse: 477.2976 - val_R2: 0.6126\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9607 - mae: 4.4316 - mse: 37.2476 - R2: 0.9729\n",
            "Epoch 58: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 396ms/step - loss: 3.9607 - mae: 4.4316 - mse: 37.2476 - R2: 0.9729 - val_loss: 4.5018 - val_mae: 4.9862 - val_mse: 40.8899 - val_R2: 0.9668\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7919 - mae: 4.2524 - mse: 35.6887 - R2: 0.9740\n",
            "Epoch 59: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 3.7919 - mae: 4.2524 - mse: 35.6887 - R2: 0.9740 - val_loss: 3.6566 - val_mae: 4.1330 - val_mse: 26.9910 - val_R2: 0.9781\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8643 - mae: 3.3283 - mse: 19.1465 - R2: 0.9861\n",
            "Epoch 60: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 394ms/step - loss: 2.8643 - mae: 3.3283 - mse: 19.1465 - R2: 0.9861 - val_loss: 4.4530 - val_mae: 4.9357 - val_mse: 38.0514 - val_R2: 0.9691\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4369 - mae: 3.8891 - mse: 30.3712 - R2: 0.9779\n",
            "Epoch 61: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 3.4369 - mae: 3.8891 - mse: 30.3712 - R2: 0.9779 - val_loss: 5.7838 - val_mae: 6.2654 - val_mse: 76.8230 - val_R2: 0.9376\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8777 - mae: 3.3370 - mse: 20.5915 - R2: 0.9850\n",
            "Epoch 62: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 397ms/step - loss: 2.8777 - mae: 3.3370 - mse: 20.5915 - R2: 0.9850 - val_loss: 4.7575 - val_mae: 5.2392 - val_mse: 40.9130 - val_R2: 0.9668\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4503 - mae: 2.9001 - mse: 15.4285 - R2: 0.9888\n",
            "Epoch 63: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.4503 - mae: 2.9001 - mse: 15.4285 - R2: 0.9888 - val_loss: 14.8033 - val_mae: 15.3002 - val_mse: 337.4517 - val_R2: 0.7261\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5057 - mae: 2.9635 - mse: 15.9505 - R2: 0.9884\n",
            "Epoch 64: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 2.5057 - mae: 2.9635 - mse: 15.9505 - R2: 0.9884 - val_loss: 17.3979 - val_mae: 17.8893 - val_mse: 419.5409 - val_R2: 0.6594\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8506 - mae: 3.3095 - mse: 18.0021 - R2: 0.9869\n",
            "Epoch 65: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.8506 - mae: 3.3095 - mse: 18.0021 - R2: 0.9869 - val_loss: 19.0961 - val_mae: 19.5940 - val_mse: 550.8060 - val_R2: 0.5529\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9780 - mae: 4.4379 - mse: 41.6547 - R2: 0.9697\n",
            "Epoch 66: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.9780 - mae: 4.4379 - mse: 41.6547 - R2: 0.9697 - val_loss: 3.8932 - val_mae: 4.3544 - val_mse: 34.2892 - val_R2: 0.9722\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3639 - mae: 3.8272 - mse: 28.9935 - R2: 0.9789\n",
            "Epoch 67: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 3.3639 - mae: 3.8272 - mse: 28.9935 - R2: 0.9789 - val_loss: 3.6703 - val_mae: 4.1349 - val_mse: 27.2286 - val_R2: 0.9779\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9194 - mae: 3.3751 - mse: 22.3516 - R2: 0.9837\n",
            "Epoch 68: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 2.9194 - mae: 3.3751 - mse: 22.3516 - R2: 0.9837 - val_loss: 5.2845 - val_mae: 5.7704 - val_mse: 45.7115 - val_R2: 0.9629\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6483 - mae: 3.1000 - mse: 19.4659 - R2: 0.9858\n",
            "Epoch 69: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.6483 - mae: 3.1000 - mse: 19.4659 - R2: 0.9858 - val_loss: 4.4355 - val_mae: 4.9235 - val_mse: 33.7882 - val_R2: 0.9726\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5093 - mae: 2.9657 - mse: 15.2312 - R2: 0.9889\n",
            "Epoch 70: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 407ms/step - loss: 2.5093 - mae: 2.9657 - mse: 15.2312 - R2: 0.9889 - val_loss: 4.1973 - val_mae: 4.6665 - val_mse: 36.1265 - val_R2: 0.9707\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7826 - mae: 3.2385 - mse: 19.4384 - R2: 0.9858\n",
            "Epoch 71: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 2.7826 - mae: 3.2385 - mse: 19.4384 - R2: 0.9858 - val_loss: 8.4056 - val_mae: 8.8904 - val_mse: 147.0703 - val_R2: 0.8806\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5801 - mae: 3.0287 - mse: 17.5072 - R2: 0.9872\n",
            "Epoch 72: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 2.5801 - mae: 3.0287 - mse: 17.5072 - R2: 0.9872 - val_loss: 4.4378 - val_mae: 4.9161 - val_mse: 36.0039 - val_R2: 0.9708\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4002 - mae: 2.8489 - mse: 14.7274 - R2: 0.9893\n",
            "Epoch 73: val_loss did not improve from 2.78186\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 2.4002 - mae: 2.8489 - mse: 14.7274 - R2: 0.9893 - val_loss: 12.0374 - val_mae: 12.5127 - val_mse: 311.4621 - val_R2: 0.7472\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9639 - mae: 3.4199 - mse: 21.8024 - R2: 0.9841\n",
            "Epoch 74: val_loss improved from 2.78186 to 2.65000, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 487ms/step - loss: 2.9639 - mae: 3.4199 - mse: 21.8024 - R2: 0.9841 - val_loss: 2.6500 - val_mae: 3.1081 - val_mse: 16.6425 - val_R2: 0.9865\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2709 - mae: 2.7290 - mse: 12.5885 - R2: 0.9908\n",
            "Epoch 75: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.2709 - mae: 2.7290 - mse: 12.5885 - R2: 0.9908 - val_loss: 6.5592 - val_mae: 7.0326 - val_mse: 94.5183 - val_R2: 0.9233\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6414 - mae: 3.0904 - mse: 18.7824 - R2: 0.9863\n",
            "Epoch 76: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 2.6414 - mae: 3.0904 - mse: 18.7824 - R2: 0.9863 - val_loss: 3.2744 - val_mae: 3.7277 - val_mse: 22.1066 - val_R2: 0.9821\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7721 - mae: 3.2266 - mse: 19.0557 - R2: 0.9861\n",
            "Epoch 77: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 2.7721 - mae: 3.2266 - mse: 19.0557 - R2: 0.9861 - val_loss: 3.9318 - val_mae: 4.4085 - val_mse: 32.9389 - val_R2: 0.9733\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1274 - mae: 2.5707 - mse: 11.7097 - R2: 0.9915\n",
            "Epoch 78: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 2.1274 - mae: 2.5707 - mse: 11.7097 - R2: 0.9915 - val_loss: 2.7872 - val_mae: 3.2442 - val_mse: 20.9619 - val_R2: 0.9830\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5016 - mae: 2.9616 - mse: 14.8422 - R2: 0.9892\n",
            "Epoch 79: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 390ms/step - loss: 2.5016 - mae: 2.9616 - mse: 14.8422 - R2: 0.9892 - val_loss: 8.1341 - val_mae: 8.6263 - val_mse: 118.1931 - val_R2: 0.9041\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5295 - mae: 2.9783 - mse: 16.6222 - R2: 0.9879\n",
            "Epoch 80: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 2.5295 - mae: 2.9783 - mse: 16.6222 - R2: 0.9879 - val_loss: 2.9433 - val_mae: 3.4100 - val_mse: 19.6450 - val_R2: 0.9841\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5247 - mae: 2.9743 - mse: 19.3099 - R2: 0.9859\n",
            "Epoch 81: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 412ms/step - loss: 2.5247 - mae: 2.9743 - mse: 19.3099 - R2: 0.9859 - val_loss: 5.8359 - val_mae: 6.3278 - val_mse: 57.0360 - val_R2: 0.9537\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1757 - mae: 2.6167 - mse: 12.6377 - R2: 0.9908\n",
            "Epoch 82: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 2.1757 - mae: 2.6167 - mse: 12.6377 - R2: 0.9908 - val_loss: 4.9400 - val_mae: 5.4303 - val_mse: 41.3043 - val_R2: 0.9665\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0684 - mae: 2.5089 - mse: 12.0036 - R2: 0.9913\n",
            "Epoch 83: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 2.0684 - mae: 2.5089 - mse: 12.0036 - R2: 0.9913 - val_loss: 6.5799 - val_mae: 7.0515 - val_mse: 98.6603 - val_R2: 0.9199\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2692 - mae: 2.7230 - mse: 13.3956 - R2: 0.9902\n",
            "Epoch 84: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.2692 - mae: 2.7230 - mse: 13.3956 - R2: 0.9902 - val_loss: 5.0568 - val_mae: 5.5417 - val_mse: 48.5902 - val_R2: 0.9606\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2815 - mae: 2.7346 - mse: 13.0195 - R2: 0.9905\n",
            "Epoch 85: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 2.2815 - mae: 2.7346 - mse: 13.0195 - R2: 0.9905 - val_loss: 10.3573 - val_mae: 10.8361 - val_mse: 192.1964 - val_R2: 0.8440\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6649 - mae: 3.1258 - mse: 18.0533 - R2: 0.9869\n",
            "Epoch 86: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.6649 - mae: 3.1258 - mse: 18.0533 - R2: 0.9869 - val_loss: 7.7472 - val_mae: 8.2322 - val_mse: 102.8384 - val_R2: 0.9165\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4407 - mae: 2.8912 - mse: 16.0853 - R2: 0.9883\n",
            "Epoch 87: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 2.4407 - mae: 2.8912 - mse: 16.0853 - R2: 0.9883 - val_loss: 2.9817 - val_mae: 3.4423 - val_mse: 23.1302 - val_R2: 0.9812\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1361 - mae: 2.5837 - mse: 13.2531 - R2: 0.9903\n",
            "Epoch 88: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 2.1361 - mae: 2.5837 - mse: 13.2531 - R2: 0.9903 - val_loss: 4.8379 - val_mae: 5.3145 - val_mse: 44.7528 - val_R2: 0.9637\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0650 - mae: 2.5080 - mse: 13.3087 - R2: 0.9903\n",
            "Epoch 89: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 2.0650 - mae: 2.5080 - mse: 13.3087 - R2: 0.9903 - val_loss: 3.6341 - val_mae: 4.0935 - val_mse: 28.0364 - val_R2: 0.9772\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0504 - mae: 2.4924 - mse: 11.5741 - R2: 0.9916\n",
            "Epoch 90: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.0504 - mae: 2.4924 - mse: 11.5741 - R2: 0.9916 - val_loss: 3.3621 - val_mae: 3.8387 - val_mse: 25.9949 - val_R2: 0.9789\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7635 - mae: 2.2102 - mse: 9.4126 - R2: 0.9931\n",
            "Epoch 91: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.7635 - mae: 2.2102 - mse: 9.4126 - R2: 0.9931 - val_loss: 3.3966 - val_mae: 3.8744 - val_mse: 27.4748 - val_R2: 0.9777\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9952 - mae: 2.4405 - mse: 11.8000 - R2: 0.9914\n",
            "Epoch 92: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 409ms/step - loss: 1.9952 - mae: 2.4405 - mse: 11.8000 - R2: 0.9914 - val_loss: 5.2040 - val_mae: 5.6730 - val_mse: 49.7595 - val_R2: 0.9596\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8856 - mae: 2.3193 - mse: 12.3352 - R2: 0.9910\n",
            "Epoch 93: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.8856 - mae: 2.3193 - mse: 12.3352 - R2: 0.9910 - val_loss: 14.7471 - val_mae: 15.2471 - val_mse: 318.0939 - val_R2: 0.7418\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6904 - mae: 3.1426 - mse: 18.2910 - R2: 0.9867\n",
            "Epoch 94: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.6904 - mae: 3.1426 - mse: 18.2910 - R2: 0.9867 - val_loss: 3.7087 - val_mae: 4.1983 - val_mse: 27.1145 - val_R2: 0.9780\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9343 - mae: 2.3623 - mse: 10.6403 - R2: 0.9922\n",
            "Epoch 95: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.9343 - mae: 2.3623 - mse: 10.6403 - R2: 0.9922 - val_loss: 5.6404 - val_mae: 6.1237 - val_mse: 63.9640 - val_R2: 0.9481\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6126 - mae: 3.0728 - mse: 15.9874 - R2: 0.9884\n",
            "Epoch 96: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 409ms/step - loss: 2.6126 - mae: 3.0728 - mse: 15.9874 - R2: 0.9884 - val_loss: 4.6354 - val_mae: 5.1208 - val_mse: 38.9549 - val_R2: 0.9684\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4730 - mae: 2.9279 - mse: 14.5766 - R2: 0.9894\n",
            "Epoch 97: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 2.4730 - mae: 2.9279 - mse: 14.5766 - R2: 0.9894 - val_loss: 15.3789 - val_mae: 15.8789 - val_mse: 312.5522 - val_R2: 0.7463\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3824 - mae: 2.8361 - mse: 13.9145 - R2: 0.9899\n",
            "Epoch 98: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 2.3824 - mae: 2.8361 - mse: 13.9145 - R2: 0.9899 - val_loss: 11.5298 - val_mae: 12.0268 - val_mse: 188.6036 - val_R2: 0.8469\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3139 - mae: 2.7649 - mse: 14.4636 - R2: 0.9895\n",
            "Epoch 99: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.3139 - mae: 2.7649 - mse: 14.4636 - R2: 0.9895 - val_loss: 5.2983 - val_mae: 5.7798 - val_mse: 49.0449 - val_R2: 0.9602\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5591 - mae: 3.0133 - mse: 16.1636 - R2: 0.9882\n",
            "Epoch 100: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 2.5591 - mae: 3.0133 - mse: 16.1636 - R2: 0.9882 - val_loss: 8.3696 - val_mae: 8.8425 - val_mse: 125.8159 - val_R2: 0.8979\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1601 - mae: 2.6024 - mse: 12.1421 - R2: 0.9912\n",
            "Epoch 101: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 2.1601 - mae: 2.6024 - mse: 12.1421 - R2: 0.9912 - val_loss: 3.3602 - val_mae: 3.8358 - val_mse: 24.7387 - val_R2: 0.9799\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4632 - mae: 2.9069 - mse: 15.6789 - R2: 0.9886\n",
            "Epoch 102: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 392ms/step - loss: 2.4632 - mae: 2.9069 - mse: 15.6789 - R2: 0.9886 - val_loss: 11.1740 - val_mae: 11.6606 - val_mse: 238.8407 - val_R2: 0.8061\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0817 - mae: 2.5203 - mse: 12.4697 - R2: 0.9909\n",
            "Epoch 103: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 394ms/step - loss: 2.0817 - mae: 2.5203 - mse: 12.4697 - R2: 0.9909 - val_loss: 7.6180 - val_mae: 8.0996 - val_mse: 108.0991 - val_R2: 0.9123\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8564 - mae: 2.2885 - mse: 10.2862 - R2: 0.9925\n",
            "Epoch 104: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 394ms/step - loss: 1.8564 - mae: 2.2885 - mse: 10.2862 - R2: 0.9925 - val_loss: 4.4664 - val_mae: 4.9372 - val_mse: 38.0183 - val_R2: 0.9691\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9676 - mae: 2.4096 - mse: 10.7141 - R2: 0.9922\n",
            "Epoch 105: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 390ms/step - loss: 1.9676 - mae: 2.4096 - mse: 10.7141 - R2: 0.9922 - val_loss: 2.8842 - val_mae: 3.3339 - val_mse: 19.2582 - val_R2: 0.9844\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3632 - mae: 2.8073 - mse: 14.9024 - R2: 0.9891\n",
            "Epoch 106: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.3632 - mae: 2.8073 - mse: 14.9024 - R2: 0.9891 - val_loss: 6.6260 - val_mae: 7.1204 - val_mse: 77.5791 - val_R2: 0.9370\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8116 - mae: 2.2500 - mse: 9.3824 - R2: 0.9932\n",
            "Epoch 107: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.8116 - mae: 2.2500 - mse: 9.3824 - R2: 0.9932 - val_loss: 10.4227 - val_mae: 10.9193 - val_mse: 160.5281 - val_R2: 0.8697\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4776 - mae: 1.9091 - mse: 6.2407 - R2: 0.9955\n",
            "Epoch 108: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.4776 - mae: 1.9091 - mse: 6.2407 - R2: 0.9955 - val_loss: 11.7555 - val_mae: 12.2518 - val_mse: 192.8631 - val_R2: 0.8434\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6898 - mae: 2.1400 - mse: 8.1657 - R2: 0.9941\n",
            "Epoch 109: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.6898 - mae: 2.1400 - mse: 8.1657 - R2: 0.9941 - val_loss: 5.0818 - val_mae: 5.5669 - val_mse: 45.2480 - val_R2: 0.9633\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8120 - mae: 2.2483 - mse: 9.6289 - R2: 0.9930\n",
            "Epoch 110: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 392ms/step - loss: 1.8120 - mae: 2.2483 - mse: 9.6289 - R2: 0.9930 - val_loss: 3.4934 - val_mae: 3.9644 - val_mse: 24.8649 - val_R2: 0.9798\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8881 - mae: 2.3212 - mse: 9.9594 - R2: 0.9927\n",
            "Epoch 111: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.8881 - mae: 2.3212 - mse: 9.9594 - R2: 0.9927 - val_loss: 3.1176 - val_mae: 3.5839 - val_mse: 21.8380 - val_R2: 0.9823\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8109 - mae: 2.2524 - mse: 10.0111 - R2: 0.9927\n",
            "Epoch 112: val_loss did not improve from 2.65000\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.8109 - mae: 2.2524 - mse: 10.0111 - R2: 0.9927 - val_loss: 3.8426 - val_mae: 4.3242 - val_mse: 30.5523 - val_R2: 0.9752\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5494 - mae: 3.0081 - mse: 16.0971 - R2: 0.9883\n",
            "Epoch 113: val_loss improved from 2.65000 to 2.60992, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 487ms/step - loss: 2.5494 - mae: 3.0081 - mse: 16.0971 - R2: 0.9883 - val_loss: 2.6099 - val_mae: 3.0652 - val_mse: 15.7163 - val_R2: 0.9872\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9272 - mae: 2.3634 - mse: 10.2412 - R2: 0.9925\n",
            "Epoch 114: val_loss did not improve from 2.60992\n",
            "13/13 [==============================] - 5s 408ms/step - loss: 1.9272 - mae: 2.3634 - mse: 10.2412 - R2: 0.9925 - val_loss: 5.3129 - val_mae: 5.7997 - val_mse: 48.5797 - val_R2: 0.9606\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9374 - mae: 2.3829 - mse: 10.8167 - R2: 0.9921\n",
            "Epoch 115: val_loss did not improve from 2.60992\n",
            "13/13 [==============================] - 5s 410ms/step - loss: 1.9374 - mae: 2.3829 - mse: 10.8167 - R2: 0.9921 - val_loss: 5.5753 - val_mae: 6.0465 - val_mse: 59.2840 - val_R2: 0.9519\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0536 - mae: 2.4956 - mse: 11.5576 - R2: 0.9916\n",
            "Epoch 116: val_loss did not improve from 2.60992\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 2.0536 - mae: 2.4956 - mse: 11.5576 - R2: 0.9916 - val_loss: 3.4870 - val_mae: 3.9469 - val_mse: 31.6217 - val_R2: 0.9743\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0715 - mae: 2.5133 - mse: 12.6827 - R2: 0.9908\n",
            "Epoch 117: val_loss did not improve from 2.60992\n",
            "13/13 [==============================] - 5s 408ms/step - loss: 2.0715 - mae: 2.5133 - mse: 12.6827 - R2: 0.9908 - val_loss: 8.0861 - val_mae: 8.5479 - val_mse: 120.9567 - val_R2: 0.9018\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0354 - mae: 2.4879 - mse: 11.2034 - R2: 0.9918\n",
            "Epoch 118: val_loss did not improve from 2.60992\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 2.0354 - mae: 2.4879 - mse: 11.2034 - R2: 0.9918 - val_loss: 3.3542 - val_mae: 3.8346 - val_mse: 22.7747 - val_R2: 0.9815\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5060 - mae: 2.9588 - mse: 15.7170 - R2: 0.9886\n",
            "Epoch 119: val_loss did not improve from 2.60992\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 2.5060 - mae: 2.9588 - mse: 15.7170 - R2: 0.9886 - val_loss: 5.1111 - val_mae: 5.5960 - val_mse: 44.8900 - val_R2: 0.9636\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7536 - mae: 2.1888 - mse: 9.0945 - R2: 0.9934\n",
            "Epoch 120: val_loss did not improve from 2.60992\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.7536 - mae: 2.1888 - mse: 9.0945 - R2: 0.9934 - val_loss: 4.2665 - val_mae: 4.7502 - val_mse: 33.0533 - val_R2: 0.9732\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8578 - mae: 2.2999 - mse: 10.0461 - R2: 0.9927\n",
            "Epoch 121: val_loss did not improve from 2.60992\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.8578 - mae: 2.2999 - mse: 10.0461 - R2: 0.9927 - val_loss: 6.3227 - val_mae: 6.8031 - val_mse: 65.5605 - val_R2: 0.9468\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3003 - mae: 2.7406 - mse: 14.5165 - R2: 0.9894\n",
            "Epoch 122: val_loss improved from 2.60992 to 2.37093, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 480ms/step - loss: 2.3003 - mae: 2.7406 - mse: 14.5165 - R2: 0.9894 - val_loss: 2.3709 - val_mae: 2.8403 - val_mse: 13.1287 - val_R2: 0.9893\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7253 - mae: 2.1475 - mse: 8.8401 - R2: 0.9936\n",
            "Epoch 123: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.7253 - mae: 2.1475 - mse: 8.8401 - R2: 0.9936 - val_loss: 9.2993 - val_mae: 9.7732 - val_mse: 174.9566 - val_R2: 0.8580\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8109 - mae: 2.2477 - mse: 9.2304 - R2: 0.9933\n",
            "Epoch 124: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.8109 - mae: 2.2477 - mse: 9.2304 - R2: 0.9933 - val_loss: 3.6745 - val_mae: 4.1343 - val_mse: 29.9746 - val_R2: 0.9757\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9456 - mae: 2.3719 - mse: 13.2722 - R2: 0.9903\n",
            "Epoch 125: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 395ms/step - loss: 1.9456 - mae: 2.3719 - mse: 13.2722 - R2: 0.9903 - val_loss: 3.1287 - val_mae: 3.5987 - val_mse: 21.2715 - val_R2: 0.9827\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8108 - mae: 2.2498 - mse: 9.0529 - R2: 0.9934\n",
            "Epoch 126: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 1.8108 - mae: 2.2498 - mse: 9.0529 - R2: 0.9934 - val_loss: 5.0878 - val_mae: 5.5714 - val_mse: 47.7485 - val_R2: 0.9612\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6858 - mae: 2.1274 - mse: 8.1031 - R2: 0.9941\n",
            "Epoch 127: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 409ms/step - loss: 1.6858 - mae: 2.1274 - mse: 8.1031 - R2: 0.9941 - val_loss: 4.9701 - val_mae: 5.4670 - val_mse: 43.1050 - val_R2: 0.9650\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3616 - mae: 1.7883 - mse: 5.8025 - R2: 0.9958\n",
            "Epoch 128: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.3616 - mae: 1.7883 - mse: 5.8025 - R2: 0.9958 - val_loss: 3.7645 - val_mae: 4.2387 - val_mse: 31.2944 - val_R2: 0.9746\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6934 - mae: 2.1230 - mse: 8.9607 - R2: 0.9935\n",
            "Epoch 129: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.6934 - mae: 2.1230 - mse: 8.9607 - R2: 0.9935 - val_loss: 6.0460 - val_mae: 6.5302 - val_mse: 59.7089 - val_R2: 0.9515\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7326 - mae: 2.1784 - mse: 8.7103 - R2: 0.9937\n",
            "Epoch 130: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.7326 - mae: 2.1784 - mse: 8.7103 - R2: 0.9937 - val_loss: 4.1412 - val_mae: 4.6105 - val_mse: 35.5962 - val_R2: 0.9711\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0526 - mae: 2.4908 - mse: 13.2787 - R2: 0.9903\n",
            "Epoch 131: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 2.0526 - mae: 2.4908 - mse: 13.2787 - R2: 0.9903 - val_loss: 5.1042 - val_mae: 5.5690 - val_mse: 54.4463 - val_R2: 0.9558\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7393 - mae: 2.1732 - mse: 8.8049 - R2: 0.9936\n",
            "Epoch 132: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.7393 - mae: 2.1732 - mse: 8.8049 - R2: 0.9936 - val_loss: 5.9903 - val_mae: 6.4713 - val_mse: 64.1477 - val_R2: 0.9479\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8161 - mae: 2.2534 - mse: 10.3715 - R2: 0.9924\n",
            "Epoch 133: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.8161 - mae: 2.2534 - mse: 10.3715 - R2: 0.9924 - val_loss: 4.1643 - val_mae: 4.6325 - val_mse: 35.1367 - val_R2: 0.9715\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5797 - mae: 2.0136 - mse: 7.2059 - R2: 0.9948\n",
            "Epoch 134: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 392ms/step - loss: 1.5797 - mae: 2.0136 - mse: 7.2059 - R2: 0.9948 - val_loss: 5.4324 - val_mae: 5.9132 - val_mse: 51.9772 - val_R2: 0.9578\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0182 - mae: 2.4600 - mse: 10.7574 - R2: 0.9922\n",
            "Epoch 135: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 410ms/step - loss: 2.0182 - mae: 2.4600 - mse: 10.7574 - R2: 0.9922 - val_loss: 12.1370 - val_mae: 12.6227 - val_mse: 244.9041 - val_R2: 0.8012\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4454 - mae: 1.8727 - mse: 6.6959 - R2: 0.9951\n",
            "Epoch 136: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.4454 - mae: 1.8727 - mse: 6.6959 - R2: 0.9951 - val_loss: 2.7232 - val_mae: 3.1825 - val_mse: 18.1680 - val_R2: 0.9853\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8722 - mae: 2.3187 - mse: 10.0893 - R2: 0.9927\n",
            "Epoch 137: val_loss did not improve from 2.37093\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.8722 - mae: 2.3187 - mse: 10.0893 - R2: 0.9927 - val_loss: 4.6277 - val_mae: 5.1126 - val_mse: 39.1975 - val_R2: 0.9682\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9078 - mae: 2.3504 - mse: 10.2861 - R2: 0.9925\n",
            "Epoch 138: val_loss improved from 2.37093 to 2.33791, saving model to saved_models/ResNet_0deg_withTL/resnet_5.h5\n",
            "13/13 [==============================] - 6s 485ms/step - loss: 1.9078 - mae: 2.3504 - mse: 10.2861 - R2: 0.9925 - val_loss: 2.3379 - val_mae: 2.7826 - val_mse: 13.2940 - val_R2: 0.9892\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5885 - mae: 2.0242 - mse: 7.9951 - R2: 0.9942\n",
            "Epoch 139: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.5885 - mae: 2.0242 - mse: 7.9951 - R2: 0.9942 - val_loss: 4.6084 - val_mae: 5.0961 - val_mse: 40.8425 - val_R2: 0.9668\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6775 - mae: 2.1212 - mse: 7.6734 - R2: 0.9944\n",
            "Epoch 140: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.6775 - mae: 2.1212 - mse: 7.6734 - R2: 0.9944 - val_loss: 8.4857 - val_mae: 8.9756 - val_mse: 109.3121 - val_R2: 0.9113\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6168 - mae: 2.0577 - mse: 7.7781 - R2: 0.9943\n",
            "Epoch 141: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 390ms/step - loss: 1.6168 - mae: 2.0577 - mse: 7.7781 - R2: 0.9943 - val_loss: 3.3003 - val_mae: 3.7663 - val_mse: 23.6411 - val_R2: 0.9808\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0105 - mae: 2.4463 - mse: 13.1615 - R2: 0.9904\n",
            "Epoch 142: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 2.0105 - mae: 2.4463 - mse: 13.1615 - R2: 0.9904 - val_loss: 8.3140 - val_mae: 8.8033 - val_mse: 103.4145 - val_R2: 0.9161\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.0718 - mae: 2.5065 - mse: 12.5670 - R2: 0.9908\n",
            "Epoch 143: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 2.0718 - mae: 2.5065 - mse: 12.5670 - R2: 0.9908 - val_loss: 6.2353 - val_mae: 6.7249 - val_mse: 77.5989 - val_R2: 0.9370\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7538 - mae: 2.1962 - mse: 8.6242 - R2: 0.9937\n",
            "Epoch 144: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.7538 - mae: 2.1962 - mse: 8.6242 - R2: 0.9937 - val_loss: 7.9031 - val_mae: 8.3887 - val_mse: 135.6624 - val_R2: 0.8899\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6239 - mae: 2.0576 - mse: 7.8899 - R2: 0.9943\n",
            "Epoch 145: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.6239 - mae: 2.0576 - mse: 7.8899 - R2: 0.9943 - val_loss: 4.8244 - val_mae: 5.2863 - val_mse: 58.1523 - val_R2: 0.9528\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.1061 - mae: 2.5536 - mse: 12.4264 - R2: 0.9909\n",
            "Epoch 146: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 393ms/step - loss: 2.1061 - mae: 2.5536 - mse: 12.4264 - R2: 0.9909 - val_loss: 5.8982 - val_mae: 6.3766 - val_mse: 60.1851 - val_R2: 0.9511\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7567 - mae: 2.1922 - mse: 9.6762 - R2: 0.9930 \n",
            "Epoch 147: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 1.7567 - mae: 2.1922 - mse: 9.6762 - R2: 0.9930 - val_loss: 3.9156 - val_mae: 4.3848 - val_mse: 28.2772 - val_R2: 0.9770\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8871 - mae: 2.3321 - mse: 10.4539 - R2: 0.9924\n",
            "Epoch 148: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.8871 - mae: 2.3321 - mse: 10.4539 - R2: 0.9924 - val_loss: 3.8479 - val_mae: 4.3296 - val_mse: 31.7619 - val_R2: 0.9742\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4644 - mae: 1.8812 - mse: 7.3335 - R2: 0.9947\n",
            "Epoch 149: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.4644 - mae: 1.8812 - mse: 7.3335 - R2: 0.9947 - val_loss: 4.1851 - val_mae: 4.6509 - val_mse: 33.4319 - val_R2: 0.9729\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8017 - mae: 2.2264 - mse: 9.2062 - R2: 0.9933\n",
            "Epoch 150: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.8017 - mae: 2.2264 - mse: 9.2062 - R2: 0.9933 - val_loss: 4.5297 - val_mae: 4.9987 - val_mse: 51.9358 - val_R2: 0.9578\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6054 - mae: 2.0244 - mse: 8.0826 - R2: 0.9941\n",
            "Epoch 151: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.6054 - mae: 2.0244 - mse: 8.0826 - R2: 0.9941 - val_loss: 5.7703 - val_mae: 6.2406 - val_mse: 74.7057 - val_R2: 0.9394\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7162 - mae: 2.1514 - mse: 8.0918 - R2: 0.9941\n",
            "Epoch 152: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.7162 - mae: 2.1514 - mse: 8.0918 - R2: 0.9941 - val_loss: 7.9886 - val_mae: 8.4831 - val_mse: 119.9057 - val_R2: 0.9027\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7606 - mae: 2.1918 - mse: 10.1558 - R2: 0.9926\n",
            "Epoch 153: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 409ms/step - loss: 1.7606 - mae: 2.1918 - mse: 10.1558 - R2: 0.9926 - val_loss: 4.3052 - val_mae: 4.7679 - val_mse: 40.6708 - val_R2: 0.9670\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8850 - mae: 2.3308 - mse: 8.8360 - R2: 0.9936\n",
            "Epoch 154: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.8850 - mae: 2.3308 - mse: 8.8360 - R2: 0.9936 - val_loss: 5.2198 - val_mae: 5.6879 - val_mse: 53.4893 - val_R2: 0.9566\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8574 - mae: 2.2763 - mse: 10.2425 - R2: 0.9925\n",
            "Epoch 155: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.8574 - mae: 2.2763 - mse: 10.2425 - R2: 0.9925 - val_loss: 5.4676 - val_mae: 5.9423 - val_mse: 58.5505 - val_R2: 0.9525\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5141 - mae: 1.9311 - mse: 7.3315 - R2: 0.9947\n",
            "Epoch 156: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.5141 - mae: 1.9311 - mse: 7.3315 - R2: 0.9947 - val_loss: 5.3888 - val_mae: 5.8733 - val_mse: 50.2677 - val_R2: 0.9592\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6577 - mae: 2.0846 - mse: 8.2488 - R2: 0.9940\n",
            "Epoch 157: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.6577 - mae: 2.0846 - mse: 8.2488 - R2: 0.9940 - val_loss: 3.9675 - val_mae: 4.4357 - val_mse: 28.7973 - val_R2: 0.9766\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4496 - mae: 1.8712 - mse: 6.4936 - R2: 0.9953\n",
            "Epoch 158: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.4496 - mae: 1.8712 - mse: 6.4936 - R2: 0.9953 - val_loss: 3.9635 - val_mae: 4.4340 - val_mse: 31.1130 - val_R2: 0.9747\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3136 - mae: 1.7329 - mse: 5.8347 - R2: 0.9958\n",
            "Epoch 159: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 392ms/step - loss: 1.3136 - mae: 1.7329 - mse: 5.8347 - R2: 0.9958 - val_loss: 3.8248 - val_mae: 4.3088 - val_mse: 27.7464 - val_R2: 0.9775\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4828 - mae: 1.9072 - mse: 7.0406 - R2: 0.9949\n",
            "Epoch 160: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.4828 - mae: 1.9072 - mse: 7.0406 - R2: 0.9949 - val_loss: 4.9859 - val_mae: 5.4644 - val_mse: 46.8374 - val_R2: 0.9620\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7557 - mae: 2.1806 - mse: 9.3832 - R2: 0.9932\n",
            "Epoch 161: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.7557 - mae: 2.1806 - mse: 9.3832 - R2: 0.9932 - val_loss: 4.9946 - val_mae: 5.4714 - val_mse: 51.2632 - val_R2: 0.9584\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3769 - mae: 1.7892 - mse: 6.1189 - R2: 0.9955\n",
            "Epoch 162: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.3769 - mae: 1.7892 - mse: 6.1189 - R2: 0.9955 - val_loss: 6.3937 - val_mae: 6.8725 - val_mse: 72.4510 - val_R2: 0.9412\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5261 - mae: 1.9496 - mse: 7.3504 - R2: 0.9946\n",
            "Epoch 163: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.5261 - mae: 1.9496 - mse: 7.3504 - R2: 0.9946 - val_loss: 5.8717 - val_mae: 6.3661 - val_mse: 57.7804 - val_R2: 0.9531\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5344 - mae: 1.9619 - mse: 7.7313 - R2: 0.9944\n",
            "Epoch 164: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 383ms/step - loss: 1.5344 - mae: 1.9619 - mse: 7.7313 - R2: 0.9944 - val_loss: 5.5439 - val_mae: 6.0362 - val_mse: 52.8045 - val_R2: 0.9571\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6181 - mae: 2.0572 - mse: 8.0038 - R2: 0.9942\n",
            "Epoch 165: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 406ms/step - loss: 1.6181 - mae: 2.0572 - mse: 8.0038 - R2: 0.9942 - val_loss: 8.8958 - val_mae: 9.3952 - val_mse: 116.1546 - val_R2: 0.9057\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6297 - mae: 2.0377 - mse: 8.3083 - R2: 0.9939\n",
            "Epoch 166: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.6297 - mae: 2.0377 - mse: 8.3083 - R2: 0.9939 - val_loss: 6.5579 - val_mae: 7.0486 - val_mse: 71.3825 - val_R2: 0.9421\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2230 - mae: 1.6288 - mse: 5.8061 - R2: 0.9958\n",
            "Epoch 167: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 390ms/step - loss: 1.2230 - mae: 1.6288 - mse: 5.8061 - R2: 0.9958 - val_loss: 3.2159 - val_mae: 3.6869 - val_mse: 21.9308 - val_R2: 0.9822\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6334 - mae: 2.0495 - mse: 8.0710 - R2: 0.9941\n",
            "Epoch 168: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.6334 - mae: 2.0495 - mse: 8.0710 - R2: 0.9941 - val_loss: 3.4940 - val_mae: 3.9808 - val_mse: 24.9775 - val_R2: 0.9797\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5763 - mae: 2.0078 - mse: 8.2013 - R2: 0.9940\n",
            "Epoch 169: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.5763 - mae: 2.0078 - mse: 8.2013 - R2: 0.9940 - val_loss: 5.4173 - val_mae: 5.8835 - val_mse: 52.8592 - val_R2: 0.9571\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5090 - mae: 1.9341 - mse: 7.1352 - R2: 0.9948\n",
            "Epoch 170: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.5090 - mae: 1.9341 - mse: 7.1352 - R2: 0.9948 - val_loss: 4.5765 - val_mae: 5.0599 - val_mse: 37.9751 - val_R2: 0.9692\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4546 - mae: 1.8759 - mse: 6.7161 - R2: 0.9951\n",
            "Epoch 171: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.4546 - mae: 1.8759 - mse: 6.7161 - R2: 0.9951 - val_loss: 3.6870 - val_mae: 4.1454 - val_mse: 32.0079 - val_R2: 0.9740\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5417 - mae: 1.9651 - mse: 7.3399 - R2: 0.9947\n",
            "Epoch 172: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.5417 - mae: 1.9651 - mse: 7.3399 - R2: 0.9947 - val_loss: 6.0074 - val_mae: 6.4998 - val_mse: 57.4206 - val_R2: 0.9534\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3135 - mae: 1.7389 - mse: 5.5870 - R2: 0.9959\n",
            "Epoch 173: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.3135 - mae: 1.7389 - mse: 5.5870 - R2: 0.9959 - val_loss: 4.6032 - val_mae: 5.0937 - val_mse: 38.4607 - val_R2: 0.9688\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3182 - mae: 1.7343 - mse: 5.6875 - R2: 0.9959\n",
            "Epoch 174: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 393ms/step - loss: 1.3182 - mae: 1.7343 - mse: 5.6875 - R2: 0.9959 - val_loss: 2.6338 - val_mae: 3.1014 - val_mse: 16.4713 - val_R2: 0.9866\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6536 - mae: 2.0843 - mse: 8.6743 - R2: 0.9937\n",
            "Epoch 175: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.6536 - mae: 2.0843 - mse: 8.6743 - R2: 0.9937 - val_loss: 4.9861 - val_mae: 5.4524 - val_mse: 49.9719 - val_R2: 0.9594\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5215 - mae: 1.9452 - mse: 7.3817 - R2: 0.9946\n",
            "Epoch 176: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.5215 - mae: 1.9452 - mse: 7.3817 - R2: 0.9946 - val_loss: 5.5608 - val_mae: 6.0359 - val_mse: 56.6665 - val_R2: 0.9540\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1609 - mae: 1.5775 - mse: 4.4336 - R2: 0.9968\n",
            "Epoch 177: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 392ms/step - loss: 1.1609 - mae: 1.5775 - mse: 4.4336 - R2: 0.9968 - val_loss: 2.6614 - val_mae: 3.1350 - val_mse: 15.2174 - val_R2: 0.9876\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4244 - mae: 1.8463 - mse: 7.2144 - R2: 0.9947\n",
            "Epoch 178: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.4244 - mae: 1.8463 - mse: 7.2144 - R2: 0.9947 - val_loss: 6.0267 - val_mae: 6.5193 - val_mse: 59.5513 - val_R2: 0.9517\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.8364 - mae: 2.2815 - mse: 9.0707 - R2: 0.9934\n",
            "Epoch 179: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.8364 - mae: 2.2815 - mse: 9.0707 - R2: 0.9934 - val_loss: 2.8832 - val_mae: 3.3518 - val_mse: 19.2964 - val_R2: 0.9843\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9655 - mae: 2.4023 - mse: 10.7958 - R2: 0.9921\n",
            "Epoch 180: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.9655 - mae: 2.4023 - mse: 10.7958 - R2: 0.9921 - val_loss: 3.7915 - val_mae: 4.2629 - val_mse: 29.2010 - val_R2: 0.9763\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3373 - mae: 1.7610 - mse: 5.6525 - R2: 0.9959\n",
            "Epoch 181: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 411ms/step - loss: 1.3373 - mae: 1.7610 - mse: 5.6525 - R2: 0.9959 - val_loss: 3.8457 - val_mae: 4.3268 - val_mse: 29.5818 - val_R2: 0.9760\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6446 - mae: 2.0823 - mse: 7.2131 - R2: 0.9947\n",
            "Epoch 182: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.6446 - mae: 2.0823 - mse: 7.2131 - R2: 0.9947 - val_loss: 5.2147 - val_mae: 5.6994 - val_mse: 53.5948 - val_R2: 0.9565\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4847 - mae: 1.9213 - mse: 6.2431 - R2: 0.9955\n",
            "Epoch 183: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 1.4847 - mae: 1.9213 - mse: 6.2431 - R2: 0.9955 - val_loss: 4.9767 - val_mae: 5.4634 - val_mse: 43.3502 - val_R2: 0.9648\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4699 - mae: 1.9020 - mse: 6.5515 - R2: 0.9952\n",
            "Epoch 184: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.4699 - mae: 1.9020 - mse: 6.5515 - R2: 0.9952 - val_loss: 4.9007 - val_mae: 5.3908 - val_mse: 42.3240 - val_R2: 0.9656\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1694 - mae: 1.5804 - mse: 4.5862 - R2: 0.9967\n",
            "Epoch 185: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.1694 - mae: 1.5804 - mse: 4.5862 - R2: 0.9967 - val_loss: 3.2137 - val_mae: 3.6799 - val_mse: 23.9970 - val_R2: 0.9805\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5784 - mae: 2.0079 - mse: 7.9560 - R2: 0.9942\n",
            "Epoch 186: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.5784 - mae: 2.0079 - mse: 7.9560 - R2: 0.9942 - val_loss: 3.6524 - val_mae: 4.1334 - val_mse: 29.2887 - val_R2: 0.9762\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4221 - mae: 1.8394 - mse: 6.0572 - R2: 0.9956\n",
            "Epoch 187: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.4221 - mae: 1.8394 - mse: 6.0572 - R2: 0.9956 - val_loss: 6.4029 - val_mae: 6.8897 - val_mse: 75.2560 - val_R2: 0.9389\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4355 - mae: 1.8536 - mse: 7.2006 - R2: 0.9948\n",
            "Epoch 188: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 389ms/step - loss: 1.4355 - mae: 1.8536 - mse: 7.2006 - R2: 0.9948 - val_loss: 8.4606 - val_mae: 8.9461 - val_mse: 129.1871 - val_R2: 0.8951\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1444 - mae: 1.5557 - mse: 4.6077 - R2: 0.9966\n",
            "Epoch 189: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 385ms/step - loss: 1.1444 - mae: 1.5557 - mse: 4.6077 - R2: 0.9966 - val_loss: 2.4849 - val_mae: 2.9403 - val_mse: 15.2613 - val_R2: 0.9876\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5579 - mae: 1.9947 - mse: 7.2497 - R2: 0.9947\n",
            "Epoch 190: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 386ms/step - loss: 1.5579 - mae: 1.9947 - mse: 7.2497 - R2: 0.9947 - val_loss: 3.1918 - val_mae: 3.6650 - val_mse: 24.4220 - val_R2: 0.9802\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2285 - mae: 1.6444 - mse: 5.2398 - R2: 0.9962\n",
            "Epoch 191: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.2285 - mae: 1.6444 - mse: 5.2398 - R2: 0.9962 - val_loss: 7.0887 - val_mae: 7.5654 - val_mse: 79.4029 - val_R2: 0.9355\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2507 - mae: 1.6666 - mse: 5.7463 - R2: 0.9958\n",
            "Epoch 192: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 390ms/step - loss: 1.2507 - mae: 1.6666 - mse: 5.7463 - R2: 0.9958 - val_loss: 2.5403 - val_mae: 3.0083 - val_mse: 15.2801 - val_R2: 0.9876\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4658 - mae: 1.8869 - mse: 7.0394 - R2: 0.9949\n",
            "Epoch 193: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 396ms/step - loss: 1.4658 - mae: 1.8869 - mse: 7.0394 - R2: 0.9949 - val_loss: 6.9869 - val_mae: 7.4680 - val_mse: 83.6782 - val_R2: 0.9321\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9569 - mae: 1.3585 - mse: 3.2827 - R2: 0.9976\n",
            "Epoch 194: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 0.9569 - mae: 1.3585 - mse: 3.2827 - R2: 0.9976 - val_loss: 10.2592 - val_mae: 10.7506 - val_mse: 153.2464 - val_R2: 0.8756\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2295 - mae: 1.6327 - mse: 5.6679 - R2: 0.9959\n",
            "Epoch 195: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 391ms/step - loss: 1.2295 - mae: 1.6327 - mse: 5.6679 - R2: 0.9959 - val_loss: 7.9841 - val_mae: 8.4806 - val_mse: 91.7660 - val_R2: 0.9255\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3622 - mae: 1.7853 - mse: 6.3791 - R2: 0.9954\n",
            "Epoch 196: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.3622 - mae: 1.7853 - mse: 6.3791 - R2: 0.9954 - val_loss: 2.7045 - val_mae: 3.1683 - val_mse: 16.1818 - val_R2: 0.9869\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.4407 - mae: 1.8590 - mse: 6.5450 - R2: 0.9952\n",
            "Epoch 197: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 393ms/step - loss: 1.4407 - mae: 1.8590 - mse: 6.5450 - R2: 0.9952 - val_loss: 9.4944 - val_mae: 9.9763 - val_mse: 143.8011 - val_R2: 0.8833\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2304 - mae: 1.6427 - mse: 5.3829 - R2: 0.9961\n",
            "Epoch 198: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 387ms/step - loss: 1.2304 - mae: 1.6427 - mse: 5.3829 - R2: 0.9961 - val_loss: 7.0905 - val_mae: 7.5635 - val_mse: 94.8235 - val_R2: 0.9230\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3867 - mae: 1.8042 - mse: 6.4073 - R2: 0.9953\n",
            "Epoch 199: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 384ms/step - loss: 1.3867 - mae: 1.8042 - mse: 6.4073 - R2: 0.9953 - val_loss: 3.2357 - val_mae: 3.7083 - val_mse: 22.4227 - val_R2: 0.9818\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2540 - mae: 1.6709 - mse: 5.3556 - R2: 0.9961\n",
            "Epoch 200: val_loss did not improve from 2.33791\n",
            "13/13 [==============================] - 5s 388ms/step - loss: 1.2540 - mae: 1.6709 - mse: 5.3556 - R2: 0.9961 - val_loss: 13.4913 - val_mae: 13.9746 - val_mse: 319.5347 - val_R2: 0.7406\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 2.1315 - mae: 2.5753 - mse: 11.2980 - R2: 0.9908\n"
          ]
        }
      ],
      "source": [
        "for train_index, val_index in kf.split(np.zeros(Y.shape[0]),Y):\n",
        "  training_data = train_df.iloc[train_index]\n",
        "  validation_data = train_df.iloc[val_index]\n",
        "\t\n",
        "  train_images = train_generator.flow_from_dataframe(training_data,\n",
        "                                                 x_col = \"Filepath\", y_col = \"Turbidity\",\n",
        "                                                 target_size=(224, 224), color_mode='rgb',\n",
        "                                                 class_mode = \"raw\", shuffle = True)\n",
        "  val_images  = train_generator.flow_from_dataframe(validation_data,\n",
        "                                                  x_col = \"Filepath\", y_col = \"Turbidity\",\n",
        "                                                  target_size=(224, 224), color_mode='rgb',\n",
        "                                                  class_mode = \"raw\", shuffle = True)\n",
        "\t\n",
        "\t# CREATE NEW MODEL\n",
        "  model = get_model()\n",
        "\t# COMPILE NEW MODEL\n",
        "  opt = tf.keras.optimizers.Nadam(learning_rate=1e-4)\n",
        "  model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=['mae','mse', tfa.metrics.RSquare(name=\"R2\")])\n",
        "\t\n",
        "\t# CREATE CALLBACKS\n",
        "  checkpoint_filepath = f'{save_dir}/{get_model_name(fold_var)}'\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                  monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "  callbacks_list = [checkpoint]\n",
        "\t# There can be other callbacks, but just showing one because it involves the model name\n",
        "\t# This saves the best model\n",
        "\t# FIT THE MODEL\n",
        "  history = model.fit(train_images, epochs=200,\n",
        "                      callbacks=callbacks_list,\n",
        "                      validation_data=val_images)\n",
        "\t\n",
        "\t# LOAD BEST MODEL to evaluate the performance of the model\n",
        "  model.load_weights(f\"{save_dir}/resnet_\"+str(fold_var)+\".h5\")\n",
        "\t\n",
        "  results = model.evaluate(val_images)\n",
        "  results = dict(zip(model.metrics_names,results))\n",
        "\t\n",
        "  VALIDATION_R2.append(results['R2'])\n",
        "  VALIDATION_MAE.append(results['mae'])\n",
        "  VALIDATION_MSE.append(results['mse'])\n",
        "  VALIDATION_LOSS.append(results['loss'])\n",
        "\t\n",
        "  tf.keras.backend.clear_session()\n",
        "\t\n",
        "  fold_var += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xh612vvHYGtn",
        "outputId": "a0682ed5-4adc-4359-882a-6a4cabdd9212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 486 validated image filenames.\n",
            "Found 55 validated image filenames.\n",
            "Found 25 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "val_df = pd.read_csv(r'./Datasets/0degree_val/0degInfo.csv')\n",
        "\n",
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Turbidity',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Turbidity',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "val_images = val_generator.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Turbidity',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "baxFnh3YYGtn"
      },
      "outputs": [],
      "source": [
        "min_fold = min(range(len(VALIDATION_LOSS)), key=VALIDATION_LOSS.__getitem__) + 1\n",
        "\n",
        "model = get_model()\n",
        "model.load_weights(f\"{save_dir}/resnet_\"+str(min_fold)+\".h5\")\n",
        "opt = tf.keras.optimizers.Nadam()\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=['mae','mse', tfa.metrics.RSquare(name=\"R2\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tFCSQyKH46W4",
        "outputId": "9a56d140-27bb-459e-b5ad-494a845bc050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 10.2429 - mae: 10.6817 - mse: 240.6168 - R2: 0.2380\n",
            "sampel air score   [10.242905616760254, 10.681726455688477, 240.6167755126953, 0.23802798986434937]\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 1.2360 - mae: 1.6636 - mse: 4.8212 - R2: 0.9964\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 2.1365 - mae: 2.5963 - mse: 9.6388 - R2: 0.9910\n",
            "test   [2.1364853382110596, 2.596308469772339, 9.638751983642578, 0.9910481572151184]\n",
            "train   [1.236011266708374, 1.663588523864746, 4.821241855621338, 0.9964161515235901]\n"
          ]
        }
      ],
      "source": [
        "pred = np.squeeze(model.predict(val_images))\n",
        "true = val_images.labels\n",
        "residuals = true - pred\n",
        "\n",
        "score = model.evaluate(val_images)\n",
        "print('sampel air score  ',score)\n",
        "\n",
        "test_pred = np.squeeze(model.predict(test_images))\n",
        "test_true = test_images.labels\n",
        "test_residuals = test_true - test_pred\n",
        "\n",
        "train_pred = np.squeeze(model.predict(train_images))\n",
        "train_true = train_images.labels\n",
        "train_residuals = train_true - train_pred\n",
        "\n",
        "train_score = model.evaluate(train_images)\n",
        "test_score = model.evaluate(test_images)\n",
        "print('test  ',test_score)\n",
        "print('train  ', train_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1_Wni6g1YGtp",
        "outputId": "3996d190-fb44-4ba5-a235-8bc064ef961f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Predicted  True Val\n",
              "3    0.380346       0.8\n",
              "16   0.317400       0.8\n",
              "8    0.369508       0.8\n",
              "9    0.725713       0.8\n",
              "14   0.478331       0.8\n",
              "4    2.898595       9.7\n",
              "19   3.449304       9.7\n",
              "18   3.812623       9.7\n",
              "10   2.607710       9.7\n",
              "13   2.842860       9.7\n",
              "12  14.749599      18.9\n",
              "21  18.801678      18.9\n",
              "20   9.582993      18.9\n",
              "24   3.431005      18.9\n",
              "11  12.526760      18.9\n",
              "5   32.226528      41.6\n",
              "1   60.237236      41.6\n",
              "22  58.337353      41.6\n",
              "23  42.756458      41.6\n",
              "0   56.212067      41.6\n",
              "15  69.651154      46.4\n",
              "7   74.785515      46.4\n",
              "17  52.641842      46.4\n",
              "6   87.607780      46.4\n",
              "2   83.814720      46.4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76127b9a-bba8-48fa-96ad-8435587ee7af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>True Val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.380346</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.317400</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.369508</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.725713</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.478331</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.898595</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3.449304</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3.812623</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.607710</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2.842860</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>14.749599</td>\n",
              "      <td>18.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>18.801678</td>\n",
              "      <td>18.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>9.582993</td>\n",
              "      <td>18.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3.431005</td>\n",
              "      <td>18.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12.526760</td>\n",
              "      <td>18.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>32.226528</td>\n",
              "      <td>41.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60.237236</td>\n",
              "      <td>41.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>58.337353</td>\n",
              "      <td>41.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>42.756458</td>\n",
              "      <td>41.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56.212067</td>\n",
              "      <td>41.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>69.651154</td>\n",
              "      <td>46.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>74.785515</td>\n",
              "      <td>46.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>52.641842</td>\n",
              "      <td>46.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>87.607780</td>\n",
              "      <td>46.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>83.814720</td>\n",
              "      <td>46.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76127b9a-bba8-48fa-96ad-8435587ee7af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76127b9a-bba8-48fa-96ad-8435587ee7af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76127b9a-bba8-48fa-96ad-8435587ee7af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "predicted = pd.Series(pred)\n",
        "truevalue = pd.Series(true)\n",
        "frame = { 'Predicted': predicted, 'True Val': truevalue }\n",
        "result = pd.DataFrame(frame)\n",
        "rslt_df = result.sort_values(by = 'True Val')\n",
        "rslt_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Kbpd3Jx4YGtq",
        "outputId": "8756f59a-7463-48f9-a06d-80a6bf47df9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test (0.9825067520141602, 0.6013597249984741)\n",
            "train (0.9660959839820862, 3.6865959174292584e-09)\n",
            "air (0.854407548904419, 0.002137856325134635)\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import shapiro\n",
        "\n",
        "#perform Shapiro-Wilk test\n",
        "shap_test = shapiro(test_residuals)\n",
        "shap_train = shapiro(train_residuals)\n",
        "shap_air = shapiro(residuals)\n",
        "\n",
        "print('test', shap_test)\n",
        "print('train', shap_train)\n",
        "print('air', shap_air)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OIQTkGf8SEUC",
        "outputId": "05b5ca17-6a37-4cbd-f0f1-24e61615263e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAGECAYAAABj6sl8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9e5xcZX34/37Omeves5vN5kJuhEAIJAGN+YGJEloUqmAtgqX8sKSpX0RsQf2C1Pq1YuuNwteqP6QUNY0oFlvxhrYxKgYIECMghkiCIffLJtlL9jazczvn+f1xzpnMzs7Mzs7O7sxuPu/Xa14zc+ZcnnPOM+f5PJ+r0lojCIIgCIJQCkalGyAIgiAIwuRFBAlBEARBEEpGBAlBEARBEEpGBAlBEARBEEpGBAlBEARBEEpGBAlBEARBEEpGBAmh4iil1imltFLqwAjrafe1tszHv8fd75Yy7Gtc2iiUF6XUWu9eVbot+VBKLcjoTwtGWLdsfVgQRosIEkJelFJbMh5kWik1oJTapZT6hFJKlfFQrwJfBjaUcZ9lJUPY8V62UuqYUur7SqllY9x32QcBpdSBrPb2KqVeVkrdUq5juMfJvC7fzVi+pthBMGt/G91tNo5imxlKqW8qpTqUUjH3PK8f1YlUJ304/4svu59L7iuZglOB1z1Zwsvasp+RMCXxVboBwqRgF/BzYBlwOfAZ4DjwjXLsXGu9Hdhejn1NEF8GAsA7gD8D1iillmqtOyvbrJz8GufaXgqsBP5NKbVXa/3LcTjW9Uqp+7XWvxmHfefEFWifAFYBrwCbgD8H/lMpdZ3W+vGJaku50Vp3Ax8u0+6O4PRbgAbgr9zPj7u/AWwr07GEMw2ttbzklfMFbAE0sNH9bgBd7rIHMtarBz4P7AaiwB+AfwTC7u8+4IvAISDu7mM7cK37+zp3nwcy9jkX+G+gH3gduN5dRwNr3XU2ZrYvq833uN/PBZ4BOoCku7+ngbdmbHOPu82WAtfCa6POWLYyo03vcpdlt9EA/hp4yT32MeDHwIqsc8h+LRjjvTuQdR2aMvZ9Z8Z6M4B/Bfa69+73OIOX6f5eB/w70A4k3Ov4DLAm+7oAtncNgTXZ55LjWhwBvgWclXXvhrxGOM93uuvFgEZ32efdZS9nrPdW97iDwHPA7TnuZ8F+7K6z1O0/EWAH8JfF3jPgP9317nO/v9v9vjPjWifdZcuABZn7LtRXON2HnwY+DZwAuoGHvHuZ0Y7M/a4t9jd5ySvfS0wbQlG4M78VOA9bgBczlv8M+DsgBTyKM+B8EviOu+77gI/gzOL/HfgfIIjzsMx1LANnlvknQA/OAPN/S2x6i3vcnwIPA78D3gL8UCnVUuI+UUr5gbUZizryrPo54Os4A9D3cQbsa4BtSqkVwGYcrQHAUbJU2eXAvZ5vzljk3bsa4HngVhzh7ltALfAvwP3uunfhCAtR4GvAL4CZwKIch3oUuEwpdU2epnjXYhbOtXgVuAl4TilVD3wPR/uF++5di0KsdN93a6173c/Pue/LlVK1SqmzcDQVF+MISn/AERjSFNOPlVJ1OJq5t+DcqxeAL43Qvkx+7r6/1X1f674vVUq14ghfPuC41vqVHNsX01fWANe6x2oAPgD8v6NooyCMGjFtCMVws/sCZ8b0MZzZEcBqHLU5ODPVOPBb4ALg3a59POj+fgBnANmjtd6vlMrX/1bhCC3gzPR/q5R6I86De1RorZ9XSn0Q+COc2ffLbpunAW/CGWBGRQ4Hvf8ih1pYKRXAmfkCfEJr/X/dAesVnOvzt1rr9yulzgX+H+B1rXVeVbZSahVwY8ai7Vrr7+Rb3+VT7gscLcDfaK1/5X6/FjgbZzbvDb6/A+YDH1RK/R2n792rOAP9H7TWR/Pcu/+Dozn6AnBbVtsDwN+6X38DnHJfb8HRPr1Ha/2AUmolcL57bsWo9WdlnBtZnxWOJuYmIIwj7L1Za51QSr3CaWEJiuvHlwCzAQtHo3VcKfUz4LEi2gmOEAbwBlcoWYtzXZcClwFvdH/PaXbSWn8nX1/JcFnqBS7VWg8opZpwNDZvAh4pso2CMGpEkBCKYRfwFI4/QBvOYPFVnFnq/Iz1bs2x7VzgmzgP6T/DmfWhlDoOfAhHsMhmXsbnV933nUW2dUifVkrdQf5ZY1uR+8zmyziDyUlgm9b6qTzrteIMYOC2X2utlVI7cQaoeXm2y8dS4I6M79/ktNYnH792j309zgz1OqXUt7XWNqfvXShrv+AIEDNwTFJLgLcDVwMopfbhCJZbMzfQWh9USj0A/G9gfdb+WoEa93MujcXcEc4jH+3ue33GMu+zxhlYveu8V2udcD9n96di+rG3nw6t9XH38++KbagrPO/F0eZcAyzHue6fxPE9eoO76s9z76EoXtVaD7ifu9z3+nwrC0I5ENOGUAzbtdYfBP4YRyPxJhwVMDh+D+DYxxdorZX3AhZrrZ8BbK31zUAjjg32/+Cox/85z/EOZ3xe6r5fmGM974HZDKCUCgLnZa2zzn3/Txy1/ayM30qKPNFaf1hr/b+11vcWECIAOnFs8uAIDp4K/QJ3mXftUu57wf+j1npj5vXVWq8rormbtNbvxxEkwBnAvO28458CGrLu3Tla68NAn9b63TiD0WIcAfJsHJt8Lj6HY466KWt5B6evxfuyjjWH09qBoq5FBi+67+crpRrdz6vd91fcQdXrT4tczQgM70/F9OOD7jrTlVLT3c+jjdjxtBKfwOl/W3D8Gq7itEbiF8M3SzPS9UlmfK7a0FZhaiGChFA0WuvfczpS4yNKqRnAszizXgN4Xin1NaXUt5VSOzg9s/oLdyb2HRyb+5+6y7vzHOrXOOp/gB8rpb4O/DDHel50wJVKqS+6x5uetc4x9/0y4CsUfkiXFa11HHjA/fpZpdQ3cTQ7F+Kozr/q/uYNUG9SSj2klPrMOLRlM6fNOPe4Qtf3ccxN04DfKqX+TSn1mFLqdU7f57tdM8A3cfxc/thdnvPeaSfS4HNkPVtcTYB3vg8rpf5DKfV1pdRTOIO4px3yrsU7lVIPKKU+OsKp/RTH5BUAnlFKfQvwtvGu46M45ptWHH+MjcA/Ze2nmH78ExzfBJ97rG/gODOOBm9fF+BoDHbiCBNnA35gl9b6aIHtx72vZPCgUmpbxuuT43gsYTJTaW9PeVXvi6yoDXfZbByThga+5C5rxBk8XsOZdXbgqL1vd3+/BPgVjikgiTNT/wmwxP19HcOjNubjOGX2A/twHMayIyJ8wL/hDGqHcdTwzzE0WmERzuA9iBP98e6M/axz17mHEqI28qyXK2rjAzj29n6csNmfAG/I2CaEM6j3utt2luHeHci8Du6yi3Fm3Br4sLtsJvAgjhNozG3fz4Eb3d+vca9pF47z4Qkcn4BZ+a6Lez4HM67Fgoxr8b9wtAi9OE6CO3C0EXXuOjNwfAQi7rYvFHGubTiOol04AtrvgBuy1lnr3oNBHIHhoznaXbAfu+t4URtRt+23ZJznWUW0dRqOWUwDP3CXXZixj69krLsgxzXM2VfI0YfJEdWUY79rC/yW/do40vnJ68x8Ka1F+yUIglAMSqlpWutTGd9vxhmwI8A0rXUy37aCMFURZ0tBEKoapdTfAOfk+Ol1rfUDOZaPJ19USrXh5EFp5XQ005e01skqa6sgTAiikRAEoapx00FfluOnp7TWaye4LR/CMYvMwdFC7MHx/fi21lpXU1sFYaIQQUIQBEEQhJKRqA1BEARBEEpGBAlBEARBEEpGBAlBEARBEEpmSkRtTJ8+XS9YsKDk7SORCLW1teVr0AQz2dsPcg7VwGRvP8g5TBQvvvhip9a6daT1xvpsFgpT7H0Yb6aEILFgwQJeeGHU9ZzSbNmyhbVr15avQRPMZG8/yDlUA5O9/SDnMFEopQ6OvNbYn81CYYq9D+ONmDYEQRAEQSgZESQEQRAEQSgZESQEQRAEQSiZKeEjIQiCkI9kMsmRI0eIxWKVbkpRNDY2smvXrko3A4BQKMRZZ52F3++vdFOEKkYECUEQpjRHjhyhvr6eBQsWoJSqdHNGpL+/n/r6+ko3A601XV1dHDlyhIULF1a6OUIVI6YNQRCmNLFYjJaWlkkhRFQTSilaWlomjSZHqBwiSAiCMOURIaI05LoJxSCChCAIwjjS1dXFRRddxEUXXcTMmTOZM2dO+nsikSi47QsvvMDtt98+quNt2LCBZcuWsXz5ci688EJ+9KMfFVz/hz/8Ia+++uqojiEImYiPhCAIwjjS0tLCyy+/DMA999xDXV0dd955Z/r3VCqFz5f7Ubxy5UpWrlxZ9LGOHDnCZz/7WV566SUaGxsZGBigo6Oj4DY//OEPufrqq1m6dGnRxxGETESQECrC1j0dbHh2P4e6B5nXHObaWalKN0kQgOF9c/3qhaxZXN4sxOvWrSMUCvHb3/6W1atXc8MNN3DHHXcQi8UIBAI88sgjnHfeeWzZsoX777+fn/zkJ9xzzz0cOnSIffv2cejQIT784Q8P01acPHmS+vp66urqAKirq0t/3rt3Lx/60Ifo6OigpqaGr33ta3R3d/PjH/+Yp556is985jM8/vjjLFq0qKznKkx9RJAQJpytezr49BOvEvIbtNT66eiP0x6OsXVPR9kf2IIwGnL1zU8/8SqfumZp2fvmkSNHeO655zBNk76+Pp555hl8Ph8//vGP+fu//3sef/zxYdvs3r2bX/3qV/T393PeeefxwQ9+cEho5ooVK2hra2PhwoX88R//Mddeey3XXHMNALfccgsPPfQQixcv5te//jW33XYbTz75JO9617u4+uqrue6668p6fsKZgwgSwoSz4dn9hPwGtUGn+9UGfSjlLBdBQqgkufompMalb15//fWYpglAb28vN998M3v27EFrjWVZObd55zvfSTAYJBgMMmPGDE6cOMFZZ52V/t00TTZt2sRvfvMbfvnLX/KRj3yEF198kTvvvJPnnnuO66+/Pr1uPB4v6/kIZy7ibClMOIe6B6kJmEOWGYbiUPdghVokCA65+mZNwByXvplZ4fOTn/wkl19+OTt37uS73/1u3pDLYDCY/myaJqnUcJOgUopVq1bx8Y9/nMcee4zHH38c27Zpamri5ZdfTr8mIunVrvY+Vn32F+N+HKGyiCAhTDjzmsNEE0NnXLatmdccrlCLBMEhV9+MJqxx75u9vb3MmTMHgEcffbTk/Rw7doyXXnop/f3ll19m/vz5NDQ0sHDhQv7rv/4LcJJN/e53vwOgvr6e/v7+MbReONMRQUKYcNavXkgsaROJp9Bau+/OckGoJLn6Zixpj3vf/NjHPsbHP/5xLr744pxahmJJJpPceeedLFmyhIsuuojvfve7fPnLXwYcAeUb3/gGK1as4IILLkiHhd5www3cd999XHzxxezdu7cs5yOcWYiPhDDhrFncyqeuWTrEM35WU0j8I4SKk6tvljNq45577sm5/NJLL+UPf/gD4KTIvu+++wBYu3Yta9euzbntzp07h+1n/vz5PPnkkzmPsXDhQjZt2jRs+erVqyWPhDAmRJAQKsKaxa1DHs5btmypXGMEIYPsvikIQmHEtCEIgiAIQsmIICEIgiCMC+fPamD7J66odDOEcUYECUEQBEEQSkYECUEQBEEQSkYECUEQBEEQSkYECUEQhHFkLGXEwYloeu6553L+duLECa6++mpWrFjB0qVLecc73lFwXz09PTz44IMlnYcg5EPCPwVBEMaRkcqIj8SWLVuoq6vjzW9+87Df/uEf/oG3ve1t3HHHHQDs2LGj4L48QeK2224bxRkIQmFEIyEIgpDJ3i3w6HvhgVXO+94tZT/Eiy++yGWXXcYb3/hGrrzyStrb2wH4yle+wpve9CaWL1/ODTfcwIEDB3jooYf4l3/5Fy666CKeeeaZIftpb28fUrRr+fLl6c/33Xdfel+f+tSnAPi7v/s79u7dy0UXXcRdd91V9vMSzkxEIyEIguCxdwtsuht8YahthYGTzver7oVFa8tyCK01f/u3f8uPfvQjWltb+e53v8snPvEJNmzYwBe+8AV27NjB9OnT6enpoampiVtvvTWvFuNDH/oQf/7nf84DDzzAFVdcwV/91V8xe/ZsNm/ezJ49e9i+fTtaa971rnfx9NNP84UvfIGdO3emNSSCUA5EkBAEQfDY9qAjRATrnO/e+7YHyyZIxONxdu7cydve9jYALMti1qxZgKNReP/73891113Hu9/97hH3deWVV7Jv3z42bdrE//zP/3DxxRezc+dONm/ezObNm7n44osBGBgYYM+ePcybN68s5yAImYggIQiC4HHqgKOJyCRQ6ywvE1prLrjgAp5//vlhv/30pz9l06ZN/PKXv+Szn/0sr7zyyoj7a25u5sYbb+TGG2/k6quv5umnn0Zrzcc//nE+8IEPDFn3wIED5ToNQUgjPhKCIAge0xZAIjJ0WSLiLC8TwWCQjo6OtCCRTCb5/e9/j23bHD58mLe+9a3ce++99Pb2MjAwULDM95NPPkk0GgWcYl979+5l3rx5XHnllWzYsIGBgQEAjh49ysmTJ6VkuDAuiCAhCILgccltkBqE+ABo7bynBp3lZcIwDL73ve9x9913s2LFCi666CKee+45LMvipptu4pJLLuHiiy/m9ttvp6mpiWuuuYYf/OAHOZ0tX3zxRVauXMny5cu59NJLef/738+b3vQm3v72t3PjjTdy6aWXsmzZMq677jr6+/tpaWlh9erVXHjhheJsKZQNMW0IgiB4LFrrOFZue9AxZ0xb4AgRZfKPyCwF/vTTTw/7fevWrfT391NfX59edu655+YN67zrrrvyCgR33HFHOiw0k+985zujbLUgFEYECUEQhEwWrS2b4CAIZwIVNW0opTYopU4qpXZmLGtWSv1cKbXHfZ9WyTYKgiAIwmRkosbYSvtIbASuylr2d8AvtdaLgV+63wVBEARBGB0bmYAxtqKChNb6aaA7a/GfAt90P38TGDmYWhAEoQBa60o3YVIi121yM1FjrKp0R1FKLQB+orW+0P3eo7Vucj8r4JT3PWu7W4BbANra2t742GOPldyGgYEB6urqSt6+0kz29oOcQzUw2dsPuc+hrq6OtrY2GhsbcR4p1Y1lWZimWelmoLWmt7eXEydOpMNIPS6//PIXtdYrR9rH+eefr//1X/913Np4pnP55ZcfBDozFj2stX44c51Sx9jRUNXOllprrZTKKem4F+thgJUrV+q1a9eWfJwtW7Ywlu0rzWRvP8g5VAOTvf2Q+xySySRHjhzh6NGjlWnUKInFYoRCoUo3A4BQKMSKFSvw+/0lbV9bWzvp+1SV01mMQJePQmPsaKhGQeKEUmqW1rpdKTULOFnpBgmCMHnx+/0sXLiw0s0omi1btqRTWwvCOFD2MbbSzpa5+DFws/v5ZuBHFWyLIAiCIEwlyj7GVjr88z+A54HzlFJHlFJ/DXwBeJtSag9whftdEARBEIRRMFFjbEVNG1rrv8jz0x9PaEMEQRAEYYoxUWNsNZo2BEEQBEGYJIggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyYggIQiCIAhCyfgq3YAznr1bYNuDcOoATFsAl9wGi9ZWtk2CIAiCUCSikagke7fAprth4CTUtjrvm+52lguCIAjCJEAEiUqy7UHwhSFYB0o5776ws1wQBEEQJgFi2qgkpw44mohMArXOckEQhMlO1+uw8ery7GvdT8qzH6HsiEaikkxbAInI0GWJiLNcEARBECYBIkhUkktug9QgxAdAa+c9NegsFwRBmORE4yleONhd6WYI44yYNirJorVw1b1TImpj654ONjy7n0Pdg8xrDrN+9ULWLG4deUNBEKYsB9VsbvP9I9vXXVHppgjjiAgSlWbR2kkpOGSydU8Hn37iVUJ+g5ZaPx39cT79xKt86pqlIkwIE0t8AB5976QXzAVhMiGmDWHMbHh2PyG/QW3Qh1KK2qCPkN9gw7P7K9004Uxi7xboOyLh1IIwwYggIYyZQ92D1ATMIctqAiaHugcr1CLhjGTbg6AMCacWhAlGTBvCmJnXHKajP05t8HR3iiYs5jWHK9gq4Uwg0zfnkcFdWOe+begKEk5dUebrYzyY+gfY+KWx70zCP6sWESSEMbN+9UI+/cSrQIqagEk0YRFL2qxfvbDSTRs3cjmXChNLtm/OkcE2UqkUPYMJmsIBZyUJp64KXjjYzcr5zZVuhjBOiGlDGDNrFrfyqWuW0lofpCuSpLU+OKUdLb0BrKM/PsS5dCCeqnTTKs/eLY6z4wOrnPdx9E/I9s3ZXP9nKDTdp7olnFoQJhDRSAhlYc3i1ikrOGSTOYAB7nuKroFEZRtWabzaMb7wUGfHq+4dl8iJQ92DtNT60993ht7AIvMIDVYjZ0c6JGpDECYIESSEqcUEVFPNHsDAcS6Np+yyHmfSkVk7Bk6/b3twXAbzXL45EcI8PPfzXLJuVdmPJ1SYcqXaBvG3KDNi2hCmDhNUTXVec5howhqyLJqwCPrO8L/TqQOOc2Mm4+jsuH71QmJJm0g8hdbafafy/ioTaN4RhGrgDH/yFc/WPR2s37idK774FOs3bmfrno5KN0nIZoKqqeYawGJJm5a6QFmPM+mY4NoxuXxzZjWFKmtimyBhVhCqCREkiiCfc50IE1XGBM2I8zmX1gXPcEthBWrHrFncyoZ1q/jFRy9jw7pVlb8HEyTMCkI1cYY/+Yojn3Pdhmf3D5/9TICNXsjDtAXODNCzzcPoZ8RF3r9czqVbjo6+yVOKKVQ7pmROHXA0EZlILgthiiOCRBHkc64blrlxgr3WhSwuuc253uA8vBOR0c2I5f6NnSlQOwbGUISuHMKsIEwyxLRRBPmc64ZlbhS1ZmXxZsR1MyDS4byPRgiQ+1cVVNofaUymzAqYdwSh0lStRkIpdQDoBywgpbVeWam2FJ25UdSalWcsM2K5fxWnGirJjsqUmY2Yd8YPCdkcNRM1jlatIOFyuda6s9KN8JzrRlR1ilpzciP3ryRKNgPkIN8gfv/m18p2jJEo2pSZjyli3ik3LxzsHvJdUmZPGOM+jla7IFE1FJW5caw2+nGgnA/5KY97//rjSY5EDIxklDozSff5H2ZZpdtWpZRbg5BrEE9aNruPR1gys35CtBRShE4QRofSWle6DTlRSu0HTgEa+Det9cNZv98C3ALQ1tb2xscee6zkYw0MDFBXVzfyisUQH4DISbASYAagdsbQGe44kK/9A/EU7T0xlALDUNi2RmuY1RSqfJhcFmW9B2NgcKAHu/8kflKklJ8e1UiEmqKuWbWcQ6mU0v6DXVGSlo1hqPQy29b4TYP5LTWjbkOu/cWSFmgIZZSqz3eMctyDSv9vJkM/uvzyy18sRk1+7sK5+kuf+0TO32oCo7yWLeeMbv0zgMsvv/wgkKlteDhzrBxpHC0X1TWaDGWN1vqoUmoG8HOl1G6t9dPej+4FeRhg5cqVeu3atSUfaMuWLYxl+0qTr/3rN26noz84NIVwPEXrYJANVZZCuFrugXPNWkq6ZtVyDqVSSvuv+OJTtNT6Uer0wK+1piuS5BfvuWzUbcjUcHj+SLuP93P29Bqm1QZHPEa57kElNXmTvR9lcjQR5p59uQWA7Z+4YoJbMyXpHEGgKziOlouqFSS01kfd95NKqR8Aq4CyX4CpzJhtvWcgVX3NqjBHSbnNALn8kQwFdpbidLxNDWdSETph6jJR42hVChJKqVrA0Fr3u5/fDvxjhZs16RBb71CKmWVW7TWr0hwXRUc0jUChe+NpKcZ6DEE4k5jIcbRa80i0AVuVUr8DtgM/1VpvqnCbJh35akKciQ/gYnMDVO01q9IcF/nShY9mNj/SvSnHMYTqYfsnrhCzxsQwYeNoVWoktNb7gBWVbsdkp+iw1TOAYnMDVO01q+IcF9618a7Zhmf3D1k+EsXcGzE1TE7m62M8mPqHoQs3fqm0nUkeiVExkeNoVQoSQvmQB7DDaHwfqvKaVXGOi7GGgFa1X4ogCCMigsQZwpmeT6JqfR+KpQpzlHiMKRMkU+DejCNn+v9WmBxUq4/E5GHvFnj0vfDAKud975ZKt2gYUga9in0fimWsdUTGkUPdg9Rk5HiA0WkUJv29GSfkfytMFkQjMRaq1JM+m7HOGKcCY/F9qJpZYZWmXh6rRqFa/VIqcd+37ungYFeUK774FKciCRrCPmqDAeDM/N8KkwMRJMZCpic9nH7f9mBVPfBLsUFXzeBZRkrxfaiGIlLVTjlCQKvNL6US99075p+fZdNS6+dwd5RIPEXIb9IYdv6/Sctm275urvjiU5P2f5ldcyMXUodjciGmjbFw6oBjr86kSjzpMym6DLrLWFWqlS4DXU4ytTlKKWqDPkJ+Ix2ZIBQfnjmZ+kUl7rt3TMNQKKUI+x1zUXtvDIDewST7O6OYCjF1CFWFaCTGQhV70mcy2hnjWEwhU20GLxEFxTGSRmGy9YtK3PfsY85sDHKwK8pgwkJrzeFTzrHnTAunhZtqN3UcVLO5zTf6HEjb10meicmEaCTGwiW3OZ7z8QHQ2nmvEk/6TEab0GcsznNTbQY/Wm3OSEymWXk5mWz9otz3vZRjNtUEaGsIUhf00RVJYtuaBS1hmmoC6XVEqBWqAdFIjAXPk77K6h/kYjQ26LE4z03WGXw+n5BypYD2jjEes/LJ4M8yln4xYeeXUcvkvsBs7o1ezi7eMGFpub2+5lQb1UQTFn7T5Ms3LHP64sbtdPTHh2wjYbJCNSCCxFM3eYoAACAASURBVFipUk/6sTCWwXMy5gQYaYAvV0TBeETP5Gr73Y/vYHpdgEjCHteBN9cAD+S8VqX2iwkziWRFYLUkevhU4BEeNIP8LHL+hAhoXl/bu+M3dEWSw45ZTqFWEMqJCBLCMMYyeE7Gh91IA3y5IgrGQ1uT3faUrekcSNA3mGTp7IZxG3jzCTBaQ0tdYNigX0y/yCWYTFjoco4IrFrgrronueu2W8t3nBFYs7iV1NGanCXYqzVMthA5U2QXwQufHr6N52shdTqqDxEkhJyUOnhOxofdRJljyqmt8QbdZ/Z0UhMwmd0UpjHsp703hqkgaeuyOuRlD/LdkcSwAX5/VxSlNQ1hH68dHySWsvAbivt+tpsf/c1bCvaLfJqHgXhq2PUZF1NZFdcyyaTawmQFAUSQEMaB7CJO9/1sN/dvfo2BuFWVgkXRA3yGDb0Uf5hyltz2Bt3agEksaXOgM8qC6TXEkzZKKULmaT/qseYeyDXI7z7ez6LWoaHPqZSNrTUHu6IYSuE3FJaGV9v72bqno+AgmE/z0B2xiSas8TeVTXAE1mTwaxGEYpGoDaHsZOahMJVm9/EBdrX34zOoytj3olI0ezb0gZNDs5iOIiV6ucphZw66MxtDKAVaa471DGKaCsvWzGwMAuXJPZAz4sJncKQnNmQ9n8/AsjWGUphuLgQFBP1mOjojX9RKvkihoN+YmPTZExiBJamvhamGCBJTiGoJLcwceE70JfAZCp+hON4Xr8qwv6IG+EwbulLOuy/sLB/lsTasW8UvPnoZG9atKmkWmjnoNtUEmN9SQ8hvEE1YnNNaS0ttAL9p5M09MNrrn2uQn90UIp60hgzwjSEfGkeo0YBla2wNZzWFONQ9WHAAzRduuWRmfVmErxGZwFomky0UVhBGQkwbU4RqSviT6XPg2clRinjSBqozHHRE23MV2dCzTTFNNY7g0FofZMO6VUPU5uXIPZDL9BPwmSydVU9LXTCtnr/7qiXcv/k1Xu+IkLI0Qb9BfdDk6KlBLA13PPYy9SGTlrrhtSMKmX2K8QvwzvmS8ACPbNxemqlggiKwJmuItCDkQzQSU4RqmuVkzi5DPhNbg207AwtUXzhoUZqcaQscm3kmeWzo460ZGskUk6n1uOTsZgK+odqE0V7/fMf7kwtnDVv3zrefx6yGEOfMqKWtPsDJ/gQJSzOvOcxAPMWJvjg90UR6fW8AHYvZJ1PT4TNV1ZsKKpHsaiqw/RNXSMRGlSIaiSnCeM5yRusYljm7bGsIcKDLacPchmDVlYjO1uTs74xwy7depDHs5/xZ9afP9ZLbHJ8IcDQRiUhOG/pEaIaKjozZu4X7El9i4NTrHFUz2Gj9CU+lLsQ0FO9cNlwIGM3xVi1o5vGXjuY8T2/dbfu68fsM5k5zIkr85iDRhMUfTgzQEPYzqzGEz1BcGdoFj36VNacOsGbaAvjT22DRqqLbN9mq207GEOmqYOPVlW5Bbtb9pNItqDgiSEwRxisRVCkDY/bAs2RmHSsSL/OO/h8yzzhJsHURLcaHgbVjals52PDsfpKWRUd/nGjCImXbmAoGEyrrXNcWlcV0oga1EdX9rnNoiy9MrL6V+p5u7mIj2reO1+tW8vhLR7lwTmPRbco+3vqN2/Oep+f7ccUXn6Kl1o9Sit7BJImU4zOhgETSYl9HhCvDu7it5lEYqHdMR52vw3dvhPA0mHFBUZExk81UMBlDpAWhECJITBHWr17I3Y/vYH9XlFTKxuczaAz5uPuqJWPab6kD45CBZ+8W2PRtqA1DYB4kepzZ/Tg5s3kUo0nZ1d5PTzSBoRSWbaM1WEAknhp+rkXY0KtmUMtwDu071Yf216H1IO+z/psP9C7DNBX3b35tyPUYiKdYv3F7UYNbMeeZKdy298bwmwpDGaRsjQ0ETMX7+G9qa+od59XoKRhoPx014UXGjNBPvOMkLZtYvcXLh3vwG4qzs8JTqwnJByFMJcRHYgqhNSjtTPmU1mjtLB+LzX4sBbzSlCniYTQUG2KXSDnCg2koNGAYCq1Bo4Dc51roeo7F/l1W34qMEvfxpI0GTqX8zNYn8JkK27L5/bG+9DG27umgvSdWdEhiMeeZ6VsRS1honNt/zoxaLprbxNLZDcywjqfbSf9RUAaYAbDiRfeT9asX0jWQYH9nFK2dh1rCcjJ8FnsNqyXiSRAmI6KRmCJseHY/LXUB5rXUpJdF4inu+9luogm7ZJv9SCaTovwnxjHiId/xi9WkBH0GkbgTqqiUQrvSl6GGn6t3vHymHjht/+6PDdITTTKYtIvyScjcr8+A7QdO8cyeTpbOqueuK5eMfvaakWAp6Dfoj6WoJcZR1YYCJ2mVT6Wvx4Zn9/PmGorWPBVj589U4e/tiGAqmNNck44giSYseoKzmZ+IOEJDKgaGH7QFvpCzkyL6yZrFrcxoCNIXTzmb+M20/0UxJqVqingSCiC+CFWLCBJThHyq5leO9rGotbZkm32hAaPoB/A4ZQ0sdPxiTQxLZtWzvzPCqWiSpK1JWRq/qagJmDkdQzc8u59VegfvGfgxM6x2TpqzeDzwLjY8G+YvFziD2nveMIevPPk6lq0J+Q2aawMj+iR4gk/K1uzrjDo5GGzNzmP93P34Du59z/LRDWoZzqGzGoIko30EVZJv6T/B0hpba86aFk5fj0Pdg6ypUyNeL49i7fyeCt+7V15+C68fGZfeBq983lnZF4JkzFFbNMxxlhXZTwbiFhfMqiccSLFkZj3g5LMoRnM22Zw1z1RWffYXRa8r0R0TS1GmDaWUoZS6WCn1TqXUHymlZox3w6Yi46k+zadqBsZkmigUlld0yOk4ZQ0sdPxiTQzrVy/EZziRBRfPbWR+Sw0+0yAc8OUMQWw58Ty3Rh+m0TpFr2qi0TrFrdGHaTnxfNrH4CtPvo7h2ujPn9VAW0NoxFDcQ92DJC2bPxzvJ5GysezTSZ2O9sT44KMvja6/ZCRYarJ7iQency83s9Veht80mN9SQ8Bnpq/HvOYwtq1HvF6ZjCa5Vr5+tOyt7z6dCMpf65g26mdBqGlU/WQsJqWymO8E4QymoEZCKbUIuBu4AtgDdAAh4FylVBT4N+CbWmt7vBtaacaaG3+81af5NAfnttWNWKtgpHPL5xhWtGOhN6iNoU5FLgod/55rlhYVYpc9s144vZZ/+tML896Tm/gpgwRIGs71i6kwlqV5r/UEL/csoqM/iK01WDpd/6Ix7B+x3kVd0GRXez+WHn5MheMIOer+kuEcGt/TwcEnXmWx38h5PdavXsiul04SiY9fSGJeB8NMJ9YS65l4/d+29RCNRzHtH6+IJ0E4UxjJtPEZ4F+BD2jPeOziaiVuBN4HfHN8mlcdlEMIKKQ+9X4fSyhYPlUzUHBAHcnmX6hdE1XsKh+Fjj+aELvReNCf4+9kTzyMYWtMw6lrkdQh2qzjKIVbh8IkadnYtmbPiQEMpUhahf1UtGtuyIVyLQ6eVqMcVVnrgiY1AYN7nng1fW1mNYVoHQyOqh+WKmDn3a7E7JLe+e3d8Ru6IslRtUXyOkwORlWOfOOXCv8u/hZlpaAgobX+iwK/nQRGuFtTg3LYUPPNnne195c8kGeTb0AsNKDmOzfPSTNl23RHEhzujrJtXze3/9E53Lr2HCD3A7hrIIFpqPTM+yNnH2PZK593vO8zi12VIfRzpAGg1BC7QoNjbds5LPId5UjUIJ60CfoNzqqx+H1vG4broTmzMci+jghJyzFPmMoREBKWzc5jfdg2w8IvT/YnII8goTXUBIwxq9uz/RWy+9wdF8CGdSMngvKuz672fnoHk7Q1BJlRHyxawB4v7dyaxa2kjtbwi/dcNurtJK+DIJTOSKaNa7MWaaATeFlr3T9uraoyypEbIN/sOZGySfqchEixlEXIZ9JU4+P+za8RiVtledgWGlBznVsiZbHnZCQ94/YbioDfJJmy+cqTr6edBrMfwLUBA6Ucu77X5shT/x/9jT7qa11HS8/hctuDYxYkxmMAGHGQu+Q26jfdzfnT/BCodzNcxnmm5XqmuT4GTTUB/EaUlO0EkWrAZ0BKQyxhURP0YWWEX65Z3EoiZWMaBj4TBpNDLYU+QzGvpbZkdXu2YNQdSeQUHrsGEiNuXxc0OdkXp6UuwGAihW1rjvfGSVk2/TGLwaTFHY+9zJdvuGjIfcjcx6lIgoawj9rg8Job5Ri8S9GSSF4HQSidkUwb1+RY1gwsV0r9tdb6yXFoU9WRmfDmeG88XYhqNAlv8s2etdac6ItjKIXfcFTgJ/riHOuJcd7M+nH3JM8WcHqiCQ50DTqJmWwnF0XS1hiWjd9UJCw9pA2ZD+D1G7dja0haNq8dHySWsmg12jnQN41lDRkHLWOxq3IPALk0NAPxGHc89jLTagPMa67hI8s+zrLD3yFy4nVeT07n2/wZe+ou5Cr7VNrHIKUhYBosbK2lvSdGfyyZFipyhV96YaiGUoT8Rjr3A8CiGbX4DFWSuj2XYLT7eD+LsvpuTcAknhru6pS9/e/b+0mmbBrCPmIpt0+kbI72xAj7TfymGubPkb2Pw91RIvEUIb9JY9ifPn45nBsH4im+LKGcVcNBNZvbfP848Qc+OsLvI0SASNTH6CgYtaG1/qscrz/FyW38+QlpYRWQmfAmYdklJbzJ57Xu5C5wEiIppZzESBpStp4QT/LsgkxH3bLTtUEznUDI1s4sOZqw8BkqbxsOdQ+SSFkc7IqStGz8huIwM9CJCD2DGbPdMoR+lhsvouaZPZ0c7o6mC0v1DiZp74kxEE+lB6aPvjCNh+Z8jrfF7+Om6Ed5YuBc9p4cQGuNoaArkqQu6GNWU4jGsJ+ZjUFs7SYMwyuvrZntltcGJwx1VlMIv89AoWis8dPWEKClNkDKpuTy2TkjW3wGB7ui7D7ez+8O97L7eD8n++MEfcMfB9nbW5bjG3K8N54uyJZyz83ru+GAOSRKxduHI2AOkLRsEimbQ93R9HHK5dzYNZAoLpJIEISyUVJmS631QcA/4opTBC/hjd9noLWT8Obs1lqaawOjekDlCpfzHt6Z4X4AftOYkAqBnoBjKHjlaB8DcUdYmFbjR+EIER6WhsGkRV3QzLmvec1hjvXEMFyBSCnFI/od1BhJuk91lzX0s5xkZsGsCZjEkjYHuxxhor03BkDYbw4ZmL76q9fpiiSwNfgN5VQ4da/VLz56GV++4SJ8hkEknqIx7HcqnypnsM0VfpkZhrr8rAbmTgtjKoO5Y7zfuUIbG8N+BpM2sYSFaUAkluRAZ5RowhoWlpy9fdBvgNbEUpYrIDn5LjyTlq1hVmNoiNDrCZj7OiL0x5LOtQIicYueaCJvIbdSwqXjKVtCOQVhgilJkFBKnQfEy9yWqsZLeLNibiNLZtbTGPaX5QGVORNNWRq/z2BWU4jzZ9UXLBVdbjoHEmlnwcGkxYm+BCrHelpD32Ay5z7Wr15ILOWYazyhaKu9jM/ZN3MgVsfRY4foUk3jXmMjm5EGpMxZ9+ymcFpLdLw3xmDCQinHgdKjJmAyELcwDTVEkwSw56RTajxbQNOuqWN2U4jzZtbhN41hjqGZGitDMczfpJTS2LnyK/TEUoR8ipDfJJ60sDSYBli2zbOvd3HLt17koS2vp7c/0Rdjd3s/Lx/uIWXZJFxtU2PYT1tDEKVw+47GNGB/Z4RXj/VRGzDS+3DyZHjOp6fbsr8zOlTbsncLPPpeIl98A77HbmBW169Hdf5BX3ECuKTEFoTyMZKz5ROAzlrcDMwCbhqvRlUj4xVr7vlOzJ0WHuI7cefbzwPGHhZaDPdvfo3OgQQ+w7HPx1LOYJGNaShMNMf7csuQaxa3csHsBl7viJCynEEFDc/Zy3jJv4K5DTXEBmw+ZS9lTdnPIjfFRAhkOpw2hv0smF7DsZ5BIgmLhpCf+pCZTusMzn13xk3P4yE/0YTNotZaagImJ/vjnOiLE0/poSXKXXL5m9QGfY55xRVqcjkyFiKXb040niLsN4mlLDTKFSKcQT7gM4Y41a5a0MwzezoxlcJnKlKWc87T6wJ0RZKc3VrHDW+axyPPH6QrksA0hte6WL96Ib/a7QzUXhpyQ4HfdASwdKSIW7EUX5hD8Vqa6eHWwYf5pv9WdobeQCEfIc/BclXIYm9HJB1JkiuUs5pTYm/d08HBrmjefCOTjfn62OjCNieIivhtTGFGcra8P+u7BrqAPVrr3C7eU5TxijUfKfJgIh4ifzgxgKmcm5u09BDR0VDOLM9vOrPLlJ0tVw7lzrefx6efeJWUbXOoK4qlnX201gdyOox6A8Al4QEe2bh9yLkX8r4v1jO/UHhrZhRByrKY2egIhY1hPz5D0VofTN/3zERN50df4u9rfkxrqp0jegbfVu/keXsZAOe21eU9dltDiLqgkzFzpDBLT7jpHXTMDt7AO9rEVLkia/ym4UTjmCrt1KkAhULBEKdagLOmhTkVTRJP2oQCJtNq/CycXjvkHDb9/jh98RSWpQlm1brYsG6VI6BYtitEKAI5/DEyi7vFUz34zRpMW/GOyA/ZGXpDXg1gpmAQqDOYUR9wBTabJTOHC2zVmhJ7654OPva9Hdw0P8WRU1FO9A6yu72ff75ulOnRBWGCGUmQ+ITW+u0T0pIKkq98cuZgdWVoF1/3PYG/7xCH7Bk803I9l171nrIk7KmG0DNbO2Gf4KipbXeGahoKw51F2m4kx5KZdXn3k1lrwtaOGttnKDoHktSFkjSEfBzqHmTrng7u3/wavz/WR8hncOkFDMuhUSi/RrEzynzhrfs6oyyZCS21fizb5ojrZNrWEBoiJGYPxFeGdnFb4BHscIg9p5qYrnu5W2/kC8Y6fMaStCYp37GLNYd5GrD23hiG61th2Zqw/7QjY74+k6vPeYP++o3bmd2U4nhvHFs799rTRniJr2wNYb+RbueM+iBtDaH0/nPVsPBMf72DSY73xtnfGSHkM+h0Q0qXzKxj9/EBfIbCcB14U9l9KaO4W9DvaEZiKuRUCCW/BjBbMJjZGKY+5M8rsGUKae29MeJJm4BP0RWp7Nzovp/tpiuSQHPa76YrkuC+n+2u+PPhTCNXXQ+J5MjPSILE9AlpRQU5XT45OGRQes8b5vD4S0cJ+Q0uM3fy3q6HiOkAjdNncomZ5JLUv4OxBCeAJf++q02FmmuQWTyjlh1H+0A7g0lmEtOkpbFtR5Uf8pu01Aa468olBY+x/UA3i1prOezWj/AGwfbeGD4jTF3Q5NNPvEp7Xyz9wEyk7HT2R28mXCgTaLEzylwmqWM9MYJ+c4imAKBvMIXPHJ4VcYig9+hXYaAegnWc7U/Q3uvDTkS4PfhzDk+7eMTMnyf6YvTHrBFV154mZDBh4TdVOtJjZmOwoDCydU8Hdz++g95YilTK5nhfjNeO96eLfh3qHmRGfZCQ36S9N+bU9XC3zYwoaaoJpAftYkx685rD7OsYGBLKHEvaJKwkW/d0cNeVS/jY93bQH3OKo/kNNbwvZRR3m9UY4kBnlJAe5IRvZkEfoZEEtuw+XxswONkf53hvHEOBz9XMJN225st/Md6mBi93i1KOCcjTEu4+PpBzoiMI1cJIgkRTjqRUabTW3y9zeyacfOWTv/bMfmY3hagN+nhn1w9JqSBxFaK9L07TTDcpwghJlapNhZpPsHnPG+bwytG+IeZ+zynO87C3bZheF+Cf3u2o8L0H25WhXaz3baIlcSyd/vpQt6Kl1gl7PNgVBdsRUAbdmX5NwCDkN7Asjc800oc93hvnvJl16QGg0OBQ7Iwyp0kqZQ/LozCjPohpGPzioyNkRcyYNTeFAzSFA6DrIdLBqeDQv1P2sU/0xTjaE+OsaeERBUtPE3LHYy8z4Po0zGwM0lQTIBJP5fXNuX/za5zoi6cdXpOWE53hZdH0hJvGsD+dw2FfRz+dA0lnJmwqJ6GWaRaVYj3zXG/51otoDYap3EgORVtDMG3e+OfrlhcelDMqljaFalnUqOnrT/I142pMQw1L6e1tW8h/KbPPm0rzm/3dDCadomg+wxGOvaiTGfWBYWa38ZwIZAsplq2HOKKC4wCbSGk6+uMjtmEihR5ByGSkqI1G4GqcxFTZr6vHt2kTw6HuwXS0gkdNwKQvlkyHkc2w2ompEKbhzFyAopIq/fZQD7va+/n1vm5eOHCKI93Rioai5auWuf1AN8vmNFAbMAn4DAyl8LlChKGgLmAS9Bmc6E+w82hvOlTS0dR8lc7jh+kxGtPpr68M7SKasGiqCTC/pQa/aZC0NHVBH5+6ZimRhBOiF/Qb6YqTCoilrPQAUKia47zmMCf74xzojJJM2ekZZU80Ocz7Plf+jgtmN6R9PrL3XYitezr4XaSJ1w4fZ9fxvtO5MfLkxcg+dn/M4qxpYdoaQkOu//2bX8sZQbBmcStfvuEi5jXXMLc5TGPYP2L0zq72flKeqQJHIEzZml3tTiLa7LwhTnhqkI9deR51QR/T60Oc3VqXHqi8czANxStH+9jbEaHGjcbIjHzY8Ox+Qj6DoP909NGC6TXMqA+m+3uu8OchZFQsJdJBfcsc5tzwFf702huJxC1sTc4IjsxzAoZco8wcFoe6B7E1BEzlRBVpiCWtdDhuW0NoyH+z6Oq2JZAZcuydEzhOqtp1U7JsTSKli2pDrv2VEuUjCKUwkkbioNZ6/YS0pEI45ZOHZvuOut76XtXMk+YsGq1TRHTIiaOHEZMqPbTldXqiTpikpzI+2hMjYVlcOKdpnM7GIXNm4qStVgzELY71DDJ3WmhIhk7Pjn3fdcvTs689JwdIpJwBPujmT/D7nAyGxWhq1qtNbI6dDzg5FLxQR29w8maQnvoad+Dz1OHFzISd2a9O+3PkmlF6ZPugeA/d7H2vWtCcV4XsbbPKdw23Jh4mEte8djxBvUrQ6E/Rff6HHdVNFpnHvuKLTw3TsiQtm2kntnFr+OfMto9zbHAm3/v+NXDtjTnTkI8000xadjpzJrhOlFqTdKNwCu1vy5YjeetUnOyLYyony+m+jgi3/8dvCQdMmmsD6YErlrKZUR9IO60CBbUnOclRtGvDxu0jOszWBU201qQsnXaSXbO4lXueeJWWWj+vHXeytcYtO10czWcoagI+lsyqz9nWcqTGz0cubeWsxiDHe+MohSMg+wwMQ6Xb5GngYgknMiXTDFNt2k/hzGIkQaJwbNsUIF/55P/1loU8/tJRIMVPa97NX/Y9RFBr2hqa8ydVyqhyeUFnLW/1X8UzqQsBJ/WxbWs6B5KsX70wpxoSnAfC7vZ+4imbgM/IGSZYiGxV7u7jAwAsnF6DYSj2dkQcG7ZpDLFjw+niXns7ImgcPwSfq62xbWdm1BdLck7AMQvMsNrpVU2YaqimpiVyrODg56n8Q36D+S1hjvTE0MDZrbXcdeWS9HqF9tEY9jOYSBFL2YR8jtq/Mewv6iGfazBdtaA57ROTS4XsPaj3BlfyVdvmqv4fcJY6yTHaeDR0LdtfmMYdF+TOr+GRrYLvHUzSevJ5/o/vEZLJIF1mIy26hw8lvs5//jzImsW3pttb7P33GcrJ16BPz2wB0KQHnnz7y+d07DkB+gyV9mk5NZgkmrSY21wDOANXW0OQE31x6kP+skY2FeMw6x1rdlOIDX9+2sHSu+bRRIqkpdMOpYZyZ/+JVN6y46MN+R6NaSHXObU1hIinNLUBzVnNNcxrDtM14DjFZkbvGIbjP5HZP8dT6BGEkRhJkJjyuSLWLG6lZ1/u8skXzmlkw7P7ear7QkItH2K9bxNNiWPQuCBdCtt7eLSceJ4Pp75BQ3099fWtNJ48yieNR/ic/2aeTl2IrZ2HmOE+yX78/e9wa+qJ9Cz02//5Dl4wVhD0G3S7tv5oAvZ1DKT9GLYf6B5VuOPh7sG0IHC8L87caWF2H+/HtjVB/2k7dkPIl1FLIsztf3SOE3XhagpsN2Nhc20An5EqSlNTaPDLHshXLZjGgpY+fnTjW4DhD+R7ctiDz59VP+whX+zsN2dUwwgzuswH9abo+TzBeRjKyauwor6RUDx/0SuPTJ+JpGWzvzPKneYm4gQY1CF0ygZ/iDoFb+n6L+DWUZ/H0tkN7Dza66Tkzlg35Df42Pd2MKMhyEDcyqlxyeV0/KlrlqadAL2kW6ZrM0kLjy4z6oPEUzat9aMrRT7SuZ2KJLBse0jkyLGeGKahONw9OKTYXfY98K65lzEWHJOdE+7q9O18ZccLhXxnX/uRBNFs8gkp58+qZ36LmdYMeROD9r4YyjVYaa2Z0+yYDL3+OV55bqYqpeS2eOHTubcZa06KqRANMpIg8ROlVObzyDO7Amit9aLxadbEUhf05QwTGzoYXkb2gz1z9v8h+ydEbD8dvYpWe5AoYbQNN6n/ZptvOT7DMQ3UBn08//PH+VDi66RUkF6jiRbdw+2pb/AFfTMvJC9KP7QtW9MTTdFUA1958nUWtdaOKtzRKy6GqzFoDPvdwmCOCjjoN2gI+TjZF0cD58yopaM/zuMvHeWa5bN4Ykc7iZQTSeEIEUZpmpocZAsaW7ZsGXZNC51rMSXMVy1oHiZ8Qe7Q0Ug8NSwddeaMzotK6Imm6B1MunkdDEIBk97BJMd6BulvcWb0ucKHveN7AtS2fd0ETMUCTtJFAyiF0ppEyiZiBplrnCx4/bycA14UhJdz4C8vnU9Hf5zjbmpvT6UYTzoRHN3RBCvOasypccnldJy2xWtNynaia2zXkTObaMJiycz6okqRj3RumfcoZVnp8FwvyVTErfvi1XTxit0NJof61XhC67p/3+5oaLIariGnoJq5bS7NYXYf+sqTrzOjPkBLXXEVTQsJKamjvx/Whlu+9SI2EDKNtNNtZhjueOW5EYRiGEmQWJn13QDeC9wJ/HZcWjSJ2PDsflK2zeFTcRqto5xSjYCd/nNHCXEWJxl0MyFaGuKpBG9MPEbU5ydhhkgkbQa0np9nqQAAIABJREFUn5Cd4kb13zybXI7Pdd02lCMM9EQ1Ccvm8KlB4kmboN9gWo1/xHDHkM90bONapzUGQZ9BwK+4cLbjz7D7uOMfkllLAlJ0DMR5+H1vzKmqzdbUvDf1BJFTh9htz+CZlr/iUvuCkjNXFmvrzZVoKTOl9P7OCFte6yDoM9CQHmhnNAQJ+Q1Stua1EwPEkzam6SRi8jQtHpkzuswMj14ehHjKpiHs50BnNJ2tMVf4cLZAtGHdqrS/RGfHLMKJLqI67AzOWlNLjFBbYRk9l7mhK5Lgf3a2c+97lnPLt14kZdmk3FDLlKtViidt+mIpN2JjqMZlTd1QS+YqewdvO/x9Pu0/wZ7kdL6euorn3MRbHif6YnkzSJZKrrwQ4ITnmobhhHAGfSRT9hAtiZXSwwQFj4DPJJXhvOv45DhRG4X8CHJp1tbn8NlwhP7kEP+QQqaFgr4qR4eve8nZzQU1DqP1pRGEclJQkNBadwEopQzgfcBdwMvAO7XWr45/86qb3e39dEecWfBRo41mfYoB2/ljmwaEiHFYz0h7iJvKqYw4V5+gM9WIsiy3poIiSoi5nMQ0HHWr6Q4OIZ9JJOFkDPQiFJIpmyPdUY71xLjii0/xvvnRtP07c2bS1hBgb0cES4Pfsvn90V78pkE4YKZ9QjwhJ7OWRNKy2bavO69pIfPhunXPUt7/xPmEGoz0TGjzCCFy+fxDYHQObpntyC5h3uPWA4klbeqCZnqg7RyIc3ZrLQe7BtM5BCzLJpa02XNiIO0b4mlgvLZtP9CdzvBoxTQajc9UdA3E8ZuOEOM3jbTgk+mUCsMFIk/g+0HwXfx14mEAIjpErYoRUimOLVlHS4G+l21usG0nD8eOI31seHY/i2fUsq8jgt+typl0IxoMQ9HeG6Mx7E/f5yu++JSb3fO0qeLC2Eu8r+8hLDNIfdMsph/v4B7fI9yT+su0MGEo6OyPpwf3cg1c+fwHfGYyHZ775s//ku5UAss+7XALp5NqeWzd08Edj72cdjb12q2185/MrMA6lvaF/AaDWaaekUwLo/F9KUbjUA2J7cYTSWtdvRQM/1RK+ZVSHwBeBd4CvFtrfdOZJkTkK/ATTzkPDtNQfJt3ENRJahgENDUqRo2R5FH1jrR6uTbow1CKo7RRQ+z07ElralWMw8wgZWs37Mt2EwP50umMTUO5FTk1Sds5/pFTUSLxFB/73o60MOGFHPbFLEzDIOSGdGqlCAdM3nfJ/HRIYp3rJOfVkugdTLK/M4qpcofaZTPaELl8YWoD7kCXK+zzRF+MU5FEwQJL2SXMPTSOU1085ZSuTliaA13RdLZIr8Kpdo3mYb8TYXKiL8573jAn/WD2EjktmVnPGxdM49y2Omr8JpbGdRqtSQ/q2eHDHpkCkRey+NOB8/g8N9Otmmg1+hgMtPCNug/wL/tm57x+Q3A7UNKyiafsdH/q6I/TOZAgkrDS+SS8Phj0GcST9rD7XB8ySViaE30xtNa8vf8HxHSA5mnNNNUEGSRMjAB/bW5yox1MQu755w3nLJFCob8e+Yrdhf2nr7nX1wbiKYK+0/lKvIyeplJDKrCOpX3NtQFMQ41bkb1cYczVUBtEEGDkPBL7gY8DDwH/DSxXSl3rvca9dVVAofjsgO+0On2bXsanU++jkyZaVB9dNHEv6/iNWj6s4uGjxjsJqwQ1DKJxhIgGX4qf1b0bQyma65y6FE01Ac5uraMx7E/7TGitiWXMfPyG44LlpdKF0/H658+q59y2OhZMr8U0FdF4imM9Mb66ZS/rVy9Ml7v2m2b6AXjYtUXPmRYuSjDIVaa6kEo3n+DhOcll5zk43jvI0Z4YDWFfQcEmu4R5JvHU6ZA/haOlSNlO3QfL1ulqlgrFklkNXDyviUWttWw/0D1k/5mDR1NNgLnNNbTUOu/ZRb288OFMcqmiLbeo2YfNv2d97QN8wL6bx0+dw7Z93QVzAJzbVoflpiz3cg+goDboZOxsrnX6kGE6A23I79TYsG1NwKeG3eeZjWECpqJvMEVXJMlZnKBterOTcMu9cIMqxALzJDUB03HizWdHGCO5cl1kD8q5yq77DCPtowCn+1o4YKK1ow1UOP/FoKkIuiXjRzvY52qfzzC4/Y/OGdeBfsQ8HIJQIUbykfgFzqRuhfvKRAOTPrNlPjz1+7Z93ZjKe+D6hqioZ9QH6Ikm0g5ez+tlbGOZ89DymxiuExgwZHDbal1IxPpL/trcxALVQadvJj9ouJZX1XIumTG8PsD6jdvTjn5OxUYHn1vCWrmza6+Etdf+bfu6SabsdKEtT+07EEtx9+M70mmTM22rtq1Z0BIeMjDmEgy863OsZ5ATvYPMmXZ6m0Iq3XymC0+7k92ezCROkN9nYv3qhTyzp9MVrE77MWRTGzRJ2Y6ZSClNyGeSSDmOewH/abk6+5zzqZYznU/hdDKkzOWFVNGe7Ttl64Lhfdnc+fbz0qmwvTwaPtNIh2PWBEzqQz5qA46g5mXWPNmfoDbooyeaHHaffabBtNqAYz549HwnwRjB9P6ID3CYGWjlmN8sDecXqLtSKsXY+/Otk+mo6PU1L1+Jl/rd0jCYtFnYGCppsC/UvsJxNsKZxFSIxiiWkXwk1k1QO6qKzHoF0YSFqWDPiQFXlasJ+QyOnHJm4rZ20gonLe3kI7KhKWyicXI0mIZi2ex6dh7rJ2Gl0mEvz7GMX+tl+LWBsqAtHsRv5p4dpUuNNzvx+b85cMrJ0JdZQVHrtKTgaVFMBfEMD/vMCeTJvtiQkM9VC5qBbo71DHKsJ4ZSKj3IZNeH8ELdUraNQtMft/nDiQFmNwaZVhssOMvLF6YWzDiXzCQ7B7siWLZN0Gek25NLsFmzeGgJ87DfIJ7Sp6uVujP2eNLG73MEsMUz6qgJmLx6rI+EpfmT8G6u73qCGVY7x9RMnpp2HU60TuHBw3M+zU6G5C0v5Pzm3duRwvuyWbO4lXvfszwt7BqGYu60cDrttRdBsX71Qu7f/JqTAh1YPMPJ1bHh2f3pbIoetq1PC4AZ6aoJ1LKgXtORSvEl/U5iCcsNZ3baml2fohwUY+/PtU6mo2JmOvDW+gBHTg2icQTwuc1hTGMkhWzhYwPp++tp7ERLMH6Usxy5+FuUl4KChFLqJuA7WuscOftAKbUImKW13joejasU929+jc6BRHoGb7ljUSRhUR80iSYtEilNfyyFz1DE3RVMVzOQsKAx7GNBS4CBuMW0k8/zjcD/MJcTHNJtfMO6ihfUcmY2huiLpRhMWPT//+y9e5wcV3Xv+91V/Zye92hmNJIlS7IEsvyA2EYxsTiIhIcDGAg2hBMC+IqD42tyQy6EOFwnwYaTkw/PEC4QYyeKcULiS3B4OCQ2NkSOrYsRtgHjh4wkj6zXSJr3o2f6VbXPH1XV093TPV3d0z3dM1rfz2c+M13TXbVr7+raq9Ze67cSFn/9rksWKDAWKveNxtPEQiZzGTtrlHiBY97ToefSXd8VzQpSFZK2YTKRZmtfjMGROI8cGmF9Z4SN3VEGR2YZHJllU48TW1BYH+KLPzxMeyTA5FwGQ6ls0OaJiSRnp1Nc6CoFFqPUk32uSzo3/a/FdT+/ODoLwC7jaV4//S3O44zz1OzqecB8CfPcJ/BjY3NuITIIGYpQ0MxG+5uGYjSeZktvjPMnf8KNib8no8KM6Q467HFuSt4JR7Zn919qcvO279u3jxt271ywfTF2bXOqpX76gefRbmDk2vb59L6Dp6dLqm16+/f6K2CoouJK8aTFBb2xbH/nZpXkjoPWzBuAnly1K7DW1rOJoy//KKO/WAOnpmgJmqzrjGDrxT0njST3WpucSxNyg2LP72nJ1iwpNNT8iko1Y0E+QWgU5ZY2eoCfKqWeAJ4AhoEIsBXnUW0E+JO6trAB/PLMDODo3Be6yBMZm4xrOFj2/BOv9z7b0oSCyr0522ya/gl/Yt5NQgcZ0R2sYYJbA3fzSet9PD79MjataaE9EmA0ns4TB/rMAwd5dmiacNDkvM4Ilu3ERlx32Xr+4+khnj41TSJtYbjVAte0hvij1780u6Rha8dtnyv8sQDtZIyMz6YxlWJ4KkkwYLqGiWZwZJa2SHDB0oJlO0WEIkET000tBCf+wPPSlCtGlWsgtYQMTk0keOuXHkEpxS/PzGDbNqbh1OjI2Damgo0TB3iPeTcJHaJlzdpsbQ+u/hRcsHvBvrf0tvKuV2zkiz88nE2FTCUybn8F6Y6F+PYHnYl/9I7PMTkSZtpyxLX6O3qIGamyhdmWyqOHhrn3yZO0hAPYlo1STvGx1kiAZMapH1KuYNNi3pJiqYqQ4cDRsQWfGeiM5I9XgVz1JUD3CwfYvrYtz6PUrFLMuf1y8PQ0sZDJ2o5ISc9WJcZBIySpSxk5UqxLaDTlljb+Win1JeDXgauAS4E54DngPVrrY/Vv4vLy6KFhEmmr6Po6OGW1DXd2zn2L935DQSKV4ciws2b+J8HvMaeCzOK4jGeJ0sosnze/xJRq4+R4Pw+0vZ1Yz69mj3/bfc9yenIOUynmUhbPn56hJWzSFg5kham29rZwaiJBIuO4/T917aWAM4EbrmhF2rJLGxHMq2w6CoWa2bSmRSnCAYWlnfiOUMCgry2c97lo0GAiY2eLnaXc+AZH98IR3ZpOzOUtnSz2JB0JOk+KnvcknfHabREJGhjKIGXZ/Lb1PVKBEHNEeP7MDGiIqSST//gJ/u78luwxCm+iX/2vF0iknSduQzmu7emExU+PTWSf9u+eO0J311q2tOScqw6WLcy2VLwJaUNXlKMjs9k6GSfH57C0Uz/Ez2RVyvuxWDptKVGwxSi1v+eGSntOakUl3oJi6cWF8uTHx52YIE9ErBLjYLklqRer3FuJoqYg1INyHgm01hbwoPuzqvG+rKGAkZcZUUgpI8P7X+7/N6ozjOiO7Ot2ZhhQ4yhsBllPlz3OB+JfZfoVG4D5iSWZcQwB5QhTkkhZzCYtAqaT6RALB+iKhd2I8em8p8/cSalU0CGAJ1oaDhpMzVnZlEhwCj2FgyapjJ0n1HRx4kn+wLiX3tAQJ+x+vq7eyA/si5xgP0MRCZhMzKY4M+XUCPDUMovd3HJv3GnLJmA4x0hl2+cYbl5WyPnGWUZT7dg5K23TOkKfPs3gSLzkDdRQipBp5MWUzKUyTGXs7NP+ibl+OkbGoLdnPlMhpzBbvZ76vAlJKcWmNS3ZokwYio5oME8WGiqfrCqRTi5VayO3hszn0p18Y+YajrTNa9WdmUowObfQc+JX1t0Pfr0FM8kMf73IhJsrTw6wqSfqW9202n6tBaWMnHJ6JUJxahlvUZK7vlD5Z67/t9q3Yxkoa0icCwzPJLn8kw8yFk9hGIrulsCihkQlHNP9rGEi65EYMJyUwgQRtFYkjRY2dSo2Hf8n4G3ZiSWbrugu8Gvm4yFyyc14KDYppSwb2ypuSaQymvF4kq6WIBOzacJueWWvtsb5nU4Mh9MXGXbaT/GeqdtJ6BBGax9r4hPczNdImu/lMX0xhqFY61YwzKbb5ahlFt7ccp/qPG8BSmV1D7SGjNZMJzNoDS+qPqcvVTTrDmpxRb/GZ9Ns6IoWvYGGAwbxJHniRZarJeDdgL/f9lu8Z/J2xsbH6Iz0O0aEK/ddSo7609dduuSbde6E1BENZkuF97peoOHpZF611qCh2NIb873/nZu6+eIPD2PZTgBqZ0uQoGkuCIYtVWvj81eMs+WJT3JmTjGVCRMzRnl/4qv8HXC49XJmUxZnp1P0t4fzJrPpxJxvWXc/+PUWjM6kiATDiy7lePLkuZlGkGEsbi+qbprLcktSl/KA5BbRy90uxboaz+MvjpV/UwE3/cVDJf/XzFkg1Yct1xml1NVKqeeVUoeVUnWLw7h932HOTCWJu4JItq0Znlm8imMpVMFvgL+zrs5qRoCmBadM8Higl3DQZGt/K21tnVkXuqdX4BXMstxJLzvRFixW5GY8eJ89OT7LoTMzTM6mHfEdla9jYSiynzk+nmDzmhgX9MYIBs2suM+mNU7WwPa1bVkhnNdN/SuWGaa/t4cL+trYsLYPMxzlxvADBAMm/e1OBU4vHXagY/5putjNLVebQXkxJrYmYCgCrlHjtNcRjvL6MpbtyzmiKsVe62qSabvkDbSYeJFpKGI5+hdPRy7j7vYbOWt1QHwYWvuysReeHLWtyZOj9nQ7lsJimgl7rtrM6EyKwZFZUpaNgSOuNTKTWlRjwsOLv+h3ZcHn0jZnp1Nce9l659g5Imuf/f7zKMUCfY/Eo1/ixDTM2E7/zREloUO8LfmdrF5CZzS4YPlrYjaNZWvfQmXl8KtXkszYJd/n6TCs64yyY137ghRnzxPpR1Sq1gJRuaJ3L47OFtVJKaZLUk6vRDi3Wa55tCk9EkopE/gy8DrgBPATpdR366Goeecjg/wfW5zshHLyOl7gYshUpIo85QdMTzRq/v0/si/h1oyjGbElMMyMHWVWxYgbrZjA0ZFZ2s0EHWvOowdnYvnjbz7lKC0WHKItbJC21YKS517Gw56rNvOhe37KWHzeELJs7ay7G9Dmegi87ZFogN62CHuv37kgUyL3CSu7lv6laYj1Z9NMO6MhOiP9bIkPc8cbLs8JoAzQHnUurYOnp0mmbTSaoGlkU0i9idJ7qgt2OvUvrlS/4IbI/fRlhjhm9POPvJED6lJmUxb/f05fblBnOa77+LvM1fzIvoSOiFH26XFDVzR7bs+fniaVsfnZ8YlsGfID5qUMbngFV7r9sfeRQY5952FeGJ5xlUUd48tUztDk6nZUSznNhL72MFNJRyI9HDQZ6IgQMJQv1/X8U3wou0QST2a4/5nTC9bVD56e5k0Fu2sJmXQlTzEb6JqvaWEoMmaUdfpMVq56z10HFlZidY3hnx+fJBw0GOiI0B4JVP2k7HcpIRwwinoVWsNmdtmmWDVRr/KmFyvhZzmmMMbEMwb8fLYwI+vsVJKe1hA9MUe6vNB740fHZLUX65KUzcpYznlU6UJfeX5DPrzYh7XWn691g9zjvhK4VWv9Bvf1x9zj/WWx97e1tenLL7+84uOcmpjj2NgsG2Ka43FV/gNe+3AmEsPNo9c52w1XgbKQcMAgYBp0qjjr7CGSFmgMDGwUNqfUAD29/XREgzx9ctLxSmidDb4DZ/5e3xllOpHJlk5e2xFBJ+N0dnYC8JOjY9m6A7gFprR2ZLUNV7wK3HTIgEE0aPLStU665uRcmtOTibx9e7oEk3NpzOHnMHQalPP0FjAU2BaYIejfkf18PJUhYzn9Yrh95ZVR94qD2VqzqcdxyZ6eTNBupEikEqyzTmFhkNEKExsDzXHWMkkMrXXJeI+Q62XY1BPLttljci7N8bHZrKckaBqOp8c1snD7KGgqtvQ6KbRHR+OOSqZSTCUcw8yT1Pb6DwWv2NSdPc7ExER2HGrFz09MEDSMPDdXxpXEDgWMBeOUy5PHxrPLVIZShAKKgGEQT2WyGTce8WSG9S2aCWt+P5at2ZAeJKwsbDXvvDS0TZoA7ec7GnWTc+m8/kpZtpNRVOZ6q4TCY1haZ6+h3HMfHRvnxKzKe59XQyRgGtn2Jd0g5ZBplNxXPdpX7L3xlLN0Fwk694juQJrhVICQaeT1Vanv52Lf23rx8MMPP6G1LizquIBY2NTbB2ojWnZIbarJflYql53ftWDbYuNQ6Ty6FMoZEh9f7MNa69tq3SD3uNcBV2ut/4f7+j3Ar2qtfz/nPTcANwAEg8HLd+zYUdEx0pZNKuNEHoRMKPAOlmqY8ztH/Gne/eC8Npg3JrQ723gBk7g3U8vKENAZFBqNIqMCWBgolOOCTlmO9oG7+9xaCYVuWwDLsjBNZ3s8ZVHMJNI5bVY5+/Mm4MXwan+Y2ARJ5yw5uH+YYSwMJ3tDOfu2vMZ7J+K+1wsAdXuGiKsmaVkWpk5n+9POuy4VSRVyjIhi16u79BE0FU6xU0csKWjmZJWoeQPQ1u6ansrvX8/QSbgeFO/0bE1WFVG5MRy4x/AMvaCpQNvZcagVhW3x2u812tteeO6mQdZrluvcMgCb/KUub78BpcloNf9+zYIx9/aXVkFCwXyjI23pPMM618D2/o74uN5KkXsMr88L92VZFigj731ei3LfmT/uxfdVCYXjBAuv8VLv9Zyb3nfDVBpLq2ycUTPy85//3Jch0RKN6K2bN9bkmAnC5d+0iil27//5z3/+Io4Mg8cdWus7wN88WivKpX/WxVCoBW5n3QFwxRVX6Mcff7yiz1/y8ftJJx3r4Q8uyfC5XyzsimjQyHodDNNgoD3CtZet58v/eZiZ1Hw6YdgtihUMOBkTvW3h7HJBMTepV0LaeZJIYmcsogGDaCjAjz72G8VdxW4AXqF8Njhpe7t37wbg8k8+SDyZyctQSLhP4mtaw6QyThlyT/XQz5pubnsuTjzJG+PfZk1miPHQOl523f8DF+xe0OafH59EKQiZRjZIEKXIWJqXbejIimt57vF9+/ax++k/hlgvKMXEXMqRjEbTxRQ3dX6FsXjKEQoDIiHHzd8RDWZrhOTKQXsu3ljYzK7Ve/z02ATRoMH2gXYmZlPZQEZDKb70nsu59b5n6YkFmUpkGJpMEE9kyLgxK5GA4x3IWJrzuqN5JbQ/dFGaN7+htgFRhUtOT52YJJW2CZmOuJZta5IZC8sw2Nbfmj33I8NxuiNmNhvHMJyqsYah2N4Xw9YsuL7etnaS/fG+BWmT3/3Xf+K6zH0M2GcYMvr5ZuAa3vL23yl57RRe386T8vz1XU9yvwuF7fE8e86YJ4inLHZtW1OTDJzCYwCMx5McH0+wpjNa9Pvvvffg6WlSaQsbePmGTl7fPca3htpLft+bgdzzXIxNXQH2/vaamhzzXF/aKBZsqZQa8WPQ1RtfMRJKqQjwfuAiHEEqALTWe+rUrpPAhpzX57nbasZMsrwLoicWYnIuTcLSXLQ2xtUXreXeJ0+ypi1MeiKRrbiotfOUN9ARyQsAK5Xbv7E7ygvDM5yZSjoGiOHIaaestLPOuoSI8A+8ajOfe/CXpNyS417Fy/72UDZgKzf2wQ+5EeNPRy7j6chl84bABa9e8B5wUkpTaSvrbk07j8uE3aezovEMXZsckalwK53REJvWwNj4GCetPnrbwtx89by0c+EaeDJt0xNbGNX/yzMzXLK+Pe8wXuDhxGyKF0dnMZTKepJuu+9ZYiGDs9NJTk8mMZRjtCRSGSwN3a0hkmmb9mhgQf0Pr/BYMapNHy2MoUhmbIIGhN0ql165+aSr3+G1x7I1ybSdzd5Jph0DMhYO8NE3bC96ffW3R9j7jiIT19t/h9v3v9J32714hs6WUDagMTcTZbnJja/wxlxr5wmvMJuk2nEqjOGYmE1xdHSOYGBhumrhewc6IrwwHCdkOg8ttis+txriHF5U61aMAdDMWRFVUvd51MNv1sY/AGuBNwAPuw2arkeDXH4CbFNKbVZKhYB3Ad+t5QHKBVYGDRibTfOKzd38/fWv4Nsf3MWBo2NEggb97RE298Yw3cqbGVuzaU0LHdGgr4jpPVdt5ux0yvFouBOBUor+9nA2iC43Itw0FC0hg1vvezZbRrtUlPeNu7fykde9hFg4kA0g7W8PsXlNa9XR837KOhe+Z6AjguVmOfS3h8i4KqBr28Olo+GvvMlJuUzOgNZ0Gim2dJhc+Tt/lq126GU5nJlK8NzQFD89NsGR4Ti21kWj9b225uKVfD45Ppd9stI4tSoccSzFmamk44lSbiaJabCxO8r2tW10xUILshRy03ALWayCbOH7ipWrz636GAmaBAL551lstcczljqiQbavbeNlGzrY2N3C9rVtJTMOWsPFnysqrTrpp3rncpLbntOTCXfFTbGuM5r3ffA7TuWOobXmpFtddUORKrqF7w0YijWtIbb0xhiNpwmahghKCbWg7vOoh9+sja1a63copd6qtf6aUuqfgEfq0SAArXVGKfX7wAOACezVWj9T5mMVETCgxH2fDV0R1nVGGY2n81yLuU/dHdEgW/tivDg6i62hPRLwfcPcta2XzmiQeCpDKqOLRrUXU3/0bm433/sUWlMyyvvG3Vu5cfdWYN7lmkuleeZ+PCSF7/FujmtaQ8RTNtvXOobMTNJiXWe4+JPeBbvz6jvQtSmvlgbALuMZ/jbwGdKjgxzXffxz4E38MnY5Z6dTnJlKsLZj3riZTVls64sxm7Lz2u6VfP7iDw9j23rBMsloPO2ksaYyJDI2Jk6w4ukpp5aIs8+FmQG5hcdy8aOBUDjOA6M/JnDPx4jHxon1b832w7a+GAdPz+SLjeWk83p0x0LZtGbvvMfiKQxFXuZMnrJljZ5V/FTvXE4KpbJbQibrOucLnHnfB79aFaW8FrnnbGnY7D5ceKQtm8deGFtQO2djd5Sbr96ePca+ffvEiBCWzHLMox5+DQkvn3BCKXUxcBroq0eDPLTW/w78e732f9G6dn5xcmpBFkAkYLC+q4V4MrPAs1DokuxsCZFIOwW3vBuC3xvm9oG2onEQhccsdnMbHJ1Fac3GHqdktGGo7NNO7sRUTZnvYlRb1jn35uibC3aXrm1xZB/cfzPWjMVsoIuNaoY/426+Fm7hB2oHZ6aStEWCecbOx6/Zke3H2MlHeWf6Ps5TZ5n68XpOdV7DT4MvL5lS6IlBvTg66yx94PT1ifEE04k0Sjn93h0LETCMbBpu4URzcGi6rGJi7jhfnHiS983dwRwhjiVjXJhTU+Sjb7goTxwraCi6okGiITPPaPCMJU9Z0pm4HMNjOaSU/RQsW0689hSLP/LG3I/sdTmFzWy6pnscj8m5NIMjs4RMRU8smL0+bxXPg1BH6j2Pevg1JO5QSnUBf4bjGmkFlkFjtH589A3b+YN//injc/niU5bWnJlKEDCMBZ6FYk/mQdPMq9rpN5fcbxxEsZtbxs1CyCX3hpd7syus5hl32BF+AAAgAElEQVQKmFW5mast61xTaenHvgKBKFNWhqCpSBAFG94Y/za/6P4VkhkbQ5Etmf2S/tZsuzqG9tN2bC8pM8ys0UU0Ncr1ia8yEdjDYPsrio6BV/Mkd/mjuyXImakkpqEcxcyUxXRilo5okNGZDLfvO7xAo2FiLk142ligW5BrzOWO8xvj3yZFmLQZJZ3REG7Nnv+ud3+D977yfO58ZJBEIk0sFOADr9pcsmT5je7+99x1IC/otF5Sys1eQGqx712p+JvccfLrtSg8znF3qWN9zlJHKW/Hi6OzJb1G5Sjs/52bumsmU14N5+tTyyNHXQuqkbSGFStrXUt8xUhorf9Waz2utX5Ya71Fa92ntb693o2rJ7u29bKxp4VYOIChFLGQQWvYxFCKqbnMopUrS6nZVbLG6lcZr1h8QiBgOFkQOeTe8HJvdp0tztprMGBwfDxR8jil1ueXwlLWnIsyfhRCMcJBI6vVkVAR+qzTzKYseltDzKZsLuiNccn6dixbZ49n/+grpFSYtNkCSpE2W8gYYd7DvxcdA298LFdt01P7nEpksoJUA51RAoajRaC1Uxvliz88TMa28xQd+9rmlxlKxQx44zw5l6YjeZKRdIB4ysL0vqGhGIwfzapVruuMcNnGTtZ1RlxBIhaNY/CrDFlsDP1eF7Uc73pcj7D4985PbIfffiw8jm1rNvVEF6hpFvN2pC27qv4r7P/BkTife/CXvDA8U5vvnyCUwG/WRlGTUmu9MsJxSzCTtLhooI1oKMMl5zlCQt66pV81u1wqLS3s5ym/2BNURySA1mRd2YVR3oVejI5oMFuqvFg6WSXlkyuhkjVnX09hblbHQEeEoyOzYGtiJDil+rOpnhnb5vh4Mpul0NUSZO/+QT6ePMWM6YxxxtXFsHWQHk7lHa/Qo7StIFXy6Miss6RhGgxNJrKplQk3tdKyNWPxVJ73ob89QjKj6W0Ll3wy3HPVZm6+9ylGZlIcN/roURPM2lFSGc3EXIpOIwVdm6ouX11NkalKr4taldau1/XoUep7V7g8FwsZxMImt973bHbMKulH7xjeEuOpiQRKqZJLjF7/GYZa1GtRisL+H59NYyrFxGyGtR2V72+1c8X53eXfJPjCb9ZGPOfHAn4T2FSnNi0bfrIRKqGSpz5vwvq1v/wBl3/yQV75lz8o+uRV7AnqU9deyqevuzS7rTDKu9Lzyr0B1aIugoef/qjoKczN6ug0UmzqidJqJDDtBA93Xce1l63nuaFpBkdmmZ5LA5p0xmZoIsHB09NMhNcRtOfI2NotKa5pIcEJ1Z89XrEn6pGZFKMzqexTqunKoK/tCJNM29msm4ibSRENLqwc68kvL+Yx2LWtlzWtIUKm4i79RqIqTVcw5WQPjY9lC4hV61moJpPCz3WR6zl47IUxUpn8666aAlL1uh794GWo3HrNDmZTNpat867LnZu6ffdj7vW0sTtKytIMjswyHk8uydtRisLPJ9NOCngiZ0ykoJdQD3x5JLTWn8t9rZT6LE4k6IrGe9q3XRXKperU+31a8W4wGdtmLJ5y3wcvDM8UffJa7AkKFkZ5V6pD4SfIrBr89EdFT2E5WR2d40fpPH8LXHkTr7QvcvtTZ1UUkxmbiKu1kEzbGK++idC+P3UnuggtJAiT5oHYb+VNUgufqB2thu5YiGNjc2ztjXF2KknQNAgFFMm0U+p9bUcYy06RyNikMjZPn5rivM4IQdPwfU3FUzY71rWTUK/inkSMN8a/TW/mNCetPrZc/WdwwW42dpcOFlyMajIpyl0XhZ6D01MJjo7OLfrU7Yd6XY+VUMq7kltFtFQ/enEKj70whmE4acXOEqPi+Pgcx8cTXLmle8HnvO9LLpX0X+H3LRw0SKSs7Peg0v3VgmbWkThw/arTjWgY1RbtasHRkljReDfXI0/9pGTWRSXBY34ncO8mdXzcCdozXZf4xGyGDd3BJbseS00aQNFA0Grc3n7w0x8VTxpFsjr23nXAMUbAKXaGo62QTFuEAgahgMEl/+1t/AIY/cEXOI+znFL9/EfstxjseAUtWmeP92rzad40+m36rCHOmgN8r+VtPJy+mG9/cH5J6PZ9h7nzkUHiSaceyppWp/2pjI3WJus7w0zOZTh8Nk40ZNIaDmQNFb/LD57wlyfkdOUFO333aSkqzaQod10UTrYbuqK8MBzn5PhcVlOlGsO8XtdjJSx2XS7Wj7nGla01WJqjI7NZnZnFlhiX+mBTeG10tQQ5kczQ2RKoyYOSIJTCb4zEL5jXcDKBXqA5zcwK2bWtl8zJFh669tUL/vfooeG8VLszk3McHJrm09dd6muNtZTh4d2kPNcjOJoAiYxVsyevwpvdYuvOS5mcyrVhsf549NAw4/EUx8dmeXW7xcRsis6WUMWThtefsUiAuWSGjFsowhHjckqbOwZUF+OBW2iLmAv0JjZ2R7lw9kneOXo7GRVmUnXSYY3z3qnbifR8EHh1ts1esOPWvhhnp5OcmUoyMRtH9TnaAZ0tIVpnnfLfmvmJsdw6f+44pC2bExMJkmlH4vrRQ8N5QaB+jFvP4JlKpGmPBPnAqzZn9UX8UO66KBaLs3lNC8fG5vIMcyhuwFZ73FwKDf23D2R8n99itIZNnhmadquuGtmqq+Wuy1zjylN0VcDQZKKsYJ03ts//7McLMo+KnWu5FOzNa2L89hUbGpq1IZwb+PVIvDnn7wxwRmtdm29sE/OZBw4yGk8RMBwZa1vDaDzFZx44WFUwpoc3sYSDBumMnZU5jgTMuj15LRYIt/f6nXUTECrVH55h0x4NuOvN8OLoLIm0k1JbiRHj9acXhBlxsypMBamMZmQmldVPsGybE24qXn97JG+SuvA//xcjOkRSRZyqjDpCWGv2BO4HN5GysB/72yO0hgMcGY4TCZlZl/7pScfbZFnad+CcNxF89vvPc/B0nEjAYMuaFmzNAq2CcmNz+77DfO7BX2IqN001meFzD/4SwJ8xcWQfuw58hW9zmMOza/jH2Tcx2v/KvOuimOcgaBpcuaU7+8RdqTGe2w/lPGo7N3UvSLUdiiayRle1PHpomLNTyex3M5W2eGE4zprWEDdfvX3Rz+YaV2s7wrw46gTnJlKWb8E624YLemNZI+q2+57l2svWLzhXv8ugNxYeYBlp1vTPZl1uWaksakgopbyw1kI57HblFLMaq0+zmoNDZ+PZpQcgm/Z36Gx8Sfv1nri6WoIMTSScctYKOlsCdXM9lltCWG4BofkJOUQkaKLUBLaG6YSVp8vhB68/I0GD83uinJhIkEpbbBtoQymVp5/gZVNMzWUImAXLWQ+cwlzTzdDUfNZHf3s3nalT2WOV6kdgvnw7jnfJYL4mhve+ct6mXdt62bt/kO1r2/Im6Eqj7e98ZBBTqWzxtlDAqbty5yOD5Q0JV/iLQJRY1wAvS8V5Weaf4FUvgwsqi8Wpxhj3+qGcR+2LPzxMX1soKwTmBGey5KXBvfsH6WkN0R4NZIuOhUxHqdXvQ4KXeg04ctmGorethKJrwbF/rYUFBv+djwyyrjOyYPtnv/98U+t2NDM7/+KhvNersNbGslHOI/EE89V2NwLj7t+dwDFg9S+26dwi3uSXEK+S3CeuZMYmmbYJBQy29LYu6UawmOuzGdadcymUG48ETV6+oWPR1NtSFD7B7tzUtaDSYi59bWFMw8hWHs3StYnOmbN0rs0p8pWcgY5N2Zel+vEl/a1oPZFNyQ0aipSlGegoLUJViloEG04l0gQMxWzKieNQOKqWiUyKPXcdWPw6c4W/skJYOYJYeXLlPpZZamWMF/OoOXFF6bxlKsNQS14a9PpfqXljwEsLL0ehcRU0DdZ2RBfozZTqs2Njc+xqzb+/tIRMphJptoZiedvTls3B03G2r23DVJqfDI7xyKERLlrXzh+9/qViUAjLRrky4psBlFJ3At9y5TZRSv0m8Lb6N6+xvKS/leeGplG2dtL8bI2l4cK1reU/XIZaewDK5d7XKw6iWqrVNSh1Ay7Vn36O48USXJS8nI8H7qatNUFfTw+k4tm0S4/cfkxlLE5NJEhkbC5a105nLJjVitjSG2NkxnkSrzTQrRZGXyRoMp3I4OmWWa6zxFSUj9cYP+qUc8/FFcSqihoY48WMK68wWS62rdnYHV2SwmZu/0/OpRmaTDCXsmgNB8oum/iJC1rse7qxO4pt5zuAZ1MW7ZHggvouJyYSRAIGactmcGQWy70//eLEJDff+xSfuvZSX8aLICwVvzESV2qtP+C90Fr/h1Lq03VqU9PwR69/KTff+xSTiQzpjE0gYLCmJcgfvf6ljW7aAsqJAVWT/ldPCg2bcqWTqxUpKmdA5cYSPGm+jE9a7+O9U//Oy+2TdK9/ycKiYW4/fuaBg7wwMks4aHJBb8x5Oo6nF0wa1fR3LYy+NbEgMwkn9iS3nExA+RCKyinnniUVd7bn4GdMKjHGK/WoeYXJTk/OMTGbZi5t86pWm97W8JIErbz+n0kmGJpIAE4wdFvE9LWfxR4Syn1P91y1meeePJtXNyWRtvnAqza7Cqbz25Npiy1rWjg+NkfacpZHTQU2MDKT4rPff55d24oX/qtnnZVcmjn9U6gdfg2JU0qpPwX+0X39buDUIu9fFeza1sunrr20aSbfxfDjDl/uOIjFKDRsgmuKl04ulpNfiepfOQOqMJbgSfNlPJa5hFgywBPvfl3JfTpxDORNbIXr89X2dy2MPtN00lBPT6XIuLEbQQOUq7m96FLJlTc5MRLgeCKKeGbAn5KlX2O8Go9awDC45tIB7ntqCMvWRIIGQVNx31NDC2InZpIJPnTPz+iKhcr2p9f/H7rnZ2ggGjRZ2xGmsyVEPLk0ZUg/sUoTL0TonVuoglpYT8Wr/jqXdgSn3Lg1TKUwFfzyzIzvcRKEpeDXkPjvwMeBb7mv/8vdturxOxk02nXYbDEQfsjt22Klk8vl5PuNG1hsDKcS6QUluAOmYiqx+Hp4sQmhFuvzHks1+pzrweC87hgHT0+TzjhLAEHXkFj02vBRzh38G69+jPFqPWqf/f7zGIZyV0tUNrg2N3Zici7N0EQCDWzti/l6It+1rZeuWIitfbFs0bZi51cpfr6nreFAUZ2JUgGo3sKR1o7BGCq4nptB4EtY3fhVthwDPlTntqxYGuk69Gi2GIiiHNlXdnLKZSk5+X5pjwSJJzOEAvOTRcbStEeCJT+Tq38RDZkMdEToiAaz6/O1pBbLI2vbwwyOzAJwXlfIXxriYuXcXfwar36MosUmu8I+8EpvP3pomGdOTRE0FAHTSaVOZWxMw8yLnRiadJYnokGzIm9WPYzzWn5PPePq//zHJ5hJOllCoYCBwqkns91dPlqJDxnlkAyL5qJc+ucXtNZ/qJS6j/ylVgC01m+pW8tWEM3gOsx9Yus58yN+l++xNThC7MBWMBafsJeFnJRCYr3OGvz9NztPviXaVouc/HJ84FWb+dyDvySVccTBUpZNOqOJhnTR7AbPaGyLmMymMiRSFoPDcQY6I+gOamK4eRPnwaFpJubS9LWF6G+PVGSgFj7BXzjQ5tSGSNm+0hD9UMtJsdRk1xo2Sxrpe/cPEgkY2Np5IvcyQ7R2/vbiDOZSjqjX2o5wdt9+65MUO7/e1jCXf/LBqoS+ah2rtGtbL3/zu5fnaXUYCnpiIT76hu2LnsdyPGTUTUei2pLfHlL6u6aU80j8g/v7s/VuyEqmWVyHu7b1sst4Bu7/J2fCDg34mrCXBZ8phbl4k0vasjk9mSRj2dgaAqZRs8nQmwDufGSQybk0ttb0tgXZvKa16MTtGY09rY7+xenJJHNpi6m5DAOdkSW3J9e7FU9lsG3NmakkkaAnduXfQC3mCvcmMD+S3X72X6tJsdRk1xIyShrpx8bmWNcZcb5nNtkMlYyt+cjrtmUVHVvDAdoiZl4J70rrkzw3NE0qY5O2bL7x+AkChqMRUrHQF4uLtO3dP8iV0RnuLpeiW7C/T19Xevmo2QKthdVHufTPJ9zfD3vblFJdwAat9VN1btuKoalch1VM2MtCFSmFe67azB9/8ylG4ylMQxE0DSwNa1pDVd0ISy0T3Lh7Kzfu3sqeu/ILYhXzLOUajZ0tITpbQlmNgdbwAqddxeR6t1IZTTBgYNua05NJOltCVRuotVh+K9V/tZiQSk12t973bEkj3fvend/TkhWOUsCOgTZnTAvOvTATwm99EnCURSOtBs+ecqSrLQ2WrQkFjJJCX5UsS+WOT6BVFR2fatKfc89DDAehXvittbEPeIv7/ieAs0qp/VrrD9exbSuGpopPqLUGQK0oklI4PT3BC3OdfOTzD/Oe82cX5Ojv2tZLX3uYqWTGrXlgZmseVLps5Gci9eNZyjUaJ2ZTWY9EazjATHJpQmWFbfAk1L06LFC9gbrU5bfliAMqNtktZqTnKpq+dG0rsymLoDmZdenn7ncpT+R79w+SsW2OjyezehxoSFmaoFk8OLewwu/xsVkee2GMP/j1rUU9F+XGp1z/NzrYuxT1Sv+Uyp3Nhd+sjQ6t9ZRS6n8Ad2utP66UEo+ES1O5Dn1qACw7BSmF09MTjE5M8o3Yu5wCZhmLG/7hCTqjQbYPtGX7byZpcZErde2hc6p1lqLwxjoWT5WdSBebtArjFlrDBtMJy8kWANqjAYYm4kuu85DbBq92iGVrTAXPnJwk4dZ/qPQ4S11+a1Qc0GJGeuH3rjVsYhhw633PVvzEvhgHh6YZc71iXpl6zbwkerHgXM/4OD2ZxFBOEGQ6Y/PFHx7m4vUdC9pSbnwW63+g4cHey02hvDVIAGYjMcq/BYCAUmoAeCcgUSpF2LWtl73X7+ShD7+avdfvbNwX+MqbnJz/5IxbS3umqAbAsuOlFLb2QXyYF+Zi3Bn7PY60XcHkXJq0pbFtTTyVyd4IHz00zMbuKLMpK29XfhQwb7vvWYank9kb6zOnpkhb+SqIhRPpnqs2k0jbbhExnQ3o3LmpO7u/Dd1R+tvDjMw4bY6ETDb3xuhvj2R1JJZCbhvaIwHWdoSxtSZhabRSWfErr3/8Uk0/5nJsbC5bU8RjOeKAPGOhty3MaDxNb1s4b4L0vne3XrODeNIx7HIn00r6qBRJN3XWNFReaqXGKR2fsmw6W4K89vMPs+euAzx6aJiDQ9McG50lkbFIZmwsWxM0ndTUYtdIufFZrP9zjYypRIbj43McG5vlQ/f8bMH5P3pomD13HchrqyAsFb+GxCeAB4AjWuufKKW2AIfq1yyhagombFr7Gh9o6XHBbnj3N+D3D/CR4C0cbr0ccCplAgQDBqmMU2ArEjTYu3+w5OS+2LLR3v2D7NRPcdvMJ/jc8A3cNvMJXh14mhOuSqFH4URaatI6cHQse6NWStHfHiFoGsTCJtvXttERdZ4ka6EjUdiGzWti7FjXzo6BNi5e105nSyivf/xSTT/mslRDZCn4MdK9ydQwVDbFs9I+KkUoYKCUGxNhKoLmvHcsaCq63NgVz4C5+V4nrsfSzg3W1ppE2iJtaaJBo+g1kjs+wILxWaz/PSNjci7N0ZFZ0hmboKmYSWbyjKliBnatjC3h3MavjsS/AP+S8/oF4Np6NWpVU6GWQlX40ABoNLkufC9IzrY14WC+8mI1y0Y9Z37Ejam/JaXCTKpOOqxx/tS8mz9PvYfx5K8tGseywAV+ZB+B45/kPM5wNjDAv8fextORy4guUudhqRS2oVjhsUq9AUtdfmuqOKAi1DNz6sKBNl4YnmFiNkMiYxELBehsCbCl11k+LAzQHRydRaGzypNKOc7BlGXT0RJgPJ7itZ9/eEHAqjc+GUsvyEparP/37h90SqhPJjCU4zmxbE00aGaNKU+NdbmXp5a1jPhSU0KrRVJJfQdbvgT4G6Bfa32xUupS4C1a6/9Z19atNqrQUlit5N4YIwHDWXPWZKtl5j7tVrq+/bt8jzlCpA3n8wkVJag1/1f0Qf6m7TX+J1J3vPpMizGrgw5rnPdN3c7XuJHTLReSmk7lZQJoXRsdiUJqlRW0lDiBpooDYmEMTGvYrJvHxLtWN3QHF0zixbJKMhkblGJ9Z5iTEwm0dlJTNTAWT7O+M1I0lsH72bdvHzfszle2LNb/Ozd158XtpDIWkaCJZWtsrVnbEc4zppolTV1YffgNtrwT+CjwVQCt9VNKqX8CxJCohAanZjZTZHfujXFkJgUkWdsRpj0SWLLY1NbgCIeSUQxbZ5/O0jrCjuhYUenhkrjj1d0VYmpkljiOkfP66W/xcPRi/uDXt2a1CjZ2R6vSkfAzJs3iDWiWFMJiGQyjMymUcrxClVZbLcdiRlQxIy8QMFBas76rhdZIMFs91Naa9Z2RrHR3pR6B3P7P7YMN3VHC04YTk5G2aA0H82qDeMZUU6WpC6sKv4ZEi9b6QG7kPJCpQ3tWNw1MzWwGGe9Ccm+M//bAQ2xOxWpi5MT6t3JB4CQnZg2SaZtw0OC8FotYjz/BoCzueHUqxaY1jtTydCrMevNMtt9uzHn7vn37Ktq93zFpNm9Aoynuonee+oNmktF4uuZ9VMyIevTQMKMzSQ6eniYcNDmv04md6YgE0JpswGzAiJJI28wkM/S3R7Jpw4mMRSRguIZ0ZRT2QX+7Y+SemXICgltC5gKDvFkMUj9ccX53o5sgVIBfQ2JEKXUBrky2Uuo6YKhurVqtNDA1sxlkvBejVKGiqrjyJtruv5kLu4IQanOrVyYrz1zJGa/OaIjOaMjJgmm9kPU16LNKxqRZvAHNQCkX/Wg8zfk9LTx07avr3oZcI3DLmhZOTSQ4MhznonXtfOraSwEWGH579w/ywvAMZ6aSGEoRNBSJtE3KStcknbevLUwy40igN4vCZbU6EqITsbLwa0h8ELgD2K6UOgkM4pQSFyrBZ3nmenBOrY/6rF5ZljqPV6PHpHBZ5e0DzelkLGxnLGQwm7JKuOhnl6VNuUZgLBygKxYmnszQHQvlTdyF3PAPTzgxE6bCtrWbBRSu2KAvtUyxfW3boga5GKRCPfCbtfEC8FqlVAwno2kWeBfwYh3btvqo1QRXBefc+mgtMldqOF7FYiEaOSbFllWGooklC2rVmmLtHIuncCtmL3DRZ04+syztOjY2x6vNp3nT6Lfps4Y4aw7wjcCb+e7wSxdkZHjs2tZLZzRIPJUhlXEylAY6IrRHAosaj8WuHW+ZYiaZYCyeIpF2hMredMnAcpy+IORRrvpnO443Yj3wHeAh9/VHgKeAr9e7gauOBqVmrqT10aaiBuNVKhbi2svWc++TJ2nEmBRbVvEEtZrJkCgVD2Eaiu5YaIGLft/J8vusRdDxGyLP8c7R28m4KcatmTHen7iDEfU+pmO7Ssa7bB9oW2A85gZEFmtr4bVz871PsaY1xMhMksm5NKahiIVMOluC3PvkyaLKmYJQT/xU/xwHfgR8ALgFRxH4t7TWP6tz24QaIgF7jaNULMSBo2Nlx6TSwk9+31tsWaUWglq1xmvnxYkneWPcefo/Yw5wj/FmPvPBD1W8v1oFHe8J3M+IDpFUEUylmLDCRLXFB0IP8FfqVSXjXYoZ9KMzjvy258nIXWIqvHYytmZkJsWUa0CETAOlFAOdUTqiQeLJ5ol7giXoSBTThBC9hqalnCGxRWt9CYBS6m9xAiw3aq0Ti39MaEbOxfXRZkh5XSwWYrExqWTSq3SCLLasUitBrVqysTvKwOiPuSH+RWL2DCYZOjOj3GwehSMvq9hbVKug457UKcw13QxNJUmmbbTW2IEW1nM2+56WkMnB09PsuetA3vWXazzGQgbTiTRnppPYtmZwJM4rwpnsEpN37XiZHl5xMNsG0zQImgpbOxlFHdHgqol7evzFsQXbbipSX8ND6mw0lnIS2dmSdlprCzghRoSwUqiLJPCRffD1d8KXdjq/j+wr+5Fq5aVzJ71yss+L1Vu4fd/hBfUViklm10tQaynsuWoz747fTYc9jqE0GYIYaLr0JPzwkxXvr2Y1Q7o20WmmuXBtOy/f0El7NEhUJTlrrs2+5ex0konZ9ILrD8hKfk8nMswkLTfw0jHmMrbmz7/zNOBcO2emErwwHGc6kcbWjnBbxgZTOUaEYSiSrsrqqo57EpqWch6Jlymlpty/FRB1XytAa63b69o6QVgCNU95PbKP+Hc/wpk5xVQmTPvUC/Sf/Qixt3xu0SfjauNTKsnq8N7r1VtwNBWc8tafe/CXnNcVpa8tnOepKFxWqUZQq97s2tZLxjhB2jbJaAPDgKAZwMSGs89VvD8/Aa6+vFgFGT3ntViMTiS5N/SWrCDWmakkfW2hRa+/o6NOlolhOBo9nlSPt33PVZt5/9ceJ2VpclV8NJDMWARNA8sN3FyqkFuzs+gSSaPksUGWXCjjkdBam1rrdvenTWsdyPlbjAihqal1xcrRH3yBE9MwY0cIBgxm7Agnpp3ti1GugmUpKvFkeO/NrbegtVPjwVSKs1MJnj89w6GzM5yenOMzDxxcUAyrNew3G3x5CShFNBigLRIgFgoQNA3Im1b9U654mW8vVkFxvLae9Uzv/p8M9fxqdow7osGsUJRH4fXnZZ8U4m33rhGvfHkuGRuSaaf6aMAwfF9XglBrmvPOIQhVkvs0OR5PYdl23s18Ka7f5PARkqod0316NA1FUkdIDB8p+9lq4lMq8WR4751LWdly1bbWKHf6mU1pWkKOCJKl4dmh6dqmetazGF3vdjjzjDObKgO0DXYG+i+qeFflgo4r8mIVZPRcAuz9b/P/3nPXgbLej9awyXTSQmudZyy0hucNYNNQ2VodSilsrbOGhmEoNnRHCRiGBE8LDcNvGXGhmUnOVLxuvxopfJpsi5icGJ/jzFSiqtLZhRyz+4ipZN62mEpy3O6rSdsL4xgq8WR4720NB0hbmqBpcH5PC7FwkJSls14KpRQKCAfNmpTYBuaL0c2czS9GV6vr8GA3JQoAABwZSURBVDf+HGJrHCPCSju/Y2uc7VWwWFnyWnqx/JRu/+BrthJwrQRbAxoUig++Zl7OfVtfLPs/nWNEKCBgOmXt/ZRML3aNCUItEI/ESufIPpg6sfAmfg5WFC18mvSKI03NZTANY8lZG4/0vIN3jn6ZiA0JFSGiEwR0kkd63sGVS2h3uYwLv+3dta2Xv37Xy7P7agmZJNIWE3NpwgHHN2HbGlvD+Z2R2kX317sY3QW74a1fXhYht1qKhPlJub5xt2Mw3PnIIFOJNO2RIP0dNu/YPW9IfPQN29lz10/I2PmLG+GAQSTgGD3ljJ1HDw3zx998iulEmrStOTM5x8GhaT593aUN92I0pK6GxDXUFDEkVjqPfQXCr21YRdFmolhwYn97hICZ5qEPL73+witfdy1f/tck12XuY8A+w5DRzzeD1/CW1127pP3WMii0cPLa0tuKaRicmU6SsebVFAOGYl1neEntzrIcxeiWScit1sJtfgzBG3dvzRoUsLD4265tvXz4dS/hiz88jGVrMpbtepdgbYczhuWMnc88cJDReIqA4Sxv2RpG46lsrIwgLAUxJFY640dhoGCFapkqijYb9Zac3rWtF97+O9y+/5U11aWodc2Nwskr1+NRFwXNBhajqzXNKtx24+6tXLy+g737Bzl4epqJ2TR9baGsCFW58Tx0No5pqPn4Hjfm4tDZ+DKdgbCaEUNipdO1yQk+y2WF3sSXynLIgNdD1MuvAVStuFbh5BgLGcTCJrfe92xtJsoGFqOrB80q3JbbrqquBa3Jy3bRej7fVBCWgBgSK50rb4InDzoBl6vgJr4UmuVpstKbvB8DqFgcxR9/8yn62sPMJK2yx/EmocXiMaqmgcXozlUqNXZe0t/Kc0PTKFtjGE7lUUvDhWtby394CfgpIy4lw1c+YkisdC7YDYdnINW3tJt4PdP3lpFGP01WU8vBjwFUGEeRtmxG4ymmkhkucgtB+akZsVg8xns3LeHEG1SMTvDHH73+pdx871NMJjKkMzaBgMGaliB/9PqXNrppwipADInVQLgV3v2N6j/vpe8Foud85sdSqTZwspwBVBhHcXoyiWkoLEtn5bP9HGfReIxNvk5RWIHs2tbLp669tOHeulykPsbqQQyJZqGRHoF6p++dQ9Q6cNKjMI4ikbEwcPQgKjnO4vEYs0tqo9DcNMJbt2j1T5G1XjWIIFUzUG9Bn3KMH3XiK3I5RzM/lkq1BbrKUShu5ClUDnRUptrpRyRJWB2IAJWwXIgh0QzkegSUcn4Hos725aBrkxOkmUudMz8Kb3IzyUzdjrWc1GuiLlS53NIbY01riIChKjpOtXU/hObBj4FQl8q3glACWdpoBpZD0Gcxljl9r1hA4lA0UdvaDw2inpkjxfQhqk0HXXJ7Vklw7krDbzBvzSvfCsIiiCHRDDRa0GeZ0/eK3eSUYtXc5JZrLbphGSoSnNswin13phNzfOien9EVC2UNynrF6jQUiWtoWsSQaAaaQdBnGdP3it3kDEOt7JvcucQyBudW63VZrRR+dyZmU5yZSmJr2NoXy3ooYiGD2ZRVN5XXpdCQ2hpCXZEYiWbA8wi09kF82Pm9ip/uigUk2rZuipuc4INlCs6Vdf6FFH53Tk8m0RqiITObBhwJGiilJKhWWDbEI9EsnEOCPsWUHLVGbnIrhWVaipN1/hzcmJT/d+wwv4h3cV/L2zjcejlzaQtFfvZOS8hkNJ7m1iZQeRXODcSQEJadYgGJA50RucmtFJZpKW5VrvNXQ05MSqxrgIsCE2yYvpMvZGwOh3fQHg3QEZ3vJ28Jo9Eqr8K5Q9MtbSilblVKnVRK/cz9eWOj2yTUnl3betl7/U4e+vCr2Xv9TlrDYtOuGCpdijuyD77+TvjSTue3T32UemlyrDgK0sPb2rtYv6abz5y3n79+18sJGIYsYQgVU8u5tlnv3n+ltf5soxshCEIJ/C7FLSHDYzmqua4IFkkPb5ZCdcKKpSZzbbMaEoIgrAaWkOEhk6RL1yamR09yYtYkmbYJBw3Oa7Fo69kENL5QnR8kU2N1o7TWjW5DHkqpW4HrgSngceAjWuvxIu+7AbgBoL+///J77rmn6mPOzMzQ2lrfcrr1ZKW3H+QcmoG6tH/4IBhFnlfsDPRur+2xWPljAAvPYW5mAnP6FBqFVgZK2yg0Vts6oq2dDWnja17zmie01leUe99LNm/QX/hft9ASqsEza8/Wpe9jlfGa17zmRWAkZ9MdWus7/HzW71zra1+NMCSUUg8Ba4v86xbgMZyO0cAngQGt9Z7F9nfFFVfoxx9/vOr27Nu3j927d1f9+Uaz0tsPcg7NQF3a//V3LszwSM44cRVLqVhbgpU+BrDwHPbcdYCB0R9zbeq79FmnOWuu5d7QWxjq+VX2Xr+zIW1USvkyJHasa9V3/96ltfFIiCDVAsqNQ63n2lI0ZGlDa+2rfqxS6k5Arh5BWKk0g9jaCufY2Bzx1sv5tJqfL7TWjJ5r2StCxSzXXNt0MRJKqQGt9ZD78reApxvZHkEQlsAyy6+vRhYv/d7cvKjWcVPgExy43td8JiwjtZxrm86QAD6tlHo5jrvlKPB7jW2OIAhL4hwSW6sHkr0i1ImazbVNZ0hord/T6DYIgiA0Cys5e+XCgXYO3CLeiGaklnNt0xkSgiAIK4plKKm+ElI8hXMXMSQEQRCqRUqqL87oYbjrzbXZl2RtNC1NJ5EtCIKwYiiQrybc6rx+7CuNbpkgLBtiSAiCIFTLMpVUF4RmRgwJQRCEauna5Ghj5FKHkuqC0MxIjIQgCEK1iODWojyX6mPnyT+UzI1VjhgSgiAI1dIAwa1HDw2vyFRQYfUihoQgCMJSWEbBrUcPDXPbfc8SCRr0xIIMTye57b5n+fg1O8SYEBqGxEgIgiCsEPbuHyQSNIiFAyiliIUDRIIGe/cPNrppwjmMGBKCIAgrhGNjc7SEzLxtLSGTY1LAS2ggYkgIgiCsEDZ2R5lNWXnbVkoBL2H1IoaEIAjCCmHPVZtJpG3iyQxaa+LJTFMX8JJaG+cGYkgIgiCsELwCXr1tYUbjaXrbwhJoKTQcydoQBEFYQUgBL6HZEI+EIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVI4aEIAiCIAhVE2h0AwThnOLIPnjsKzB+FLo2wZU3wQW7G9smQagXo4fhrjfXZl/X/1tt9iPUHPFICMJycWQf3H8zzJyFWK/z+/6bne2CIAgrFDEkBGG5eOwrEIhCuBWUcn4Hos52QRCEFYosbQjCcjF+1PFE5BKKOdsFYTXSs1WWJM4BxCMhCMtF1yZIxfO3peLOdkEQhBWKGBKCsFxceRNk5iA5A1o7vzNzznZBEIQVihgSgrBcXLAbrv4UtPZBfNj5ffWnJGtDEIQVjcRICMJycsFuMRwEQVhViEdCEARBEISqEUNCEARBEISqEUNCEARBEISqEUNCEARBEISqEUNCEARBEISqEUNCEARBEISqEUNCEARBEISqEUNCEARBqAvPDU2x8y8eanQzhDojhoQgCIIgCFUjypbCquLRQ8Ps3T/IsbE5NnZH2XPVZnZt6y3/QUEQBKEqxCMhrBoePTTMbfc9y/B0kp5YkOHpJLfd9yyPHhpudNMEQRBWLWJICKuGvfsHiQQNYuEASili4QCRoMHe/YONbpogCMKqRQwJYdVwbGyOlpCZt60lZHJsbK5BLRIEQVj9iCEhrBo2dkeZTVl522ZTFhu7ow1qkSCc21w40M6BW17b6GYIdaYhhoRS6h1KqWeUUrZS6oqC/31MKXVYKfW8UuoNjWifsDLZc9VmEmmbeDKD1pp4MkMibbPnqs2NbpogCEJTUct5uFEeiaeBtwP/lbtRKbUDeBdwEXA18BWllLnw44KwkF3bevn4NTvobQszGk/T2xbm49fskKwNQRCEhdRsHm5I+qfW+jkApVThv94K3KO1TgKDSqnDwE7gR8vbQmGlsmtbrxgOgiAIZajlPNxsMRLrgeM5r0+42wRBEARBqD8Vz8N180gopR4C1hb51y1a6+/UYP83ADcA9Pf3s2/fvqr3NTMzs6TPN5qV3n6Qc2gGVnr7Qc6h2YjH46vmXJqUNUqpx3Ne36G1vsN7Ue952KNuhoTWuppQ3ZPAhpzX57nbiu3/DuAOgCuuuELv3r27isM57Nu3j6V8vtGs9PaDnEMzsNLbD3IOzUYsFls159KkjGitryj1z3rPwx7NtrTxXeBdSqmwUmozsA040OA2CYIgCMK5QsXzcKPSP39LKXUCeCXwPaXUAwBa62eAbwDPAvcDH9RaW6X3JAiCIAhCpdRyHm5U1sa3gG+V+N9fAH+xvC0SBEEQhHOHWs7Dzba0IQiCIAjCCkIMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBKEuPDc0xc6/eKjRzRDqjBgSgiAIgiBUjRgSgiAIgiBUTaDRDRCE5eDRQ8Ps3T/IsbE5NnZH2XPVZnZt6210swRBEFY84pEQVj2PHhrmtvueZXg6SU8syPB0ktvue5ZHDw03ummCIAgrHjEkhFXP3v2DRIIGsXAApRSxcIBI0GDv/sFGN00QBGHFI4aEsOo5NjZHS8jM29YSMjk2NtegFgnCucGFA+0cuOW1jW6GUGfEkBBWPRu7o8ymrLxtsymLjd3RBrVIEARh9SCGhLDq2XPVZhJpm3gyg9aaeDJDIm2z56rNjW6aIAjCikcMCWHVs2tbLx+/Zge9bWFG42l628J8/JodkrUhCIJQAyT9Uzgn2LWtVwwHQRCEOiAeCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkYMCUEQBEEQqkZprRvdhiWjlBoGXlzCLtYAIzVqTiNY6e0HOYdmYKW3H+QclovztdZlNeeVUtPA88vQnmZkOcbR1zjUm1VhSCwVpdTjWusrGt2Oalnp7Qc5h2Zgpbcf5ByajdV0LpVyLp27LG0IgiAIglA1YkgIgiAIglA1Ykg43NHoBiyRld5+kHNoBlZ6+0HOodlYTedSKefMuUuMhCAIgiAIVSMeCUEQBEEQqkYMCUEQBEEQquacNiSUUlcrpZ5XSh1WSv1Jo9vjB6XUBqXUfyqlnlVKPaOU+pC7vVsp9aBS6pD7u6vRbV0MpZSplPqpUurf3NeblVI/dsfi/1NKhRrdxsVQSnUqpb6plDqolHpOKfXKFTgG/7d7DT2tlPpnpVSk2cdBKbVXKXVWKfV0zrai/a4cvuiey1NKqcsa1/JsW4u1/zPudfSUUupbSqnOnP99zG3/80qpNzSm1eUpdy9VSoXd6+mwe31tWv5W1h4f5/1h9179lFLqB0qp8xvRznpzzhoSSikT+DLwm8AO4L8rpXY0tlW+yAAf0VrvAK4EPui2+0+AH2ittwE/cF83Mx8Cnst5/Sngr7TWW4Fx4P0NaZV//hq4X2u9HXgZzrmsmDFQSq0H/gC4Qmt9MWAC76L5x+Eu4OqCbaX6/TeBbe7PDcDfLFMbF+MuFrb/QeBirfWlwC+BjwG43+t3ARe5n/mKe99qKnzeS98PjLvX1V/hXGcrGp/n/VOc79ilwDeBTy9vK5eHc9aQAHYCh7XWL2itU8A9wFsb3KayaK2HtNZPun9P40xg63Ha/jX3bV8D3taYFpZHKXUe8Cbgb93XCvh1nC8aNH/7O4D/BvwdgNY6pbWeYAWNgUsAiCqlAkALMESTj4PW+r+AsYLNpfr9rcDd2uExoFMpNbA8LS1OsfZrrb+vtc64Lx8DznP/fitwj9Y6qbUeBA7j3LeaDT/30twx+ibwG+73fiVT9ry11v+ptZ51X+aO7ariXDYk1gPHc16fcLetGFz34K8APwb6tdZD7r9OA/0NapYfvgD8MWC7r3uAiZybabOPxWZgGPh7d3nmb5VSMVbQGGitTwKfBY7hGBCTwBOsrHHwKNXvK/E7vgf4D/fvldJ+P+3Mvse9viZxvvcrmUrH5/3Mj+2q4lw2JFY0SqlW4F7gD7XWU7n/005Ob1Pm9Sql3gyc1Vo/0ei2LIEAcBnwN1rrXwHiFCxjNPMYALhxBG/FMYrWATEWutxXHM3e74uhlLoFZ+ny641ui1BblFK/C1wBfKbRbakH57IhcRLYkPP6PHdb06OUCuIYEV/XWv+ru/mM57Z1f59tVPvKcBXwFqXUURxX4K/jxBt0ui52aP6xOAGc0Fr/2H39TRzDYqWMAcBrgUGt9bDWOg38K87YrKRx8CjV7yvmO66Uuh54M/BuPS/us1La76ed2fe411cHMLosrasfvsZHKfVa4BbgLVrr5DK1bVk5lw2JnwDb3Cj1EE5Q03cb3KayuOuKfwc8p7X+fM6/vgu8z/37fcB3lrttftBaf0xrfZ7WehNOn/9Qa/1u4D+B69y3NW37AbTWp4HjSqmXupt+A3iWFTIGLseAK5VSLe415Z3DihmHHEr1+3eB97rZG1cCkzlLIE2DUupqnKW+t+Ssp4PT/ne5GQ+bcYJGDzSijWXwcy/NHaPrcL73K9JzlEPZ81ZK/QrwVZyxbeYHi6WhtT5nf4A34kRJHwFuaXR7fLZ5F47r9ingZ+7PG3HWG38AHAIeArob3VYf57Ib+Df37y04N8nDwL8A4Ua3r0zbXw487o7Dt4GulTYGwG3AQeBp4B+AcLOPA/DPODEdaRzP0PtL9TugcKLqjwC/wImeb8b2H8ZZa/e+z7fnvP8Wt/3PA7/Z6PYvcl4L7qXAJ3AmUICIez0ddq+vLY1u8zKd90PAmZyx/W6j21yPH5HIFgRBEAShas7lpQ1BEARBEJaIGBKCIAiCIFSNGBKCIAiCIFSNGBKCIAiCIFSNGBKCIAiCIFSNGBL/u71zjbGquuL47w8mQo3agBI10aCo1Zi0EwVrJAxqatVGjRaMwSYGE7W2VSwREz/4DiYQErENqRhJNIgPokg6FZWnyKMiIB0QqIlpizQxaa2viBmDjssPax04c7n3zp3rkF6G9ft09uPsx83d56y99j77n7QEkroldYYS5YuSfvA9ynpa0sS4nldPjE3SRZIubKKOXZKOq4h7O/qwW9JHcd3ZqNKhpD014h+OQ22qtb1QT726UB+UdE0zAnSSHpPUHterJW0upY2OuMtK/doTyoedkuZLmixpTkWZqyWNjusVanFF1KS1KD0XdkjaKukuSYMibbSkP9a5d6SkG+qknyTppbg+4L/bQNsmSzqpFK77rBnIpCGRtApdZtZmrkS5F7itnFg6bbFPmNnNZrazTpaLgD4bEjXq+qmZtQH3AwujP21mtqvefXFgUs2xaGb3m9mKXuruMLMZEbwGVyNsGEnDgQvMRaUKRki6oqKepUW/8HM0fhXhGxuo5hngt31pV3LYUzwXzgEuxZU2HwAws81mNqXOvSOBqoaEpCPM7EMzm1gtvUEm48fLE+3p7VkzYElDImlF1gKnx4x7raQOYKekwZJmSdokaZukX8O+F/GcmB2vAEYUBVXMiC+XtCVmNivDU3AbMDVmPeMkHS9pUdSxSdLYuHe4pGUxM5qHH3bUK5IelDStFN4eM6WR0d75+IFQxfHBs6OOlZKOj7iyh+VySe9J2gL8slTu5PgNLgSuBmZFn0ZF3iLfGeVwiQnA6xVxs/ADkfqLDmBSP5aXHEaYnwx5K3B7jPmyR258yVP2N0lHAzOAcRE3NcZIh6RVwMoYg9tLVZwcz4v3JT0Q5fbII2lajOmJuHbGs1H+0IpnzSRJ78Z4n1m6f4+kR+IZtEFSywr79YU0JJKWIjwPV+AnEYJrWNxpZmfipwB+bmZjgDHALfKjg68FfoTPwm+kiochXspPAhPM7CfAdeEpmAvMjlnPWlz3Y3bUMYGQOsdnQetiZrQYOKUfunsG8CczO8fMPsCFszZHHW9GneU+DIk+XAWcB5xQWaCZ/RV/Yd8dffoH8LmktshyE/BUlbaMxdU/y7wF7JV0cbMdrGjbp8CR4f1Ikj5jZv8EBlOaLATTgN+Fp2wc0IUL6a2NcTA78p0LTDSz8VWKPx8f8z8GriuMghrteImeHrmuIi2WO2biOkJtwBhJhbT9UcCGeAatAW5pvPetSxoSSaswVFInPjh343oiABvN7F9x/XNcO6ETl04fjr+M24HnzazbzD4EVlUp/wJgTVGWmX1Sox0/A+ZEHR3AMXKl1XZgQdy7BPj0e/XW+cDMNpTC3wIL43oBfhx6mbNwoa33zY+kXdBgPfOAmyQNBq4HnquS50RcGr2S6cC9DdZT65jccvx/KbmDk6SfWA88KmkK8ENzqfJqLK8z9peb2cdhFLzMgeOvUcYAq80F8Qo11/ZI2wu8Etfv4MsvhzxNrTsnyUGgK2YT+5AELtG9Lwq4w8yWVuT7RT+2YxC+V+CrKm1phm/oabAPKV1/SX366/z6Rbh3YxXwjplVU13sqmibN8BslaTpuCHWGx/jmiNlhgH/K4WHRF1J0mcknQZ04wbp2UW8mc2QtATXvlgv6bIaRdQbc5Xjzag/fpvha9uvS9HNAHkHp0ciOZRYCvxGLqOOpDMlHYW7CK+PPRQnAtVc8RuA9lgKQdKwiP8COLqUbxlwRxEoLQmsITZuyTcgNvr1wS7cnYqkc4FT6+QdxH7lzRuAdRXp7wEjJY2KcK39Bj36FEbRUuBxqi9rAPwdOL1G2nRcnbI3NgFjJZ0AvqseFwL7d4SFL8fsaqCsJOlBLE/OBeaUXsZF2igze9fMZuL/w7M4cGz3xqWShkkaim9YXo8Lbo2IPVJH4lLvBbXK3wiMl3RceAEn4UuVA5Y0JJJDiXm41PWW2AD1BG7RL8aVH3cC8/G1/R6Y2Uf4Rq2XJW1l/xLCX4Bri82WwBRgtHwz5072fz3yEG6I7MA3Oe5usM2LgGFx3+24UmAtvgTOj75dgqsIlvvwVfRhSWyYrCVL/AJwd2w6K4yOZ/Glk2U17lmCf8FyAGb2KtWXPSrz/Qe4E3g1loYeAyaZ2beR5Tx8fbiW2zlJKhkaY3MHrqS5DB+Llfw+NjZuw5VVX8OVebtjY+PUBuraiI/XbcCi+Crka3wcbgSW48Z8wdPA3GKzZRFpLlV/D/AGsBX3Av6ZAUyqfybJYYD8y5Fjzey+OnnWAVea2WcHqQ1/wGWUVx6M8pMk+f8wINZnkiSpjaTFwCjcy1GPu/CvUQ6KIQFsTyMiSQYe6ZFIkiRJkqRpco9EkiRJkiRNk4ZEkiRJkiRNk4ZEkiRJkiRNk4ZEkiRJkiRNk4ZEkiRJkiRN8x3oEe4VjVFCxQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_dir = f'plots/{name}'\n",
        "if not os.path.exists(plot_dir):\n",
        "  os.makedirs(plot_dir)\n",
        "\n",
        "f, axs = plt.subplots(1, 2, figsize=(8,6), gridspec_kw={'width_ratios': [4, 1]})\n",
        "\n",
        "f.suptitle(f'Residual Plot - {name}', fontsize=13, fontweight='bold',  y=0.92) \n",
        "axs[0].scatter(train_pred,train_residuals, label='Train Set', alpha=0.75, color='tab:blue')   \n",
        "axs[0].scatter(test_pred,test_residuals, label='Test Set', alpha=0.75, color='tab:orange')\n",
        "axs[0].set_ylabel('Residual (NTU)')\n",
        "axs[0].set_xlabel('Predicted Turbidity (NTU)')      \n",
        "axs[0].axhline(0, color='black')\n",
        "axs[0].legend()\n",
        "axs[0].grid()\n",
        "\n",
        "axs[1].hist(train_residuals, bins=50, orientation=\"horizontal\", density=True, alpha=0.9, color='tab:blue')\n",
        "axs[1].hist(test_residuals, bins=50, orientation=\"horizontal\", density=True, alpha=0.75, color='tab:orange')\n",
        "axs[1].axhline(0, color='black')\n",
        "axs[1].set_xlabel('Distribution')  \n",
        "axs[1].yaxis.tick_right()\n",
        "axs[1].grid(axis='y')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.05)\n",
        "\n",
        "plt.savefig(f'{save_dir}/residualPlottraintest_{name}.png', dpi=150)\n",
        "plt.savefig(f'{plot_dir}/residualPlottraintest_{name}.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IN4Su1U1YGtq",
        "outputId": "cee9c0e6-49cb-4469-f77c-fa934ac39c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 936x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(13,6))\n",
        "fig.suptitle(f'Nilai Prediksi vs Observasi - {name}', fontsize=13, fontweight='bold',  y=0.96)\n",
        "\n",
        "ax[0].scatter(test_true,test_pred, label=f'$Test\\ R^2=${round(test_score[3],3)}',color='tab:orange', alpha=0.75)\n",
        "theta = np.polyfit(test_true, test_pred, 1)\n",
        "y_line = theta[1] + theta[0] * test_true\n",
        "ax[0].plot([test_true.min(), test_true.max()], [y_line.min(), y_line.max()],'k--', lw=2,label='best fit')\n",
        "ax[0].plot([test_true.min(), test_true.max()], [test_true.min(), test_true.max()], 'k--', lw=2, label='identity',color='dimgray')\n",
        "ax[0].set_xlabel('Measured Turbidity (NTU)')\n",
        "ax[0].set_ylabel('Predicted Turbidity (NTU)')\n",
        "ax[0].set_title(f'Test Set', fontsize=10, fontweight='bold')\n",
        "ax[0].set_xlim([0, 130])\n",
        "ax[0].set_ylim([0, 130])\n",
        "ax[0].grid()\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].scatter(train_true,train_pred, label=f'$Train\\ R^2=${round(train_score[3],3)}', color='tab:blue', alpha=0.75)\n",
        "theta2 = np.polyfit(train_true, train_pred, 1)\n",
        "y_line2 = theta2[1] + theta2[0] * train_true\n",
        "ax[1].plot([train_true.min(), train_true.max()], [y_line2.min(), y_line2.max()],'k--', lw=2,label='best fit')\n",
        "ax[1].plot([train_true.min(), train_true.max()], [train_true.min(),train_true.max()], 'k--', lw=2, label='identity',color='dimgray')\n",
        "ax[1].set_xlabel('Measured Turbidity (NTU)')\n",
        "ax[1].set_ylabel('Predicted Turbidity (NTU)')\n",
        "ax[1].set_title(f'Train Set', fontsize=10, fontweight='bold')\n",
        "ax[1].set_xlim([0, 130])\n",
        "ax[1].set_ylim([0, 130])\n",
        "ax[1].grid()\n",
        "ax[1].legend()\n",
        "\n",
        "plt.savefig(f'{save_dir}/predErrorPlottraintest_{name}.png', dpi=150)\n",
        "plt.savefig(f'{plot_dir}/predErrorPlottraintest_{name}.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wOpMjYgaYGtr",
        "outputId": "f63e6b98-dc33-4ae5-e1b3-020fdaac91f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "fig.suptitle(f'Nilai Prediksi vs Observasi - {name}', fontsize=13, fontweight='bold',  y=0.96)\n",
        "\n",
        "\n",
        "ax.scatter(train_true,train_pred, label=f'$Train\\ R^2=${round(train_score[3],3)}', color='tab:blue', alpha=0.75)\n",
        "ax.scatter(test_true,test_pred, label=f'$Test\\ R^2=${round(test_score[3],3)}',color='tab:orange', alpha=0.75)\n",
        "ax.plot([test_true.min(), test_true.max()], [test_true.min(), test_true.max()], 'k--', lw=2, label='identity',color='dimgray')\n",
        "ax.set_xlabel('Measured Turbidity (NTU)')\n",
        "ax.set_ylabel('Predicted Turbidity (NTU)')\n",
        "ax.set_xlim([0, 130])\n",
        "ax.set_ylim([0, 130])\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "plt.savefig(f'{save_dir}/predErrorPlottraintestgabung_{name}.png', dpi=150)\n",
        "plt.savefig(f'{plot_dir}/predErrorPlottraintestgabung_{name}.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xCs7oFYiYGtr",
        "outputId": "bc92aa21-e3ab-4cac-fb9f-504a62eeefcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(6,6))\n",
        "fig.suptitle(f'Nilai Prediksi vs Observasi - {name}', fontsize=13, fontweight='bold',  y=0.96)\n",
        "\n",
        "amax = test_pred.max()\n",
        "delt = abs(test_true.max() - amax) + 2\n",
        "\n",
        "ax.scatter(test_true,test_pred, label=f'$Validation\\ R^2=${round(test_score[3],3)}',color='tab:green', alpha=0.75)\n",
        "theta = np.polyfit(test_true, test_pred, 1)\n",
        "y_line = theta[1] + theta[0] * test_true\n",
        "#ax.plot([test_true.min(), test_true.max()+delt], [y_line.min(), y_line.max()+delt],'k--', lw=2,label='best fit')\n",
        "ax.plot([0,amax+2], [0,amax+2], 'k--', lw=2, label='identity',color='dimgray')\n",
        "ax.set_xlabel('Measured Turbidity (NTU)')\n",
        "ax.set_ylabel('Predicted Turbidity (NTU)')\n",
        "ax.set_title(f'Test Set', fontsize=10, fontweight='bold')\n",
        "ax.set_xlim([0,amax+2])\n",
        "ax.set_ylim([0,amax+2])\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "\n",
        "plt.savefig(f'{save_dir}/predErrorPlotVal_{name}.png', dpi=150)\n",
        "plt.savefig(f'{plot_dir}/predErrorPlotVal_{name}.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-2pzk2WPYGts",
        "outputId": "69342fe3-078d-4498-9366-2dd5a068238c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAGECAYAAABj6sl8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xcZbn3/8/VJiQkKaUhUGnDtoAUDJZSCJXIKVY84AGUk6JRKrgRnro9bA/FBwVEUfLAVvCHW62wBQluYKMgKm6k1ABisLRYTqmUggWGIJC2QJOQkLTX74+1kk5CkpmszmTN4fvOa16Zdb7WPYf7mnvday1zd0RERESimBJ3ACIiIpK/lEiIiIhIZEokREREJDIlEiIiIhKZEgkRERGJTImEiIiIRKZEQmJnZovNzM1sQ4r5PHw0Znj7F4brbc3AurISo2SWmTUOvlZxxzIWM5uT9H6ak2LejL2HRSZKiYSMycxak77I3My6zGytmZ1nZpbBTbUDVwD/lcF1ZlRSsjP42GZmHWb2azObt4PrznglYGYbRsT7ipmtMbOzMrWNcDvJ5XJj0vgj060ER6zvmnCZayawzB5mdq2ZvWRmveF+njKhHclNrxJ8Lq4In0d+ryQnTuM8LhyRvDRmfI+kIJXEHYDkhbXAncA84J3Ad4B/AldnYuXuvhJYmYl1TZIrgJ2A9wMfAY40szp374w3rFH9laBsG4B64Kdm9qS735WFbZ1iZpe5+wNZWPeowoT2t8BC4BHgf4GPAjeZ2cnu/qvJiiXT3H0T8MUMrS5B8L4F2AX4dPj8V+E0gPsztC0pNu6uhx6jPoBWwIFrwuEpwMZw3JVJ800Dvgf8HegB1gEXATuH00uA7wPPAH3hOlYCJ4bTF4fr3JC0zr2A24EtwHrglHAeBxrDea5Jjm9EzBeGw3OBe4GXgP5wffcARyctc2G4TOs4ZTEYoyeNq0+K6fhw3MgYpwBnAg+G2+4AbgPmj9iHkY85O/jabRhRDrsmrfsrSfPtAfwYeDJ87R4jqLymhtOrgJ8DzwOvh+V4L3DkyHIBtg2WIXDkyH0ZpSwSwHVA7YjXbtgjxX5+IJyvF5gejvteOG5N0nxHh9t9DfgL8PlRXs9x38fhPHXh+6cbeBj4VLqvGXBTON+l4fCHw+FHk8q6Pxw3D5iTvO7x3itsfw/fA3wLeAHYBPxk8LVMiiN5vY3pTtNDj7EeOrQhaQl/+c0n+LIFWJ00/g7gXGAAuJ6gwvkm8Mtw3k8CXyL4Ff9z4A9AGcGX5WjbmkLwK/M44GWCCuY/Ioa+W7jd3wPLgIeAo4BbzWy3iOvEzEqBxqRRL40x63eBqwgqoF8TVNgfAu43s/nAHwlaDQCeY0RTdiaE5fmOpFGDr10F0AacTZDcXQdUAj8ALgvn/SpBstAD/AxYDrwJ2HeUTV0PHGNmHxojlMGy2JOgLNqBJuAvZjYNuJmg9Yvw/2BZjKc+/P93d38lfP6X8P9BZlZpZrUELRULCBKldQQJw5B03sdmVkXQMncUwWu1Crg8RXzJ7gz/Hx3+bwz/15nZ7gTJVwnwT3d/ZJTl03mvHAmcGG5rF+CzwCcmEKPIhOnQhqTj9PABwS+mrxH8OgI4gqDZHIJfqn3A34ADgQ+Hx8fLwukbCCqQJ9z9H2Y21vtvIUHSAsEv/b+Z2aEEX9wT4u5tZnYOsIjg1/eaMOYZwGEEFcyEjNJB738YpVnYzHYi+OULcJ67/0dYYT1CUD7/5u6fMbO5wNuB9e4+ZlO2mS0EPp40aqW7/3Ks+UMXhA8IWgE+5+5/CodPBPYh+DU/WPk+BLwZOMfMzmX7a9dOUNGvc/fnxnjtvkHQcnQJ8H9GxL4T8G/h4APA5vBxFEHr00nufqWZ1QNvDfctnWb9PZP2jRHPjaAlpgnYmSDZe4e7v25mj7A9WYL03seHA7OArQQtWv80szuAG9KIE4IkDOCQMClpJCjXOuAY4NBw+qiHndz9l2O9V5K6LL0CNLh7l5ntStBicxjwizRjFJkwJRKSjrXA3QT9AWYSVBY/IviV+uak+c4eZdm9gGsJvqQ/QvCrDzP7J7CEILEY6V+SnreH/x9NM9Zh72kz+wJj/2qcmeY6R7qCoDJ5Ebjf3e8eY77dCSowCON3dzezRwkqqH8ZY7mx1AFfSBq+lu2tPmP5a7jtUwh+oZ5sZi3uvo3tr135iPVCkEDsQXBI6gDgPcAHAczsKYLE8s/JC7j702Z2JfBl4IwR69sdqAifj9ZisVeK/RjL8+H/aUnjBp87QcU6WM5Puvvr4fOR76d03seD63nJ3f8ZPn8o3UDD5PlJgtacDwEHEZT7Nwn6Hh0Sznrn6GtIS7u7d4XPN4b/p401s0gm6NCGpGOlu58DvIugReIwgiZgCPo9QHB8fI672+AD2M/d7wW2ufvpwHSCY7DfIGge/39jbO/ZpOd14f+3jTLf4BdmNYCZlQH7j5hncfj/JoJm+z2TpkU688Tdv+juX3b35nGSCIBOgmPyECQOg03oB4bjBstuIPw/7ufR3a9JLl93X5xGuP/r7p8hSCQgqMAGlxvc/mZglxGv3Vvc/VngVXf/MEFltB9BArkPwTH50XyX4HBU04jxL7G9LD45Yluz2d46kFZZJFkd/n+rmU0Pnx8R/n8krFQH30/7hi0j8Mb3Uzrv46fDeWrMrCZ8PtEzdgZbJc4jeP+1EvRreB/bWySWv3GxIanKpz/pec6e2iqFRYmEpM3dH2P7mRpfMrM9gPsIfvVOAdrM7Gdm1mJmD7P9l9Vp4S+xXxIccz8hHL9pjE39laD5H+A2M7sKuHWU+QbPDnivmX0/3F7NiHk6wv/HAD9k/C/pjHL3PuDKcPBiM7uWoGXnbQRN5z8Kpw1WUIeZ2U/M7DtZiOWPbD+Mc2GYdP2a4HDTDOBvZvZTM7vBzNaz/XVeGh4GuJagn8u7wvGjvnYenGnwXUZ8t4QtAYP7u8zM/tvMrjKzuwkq8cHWocGy+ICZXWlm/55i135PcMhrJ+BeM7sOGFxmsByvJzh8sztBf4xrgG+PWE867+PfEfRNKAm3dTVBZ8aJGFzXgQQtBo8SJBP7AKXAWnd/bpzls/5eSfKfZnZ/0uObWdyW5LO4e3vqkbsPRpy1EY6bRXBIw4HLw3HTCSqPxwl+db5E0Oz9+XD64cCfCA4F9BP8Uv8dcEA4fTFvPGvjzQSdMrcATxF0GBt5RkQJ8FOCSu1Zgmb4vzD8bIV9CSrv1wjO/vhw0noWh/NcSISzNsaYb7SzNj5LcLx9C8Fps78DDklappygUn8lXLYzA6/dhuRyCMctIPjF7cAXw3FvAv6ToBNobxjfncDHw+kfCst0I0HnwxcI+gTsOVa5hPvzdFJZzEkqi38laEV4haCT4MMErRFV4Tx7EPQR6A6XXZXGvs4k6Ci6kSBBewj42Ih5GsPX4DWChOHfR4l73PdxOM/gWRs9YexnJe1nbRqxziA4LObALeG4tyWt44dJ884ZpQxHfa8wynuYUc5qGmW9jeNMG/m4JtX+6VGcD3NX65eISDrMbIa7b04aPp2gwu4GZrh7/1jLihQqdbYUkZxmZp8D3jLKpPXufuUo47Pp+2Y2k+A6KLuz/Wymy929P8diFZkUapEQkZwWXg76mFEm3e3ujZMcyxKCwyKzCVohniDo+9Hi7p5LsYpMFiUSIiIiEpnO2hAREZHIlEiIiIhIZEokREREJLKCOGujpqbG58yZE2nZ7u5uKisrMxtQAVH5pKYySk1lNL58K5/Vq1d3uvvuqebbke9mSS3d1yHbCiKRmDNnDqtWTfh+TgC0trbS2NiY2YAKiMonNZVRaiqj8eVb+ZjZ06nn2rHvZkkt3dch23RoQ0RERCJTIiEiIiKRKZEQERGRyAqij4SI5Kf+/n4SiQS9vb1xhxKr6dOns3bt2rjDeIPy8nJqa2spLS2NOxTJYUokRCQ2iUSCadOmMWfOHMws7nBis2XLFqZNmxZ3GMO4Oxs3biSRSLD33nvHHY7kMB3aEJHY9Pb2sttuuxV1EpGrzIzddtut6FuLJDUlEiISKyURuUuvjaRDiYSIFK13vvOd3HHHHcPGXX755ZxzzjljLtPY2Dh0bYT3v//9vPzyy2+Y58ILL+Syyy4bd9u33nor7e3tQ8Pnn38+y5cvn0j4o+rp6eETn/gE8+bN421vextHHnkkXV1d4y7z3e9+d4e3K8VLiYSIFK3TTjuNG264Ydi4G264gdNOOy2t5W+//XZ23XXXSNsemUhcdNFFHHvssZHWleyKK65g5syZPPLIIzz66KNcffXVKTtLKpGQHaFEIk1tHW0sWb6EE249gSXLl9DW0RZ3SCJFJ9Ofw5NPPpnf//73vP766wBs2LCBjo4OjjrqKM455xzq6+s58MADueCCC0Zdfs6cOXR2dgJw8cUXM3fuXI488kgef/zxoXl+9rOfcdhhhzF//nxOOukkenp6+Mtf/sJtt93GV7/6VQ4++GCeeuopFi9ezM033wzAXXfdxYIFC5g3bx5nnHEGfX19Q9u74IILOOSQQ5g3bx5///vf3xDT888/z+zZs4eG999/f8rKygBoaWlh4cKFHHzwwXz2s59l69atnHvuubz22mscfPDBfOITn9ih8pTipEQiDW0dbTSvbKazt5Pq8mo6eztpXtmsZEJkEmXjc1hdXc3ChQv5wx/+AAStEaeeeipmxsUXX8yqVat4+OGHufvuu3n44YfHXM/q1au54YYbWLNmDbfffjsPPPDA0LQTTzyRBx54gIceeoi3vvWtXH311bzjHe/g+OOP59JLL2XNmjXss88+Q/P39vayePFibrzxRh555BEGBgb48Y9/PDS9pqaGBx98kHPOOWfUwydnnHEGzc3NNDQ08I1vfIMnnngCgLVr13LjjTdy3333sWbNGqZOncr111/PJZdcws4778yaNWu4/vrrI5elFC8lEmloaW+hrKSMytJKzIzK0krKSspoaW+JOzSRopGtz2Hy4Y3kwxo33XQThxxyCAsWLOCxxx4bdhhipHvvvZePfOQjVFRUsMsuu3D88ccPTXv00Uc56qijmDdvHtdffz2PPfbYuPE8/vjj7L333sydOxeA008/nXvuuWdo+oknngjAoYceyoYNG96w/GALx1e/+lU2bdrEYYcdxtq1a7nrrrtYvXo1hx12GAcffDB33XUXTz31VHqFJDIOXUciDYmuBNXl1cPGVZRUkOhKxBSRSPHJ1ufwhBNO4Etf+hIPPvggPT09HHroofzjH//gsssu44EHHmDGjBksXrw48mmQixcv5tZbb2X+/Plcc801tLa27lC8g4cppk6dysDAwKjzVFVVceKJJ3LiiScyZcoUbr/9dnbaaSdOP/10vve97+3Q9idi3eZ1LLpp0YSXW3HqiixEI9miFok01FbV0jPQM2xcz0APtVW1MUUkUnyy9Tmsqqrine98J2ecccZQa8Srr75KZWUl06dP54UXXhg69DGWo48+mltvvZXXXnuNLVu28Nvf/nZo2pYtW9hzzz3p7+8fduhg2rRpbNmy5Q3r2n///dmwYQPr168H4LrrruOYY45Je3/uu+8+Nm/eDMDrr79Oe3s7b37zm3nXu97FzTffzIsvvgjApk2bePrp4OaRpaWl9Pf3p70NkWRKJNLQVNdE30Af3f3duDvd/d30DfTRVNcUd2giRSObn8PTTjuNhx56aCiRmD9/PgsWLOCAAw7g4x//OEccccS4yx9yyCF89KMfZf78+Rx33HEcdthhQ9O+/e1v8/a3v50jjjiCAw44YGj8xz72MS699FIWLFgw7BBDeXk5P//5zznllFOYN28eU6ZM4eyzz057X5588kmOOeYY5s2bx4IFC6ivr+ekk06irq6O73znO7znPe/hoIMO4t3vfjfPP/88AGeddRYHHXSQOltKJObucceww+rr6z3qPe9bW1tpbGxMOV9bRxst7S0kuhLUVtXSVNdEw6yGSNvMJ+mWTzFTGaU2VhmtXbuWt771rWmvp1A/h7l4iexBo71GZrba3etTLbvLvrt4/fdSzvYGOrSRnnRfh2xTH4k0NcxqKIgvLJF8ps+hSO7RoQ0RERGJTC0SIiKSFXNnzNVhiiKgFgkRiVUh9NMqVHptJB1KJEQkNuXl5WzcuFEVVg5ydzZu3Eh5eXncoUiO06ENEYlNbW0tiUSCl156Ke5QYtXb25uTFXZ5eTm1tbpejoxPiYSIxKa0tJS999477jBi19rayoIFC+IOQyQSHdoQERGRyJRIiIiISGRKJERERCQyJRIiIiISmRIJERERiUyJhIiIiESmREJEREQiUyIhIiIikSmREBERkciUSIiIiEhkSiREREQkMiUSIiIiEpkSCREREYlMiYSIiIhEpkRCREREIos1kTCz/zKzF83s0aRx1WZ2p5k9Ef6fEWeMIiIi+Wiy6ti4WySuAd43Yty5wF3uvh9wVzgsIiIiE3MNk1DHxppIuPs9wKYRo08Arg2fXwt8eFKDEhERKQCTVceW7OgKsmCmuz8fPv8nMHO0mczsLOAsgJkzZ9La2hppY11dXZGXLQb5VD7d/d1s7N1I/9Z+SqeWslv5blSWVmZ9u/lURnFRGY2vUMunu7u7IPcrh9SY2aqk4WXuvizFMmnVsRORi4nEEHd3M/Mxpi0DlgHU19d7Y2NjpG20trYSddlMaetoo6W9hURXgtqqWprqmmiY1RBrTINyoXzS0dbRxuUrL6espIyK8gp6Bnro6+5j6cKlWS/LfCmjOKmMxleo5fPc689x0YsXTdr2Vpy6YtK2lSM63b0+6sLj1bETEXcfidG8YGZ7AoT/X4w5nqxq62ijeWUznb2dVJdX09nbSfPKZto62uIOLa+0tLdQVlJGZWklZkZlaSVlJWW0tLfEHZqISC7JeB2bi4nEbcDp4fPTgd/EGEvWqQLMjERXgoqSimHjKkoqSHQlYopIRCQnZbyOjfv0z/8G2oD9zSxhZmcClwDvNrMngGPD4YKlCjAzaqtq6RnoGTauZ6CH2qramCISEYnXZNWxsfaRcPfTxpj0rkkNJEa1VbV09nYO6xSoCnDimuqaaF7ZDASJWM9AD30DfTTVNcUcmYhIPCarjs3FQxtFpamuib6BPrr7u3F3uvu7VQFG0DCrgaULl1JTXsOm3k3UlNdMSkdLEZFil9NnbRSDwQowV8/ayCcNsxpUbiI5ZO6MucV4JkXRUSKRA1QBiohIvtKhDREREYlMiYSIiIhEpkRCREREIlMfiXHk8qWrRUREcoESiTEMXrq6rKRs2KWrdUqhiEh61m1ex6KbFsUdRko6s2TH6NDGGAYvXf1K7yuseXENazeuZcOrG/juX78bd2giIiI5Q4nEGBJdCV7ufZmO7g62+lYMY5tvY8OrG7j6kavjDk9ERCQnKJEYQ21VLS/0vADAFJuCmWFmTGEKv3jsF7HE1NbRxpLlSzjh1hNYsnyJ7hAqIiKxUyIxhqa6Jrb61qHhrb6Vbb4Nx9nct3nSK3HdblxERHKREokxNMxqoKq0CsOGEgrDAJjClEmvxHW7cRERyUVKJMbxmXmfYeqUqUwJ/wzDcUqnlvLslmc5955zJy2Z0O3GRUQkFymRGMeZ885kycFLwGAb2zAzSqaUMMWmsNOUnega6Jq0lonaqlp6BnqGjdPtxkVEJG5KJFI4c96ZHDnrSOp2q6OqtIqdpuzE1ClT2cY2dp6686QdXtDtxkVEJBcpkUjDYCX+2sBrTGEKW7cFHS9nVsyctMMLg7cbrymvYVPvJmrKa3RxLBERiZ2ubJmGwUr83HvOpWugi52n7szMiplML59Od3/3pB1e0O3GRUQk16hFIk0Nsxq45OhL2KtqL2ZPm80uZbvo8IKIiBQ9tUhMwGDLhG7kJSKSPbr3RX5RIjFBOrwgIiKynQ5tiIiISGRqkSggbR1tOuwiIiKTSi0SBUL34hARkTgokSgQuheHiIjEQYc2CkSiK0F1efWwcboXh4jEae6MuToDowioRaJA6F4cIiISByUSBUL34hARkTgokSgQuheHiIjEQX0kCoguliUiIpNNLRIiIiISmRIJERERiUyJhIiIiESmREJEREQiUyIhIiIikSmREBERkciUSIiIiEhkSiREREQkMiUSIiIiEpkSCREREYlMiYSIiIhEVtSJxPn3nc/ajWuZd+08DvnFIZx/3/lxhyQiIpJXijaROP++87ll/S04DkC/93PL+ls4+49nxxyZiIhI/sjZu3+a2fuAK4CpwFXufkkm1/+7J3836vj7nr+Pqx+5mjPnnZnJzeW8to42WtpbSHQlqK2qpamuSXcSFZEdsm7zOhbdtCjuMArCilNXTHiZbNejg3KyRcLMpgI/Ao4D6oDTzKwuk9vo9/4xpy17eBltHW2Z3FxOa+too3llM529nVSXV9PZ20nzyuaiKgMRkUIyGfXo0LbcPRvr3SFm1gBc6O7vDYe/DuDu3xtt/mnTpvmhhx46oW2sfmE123wbs6fO5rmtzw2bNsWmsMtOu7DfjP0ixZ9vntj8BP3b+plqU4fGbfWtlE4pZXfbnV133TXG6HLfyy+/rDJKQWU0vnwrn7vvvnu1u9enmq9k5xKfts+0yQip4M3fff4bxo33Oky0Ht0RuXpoYzbwbNJwAnh78gxmdhZwFkBpaSkvv/zyhDawV8leDGwboNRKmT119vCJBrbVJrzOfFW1tQozgxE5pW91ttrWoimHqLZuVRmlojIaX6GWTwkl7GF7xB1GQRjj/VFjZquShpe5+7Lwecp6NFNyNZFIKSysZQD19fW+atWqFEu80dl/PJuDthzEj7t+DMAUprDT1J3Yo2IP5uwyhx8d+6OMxpyrlixfQmdvJ5WllUPjuvu7qSmv4ZSSU2hsbIwvuDzQ2tqqMkpBZTS+fCsfM0trvp1m7cTs82ennlFSGq2PhJl1ptMylG25mkg8B+yVNFwbjsuon7znJ9z8h5up6K1gwAfYeerOTC+bTumUUprqmjK9uZzVVNdE88pmACpKKugZ6KFvoI+muib61vXFHJ2IFJsoHQvlDSalHoUc7WwJPADsZ2Z7m9lOwMeA27KxoZqda7j8nZdz+JsOZ7edd2POLnNYunBpUZ2x0DCrgaULl1JTXsOm3k3UlNcUXRlkU1tHG0uWL+GEW09gyfIl6sQqIpNh0urRnGyRcPcBM/sccAfBaSv/5e6PZWt7DbMair7SVBlkx+AZMWUlZcPOiFGiJiLZNJn1aE4mEgDufjtwe9xxiOyIlvYWykrKhvqfDP5vaW9RIiEiWTVZ9WiuHtoQKQiJrgQVJRXDxlWUVJDoSsQUkYhIZimREMmi2qpaegZ6ho3rGeihtqo2pohERDIrZw9tiBSC8c6IESl0c2fM1RkYRUAtEiJZpDNiRKTQqUVCJMt0RoyIFDK1SIiIiEhkSiREREQkMiUSIiIiEpkSCREREYlMiYSIiIhEpkRCREREIlMiISIiIpEpkRAREZHIlEiIiIhIZEokREREJDIlEiIiIhKZEgkRERGJTImEiIiIRKZEQkRERCJTIiEiIiKRKZEQERGRyJRIiIiISGRKJERERCQyJRIiIiISWUncAYjI5GrraKOlvYVEV4Laqlqa6ppomNUQd1gikqfUIiFSRNo62mhe2UxnbyfV5dV09nbSvLKZto62uEMTkTylFgmRItLS3kJZSRmVpZUAQ/9b2lvUKiEZt27zOhbdtGjCy604dUUWopFsSSuRMLMpwHxgFvAa8Ki7v5jNwEQk8xJdCarLq4eNqyipINGViCkiEcl34yYSZrYvsBQ4FngCeAkoB+aaWQ/wU+Bad9+W7UBFZMfVVtXS2ds51BIB0DPQQ21VbYxRiUg+S9VH4jtAC7Cvu7/X3Zvc/WR3Pwg4HpgOfDLbQYpIZjTVNdE30Ed3fzfuTnd/N30DfTTVNcUdmojkqXFbJNz9tHGmvQhcnvGIRCRrGmY1sHThUp21ISIZk+rQxokjRjnQCaxx9y1Zi0pEsqZhVoMSBxHJmFSdLT80yrhq4CAzO9Pd1bVWRERGNXfGXJ2BUQRSHdr49GjjzezNwE3A27MRlIiIiOSHSBekcvengdIMxyIiIiJ5JlIiYWb7A30ZjkVERETyTKrOlr8l6GCZrBrYE9D5YiIiIkUuVWfLy0YMO7AReMLdX89OSCIiIpIvUiUS57n7eyYlEhEREck7qfpI1ExKFCIiIpKXUrVI7DrKRamGuPuvMxyPiIiI5JFUicR04IOAjTLNASUSIiIiRSxVIvG0u58xKZGIiIhI3knVR2K0lggRERERIHUikZVrRZjZKWb2mJltM7P6EdO+bmbrzexxM3tvNrYvIiJSzDJZD6c6tPE7M0u+IJWx/QJV7u77Tiz0IY8CJwI/TR5pZnXAx4ADgVnAcjOb6+5bI25HRERE3ihj9XCqRKJ+xPAU4FTgK8DfJhj0EHdfGwY8ctIJwA3u3gf8w8zWAwuBtqjbEhERkeEyWQ+nuvvnxnBDU4BPAl8F1gAfcPf2qDswjtnA/UnDiXDcG5jZWcBZADNnzqS1tTXSBru6uiIvWwxUPqmpjFJTGY2vUMunu7u7IPcrh9SY2aqk4WXuvmwH15l2PTwo1b02SoEzgC8BfwY+7O7r04nEzJYDbxpl0nnu/pt01jGesLCWAdTX13tjY2Ok9bS2thJ12WKg8klNZZSaymh8hVo+lZWVBblfOaTT3UceORiS7Xp4UKpDG/8ABoDLgWeAg8zsoMGJ412Qyt2PjRDPc8BeScO14TgRERGZgMmqh1MlEssJOlfODx/JsnFBqtuAX5rZ9wk6eewHrMzwNkRERGR0E66HU/WRWJyx0JKY2UeA/w/YHfi9ma1x9/e6+2NmdhPQTtASskRnbIiIiGRWJuvhVH0kmoBfuvu2MabvC+zp7n+eyA64+y3ALWNMuxi4eCLrExERkfRlsh5OdWhjN+BvZrYaWA28BJQDbwGOATqBc9PdmIiIiBSWVIc2rjCzK4FFwBHAQcBrwFrgk+7+TPZDFBERkVyVqkWC8NjIneFDREREZEiqe22IiIiIjEmJhIiIiESmREJEREQiS3X657+PNw+6bYQAABp9SURBVN3dv5/ZcERERCSfpOpsOW1SohAREZG8lOr0z29NViAiIiKSf1Ke/glgZuXAmcCBBBekAsDdz8hSXCIiIpIH0u1seR3BrUjfC9xNcDewLdkKSkRERPJDuonEW9z9m0C3u18LfAB4e/bCEhERkXyQbiLRH/5/2czeBkwH9shOSCIiIpIv0uojASwzsxnANwnuVV4FnJ+1qERERCQvpJVIuPtV4dO7gX2yF46IiIjkk3TP2hi19cHdL8psOCKSi9o62mhpbyHRlaC2qpamuiYaZjXEHZbkuHWb17HopkUTXm7FqSuyEI1kS7p9JLqTHluB44A5WYpJRHJIW0cbzSub6eztpLq8ms7eTppXNtPW0RZ3aCKSA9I9tPEfycNmdhlwR1YiEpGc0tLeQllJGZWllQBD/1vaW9QqISKRb9pVQXAtCREpcImuBBUlFcPGVZRUkOhKxBSRiOSSdPtIPAJ4ODgV2B1Q/wiRIlBbVUtnb+dQSwRAz0APtVX6LSEi6Z/++cGk5wPAC+4+kIV4RCTHNNU10byyGQhaInoGeugb6KOprinmyEQkF6S6jXh1+HTk5bB3MTPcfVN2whKRXNEwq4GlC5fqrA2ZsLkz5uoMjCKQqkViNcEhDQP+BdgcPt8VeAbYO6vRiUhOaJjVoMRBREY1bmdLd9/b3fcBlgMfcvcad9+N4FDHHycjQBEREcld6Z61cbi73z444O5/AN6RnZBEREQkX6Tb2bLDzL4BtITDnwA6shOSiIiI5It0E4nTgAuAW8Lhe8JxIiK6hLZIEUv3ypabgC9kORYRyUODl9AuKykbdgntpQuXKpkocrrXRnFIdfrn5e7+RTP7LdsvSDXE3Y/PWmQikhd0CW2R4paqReK68P9l2Q5ERPJToitBdXn1sHG6hLZI8Rg3kXD31eH/uwfHmdkMYC93fzjLsYlIHtAltEWKW1qnf5pZq5ntEl7p8kHgZ2b2/eyGJiL5oKmuib6BPrr7u3F3uvu7dQltkSKS7lkb0939VTP7DPALd7/AzNQiISK6hLaMSZfILg7pJhIlZrYncCpwXhbjEZE8pEtoixSvdK9seRFwB/Ckuz9gZvsAT2QvLBEREckH6V5H4n+A/0kafgo4KVtBiYiISH5It7PlXDO7y8weDYcPCi+ZLSIypraONpYsX8KTLz/JkuVLaOtoizskEcmwdA9t/Az4OtAPEJ76+bFsBSUi+W/wipedvZ1MnTJ16IqXSiZECku6nS0r3H2lmSWPG8hCPCJSIJKveGl9piteFiFdIrs4pNsi0Wlm+xJeJtvMTgaez1pUIpL3El0JKkoqho3TFS9FCk+6LRJLgGXAAWb2HPAPgluJi4iMSle8FCkOabVIuPtT7n4ssDtwAHAMcGQ2AxOR/DbsipfoipcihWrcRCK8LPbXzexKM3s30AOcDqwnuDiViMioBq94WVNew9ZtW6kpr9GtxUUKUKoWieuA/YFHgH8F/gScAnzE3U+IulEzu9TM/m5mD5vZLWa2a9K0r5vZejN73MzeG3UbIhK/hlkN/OjYH7Hvrvvyo2N/pCRCJEdksh5O1UdiH3efF674KoIOlv/i7r07tAdwJ/B1dx8ws2aCU0uXmlkdwWmlBwKzgOVmNtfdt+7g9kREZJLpXhs5LWP1cKoWif7BJ+FKEhlIInD3P7r74Omj9wODva9OAG5w9z53/wfBIZSFO7o9ERER2S6T9XCqFon5ZvZq+NyAncNhC+LwXSLtwXBnADeGz2cT7NCgRDjuDczsLOAsgJkzZ9La2hpp411dXZGXLQYqn9RURqmpjMZXqOXT3d1dkPuVQ2rMbFXS8DJ3XxZhPZHq4UHjJhLuPjVCQACY2XLgTaNMOs/dfxPOcx7Bha2un+j6w8JaBlBfX++NjY2R4mxtbSXqssVA5ZOayig1ldH4CrV8KisrC3K/ckinu9ePNTHb9fCgdK8jMWHh6aJjMrPFwAeBd7m7h6OfA/ZKmq02HCciIiITMFn1cLpXtswoM3sf8DXgeHfvSZp0G/AxMyszs72B/YCVccQoIiJSqDJZD2etRSKFK4Ey4M7w/h33u/vZ7v6Ymd0EtBM0tSzRGRsiIiIZl7F6OJZEwt3fMs60i4GLJzEcERGRopLJejiWQxsiIiJSGJRIiIiISGRKJERERCQyJRIiIiISmRIJERERiUyJhIiIiESmREJEREQiUyIhIiIikcV1ZUsRkUnV1tFGS3sLia4EtVW1NNU10TCrIe6wRPKeWiREpOC1dbTRvLKZzt5Oqsur6eztpHllM20dbXGHJpL31CIhIgWvpb2FspIyKksrAYb+t7S3qFUii9ZtXseimxZNeLkVp67IQjSSLWqREJGCl+hKUFFSMWxcRUkFia5ETBGJFA4lEiJS8GqraukZ6Bk2rmegh9qq2pgiEikcSiREpOA11TXRN9BHd3837k53fzd9A3001TXFHZpI3lMiISIFr2FWA0sXLqWmvIZNvZuoKa9h6cKl6h8hkgHqbCkiRaFhVoMSB5EsUCIhIiJZMXfGXJ2BUQR0aENEREQiUyIhIiIikSmREBERkciUSIiIiEhkSiREREQkMiUSIiIiEpkSCREREYlMiYSIiIhEpkRCREREIlMiISIiIpEpkRAREZHIlEiIiIhIZEokREREJDIlEiIiIhKZEgkRERGJTImEiIiIRKZEQkRERCIriTsAEREpTOs2r2PRTYsmvNyKU1dkIRrJFiUSIiIT0NbRRkt7C4muBLVVtTTVNdEwqyHusERio0MbIiJpautoo3llM529nVSXV9PZ20nzymbaOtriDk0kNkokRETS1NLeQllJGZWllZgZlaWVlJWU0dLeEndoIrFRIiEikqZEV4KKkoph4ypKKkh0JWKKSCR+SiRERNJUW1VLz0DPsHE9Az3UVtXGFJFI/NTZUkQkTU11TTSvbAaCloiegR76BvpoqmuKObLcNHfGXJ2BUQTUIiEikqaGWQ0sXbiUmvIaNvVuoqa8hqULl+qsDSlqapEQEZmAhlkNShxEksTSImFm3zazh81sjZn90cxmhePNzH5oZuvD6YfEEZ+IiEghy2Q9HNehjUvd/SB3Pxj4HXB+OP44YL/wcRbw45jiExERKWQZq4djSSTc/dWkwUrAw+cnAL/wwP3Arma256QHKCIiUsAyWQ/H1kfCzC4GPgW8ArwzHD0beDZptkQ47vlRlj+LIFti5syZtLa2Roqjq6sr8rLFQOWTmsooNZXR+Aq1fLq7uwtyv3JIjZmtShpe5u7L0l14R+vhQVlLJMxsOfCmUSad5+6/cffzgPPM7OvA54ALJrL+sLCWAdTX13tjY2OkOFtbW4m6bDFQ+aSmMkpNZTS+Qi2fysrKgtyvHNLp7vVjTcx2PTwoa4mEux+b5qzXA7cT7MBzwF5J02rDcSIiIjIBk1UPx3XWxn5JgycAfw+f3wZ8Kuw1ejjwiruP2ZwiIiIiE5fJejiuPhKXmNn+wDbgaeDscPztwPuB9UAP8Ol4whMRESloGauHY0kk3P2kMcY7sGSSwxERESkqmayHdYlsERERiUyJhIiIiESmREJEREQiUyIhIiIikSmREBERkciUSIiIiEhkSiREREQkMiUSIiIiEpkSCREREYlMiYSIiIhEpkRCREREIlMiISIiIpEpkRAREZHIlEiIiIhIZEokREREJDIlEiIiIhKZEgkRERGJTImEiIiIRKZEQkRERCJTIiEiIiKRKZEQERGRyJRIiIiISGRKJERERCQyJRIiIiISmRIJERERiUyJhIiIiESmREJEREQiUyIhIiIikSmREBERkchK4g5AREQK07rN61h006IJL7fi1BVZiEayRYmEiEieaetoo6W9hURXgtqqWprqmmiY1RB3WFKkdGhDRCSPtHW00byymc7eTqrLq+ns7aR5ZTNtHW1xhyZFSomEiEgeaWlvoaykjMrSSsyMytJKykrKaGlviTs0KVJKJERE8kiiK0FFScWwcRUlFSS6EjFFJMVOiYSISB6praqlZ6Bn2LiegR5qq2pjikiKnTpbiojkkaa6JppXNgNBS0TPQA99A3001TXFHNkbzZ0xV2dgFAG1SIiI5JGGWQ0sXbiUmvIaNvVuoqa8hqULl+qsDYmNWiRERPJMw6wGJQ6SM9QiISIiIpEpkRAREZHIlEiIiIhIZEokREREJDIlEiIiIhJZrImEmX3ZzNzMasJhM7Mfmtl6M3vYzA6JMz4REZFClol6OLZEwsz2At4DPJM0+jhgv/BxFvDjGEITEREpeJmqh+NskfgB8DXAk8adAPzCA/cDu5rZnrFEJyIiUtgyUg/HkkiY2QnAc+7+0IhJs4Fnk4YT4TgRERHJkEzWw1m7sqWZLQfeNMqk84D/S9CcsiPrP4ug2YWZM2fS2toaaT1dXV2Rly0GKp/UVEapqYzGV6jl8+LLL7LslmUTXm7ujLlZiKYg1ZjZqqThZe4+VODZrocHZS2RcPdjRxtvZvOAvYGHzAygFnjQzBYCzwF7Jc1eG44bbf3LgGUA9fX13tjYGCnO1tZWoi5bDFQ+qamMUlMZja9Qy+dlf5kb+m+Y8HIrGnWjrzR1unv9WBOzXQ8PmvRDG+7+iLvv4e5z3H0OQbPJIe7+T+A24FNhr9HDgVfc/fnJjlFERKRQZboezrWbdt0OvB9YD/QAn443HBGRwtHW0UZLewuJrgS1VbU01TXp5l8y0oTr4dgTiTAbGnzuwJL4ohERKUxtHW00r2ymrKSM6vJqOns7aV7ZrFuQyw7Xw7qypYhIEWhpb6GspIzK0krMjMrSSspKymhpb4k7NMlzsbdIiIhI9iW6ElSXVw8bV1FSQaIrkbVtzp0xlxWnquNkoVOLhIhIEaitqqVnoGfYuJ6BHmqramOKSAqFEgkRkSLQVNdE30Af3f3duDvd/d30DfTRVNcUd2iS55RIiIgUgYZZDSxduJSa8ho29W6iprxGHS0lI9RHQkSkSDTMalDiIBmnFgkRERGJTImEiIiIRKZEQkRERCJTIiEiIiKRKZEQERGRyJRIiIiISGRKJERERCQyJRIiIiISmRIJERERiUyJhIiIiERm7h53DDvMzF4Cno64eA3QmcFwCo3KJzWVUWoqo/HlW/m82d13TzWTmW0BHp+EeApROu+JtF6HbCuIRGJHmNkqd6+PO45cpfJJTWWUmspofIVaPoW6X5Mhn8pOhzZEREQkMiUSIiIiEpkSCVgWdwA5TuWTmsooNZXR+Aq1fAp1vyZD3pRd0feREBERkejUIiEiIiKRKZEQERGRyIo2kTCz95nZ42a23szOjTueXGBme5nZn8ys3cweM7MvhOOrzexOM3si/D8j7ljjZGZTzexvZva7cHhvM/tr+F660cx2ijvGOJnZrmZ2s5n93czWmlmD3kPDmdmXws/Yo2b232ZWns/vo1Tfp2ZWFu7T+nAf50x+lLkpjbL79/A7+WEzu8vM3hxHnOMpykTCzKYCPwKOA+qA08ysLt6ocsIA8GV3rwMOB5aE5XIucJe77wfcFQ4Xsy8Aa5OGm4EfuPtbgM3AmbFElTuuAP7X3Q8A5hOUld5DITObDXweqHf3twFTgY+Rp++jNL9PzwQ2h/v2A4J9LXpplt3fCN4rBwE3A/9vcqNMrSgTCWAhsN7dn3L314EbgBNijil27v68uz8YPt9CUAHMJiiba8PZrgU+HE+E8TOzWuADwFXhsAGLCD7goPKZDhwNXA3g7q+7+8voPTRSCbCzmZUAFcDz5O/7KJ3v0+TX/2bgXeFnp9ilLDt3/5O794SD9wO1kxxjSsWaSMwGnk0aToTjJBQ2PS4A/grMdPfnw0n/BGbGFFYuuBz4GrAtHN4NeNndB8LhYn8v7Q28BPw8PPxzlZlVovfQEHd/DrgMeIYggXgFWE3+vo/S+T4dmifcx1cIPjvFbqJ10ZnAH7IaUQTFmkjIOMysCvgV8EV3fzV5mgfnCxflOcNm9kHgRXdfHXcsOawEOAT4sbsvALoZcRijmN9DAGH/kBMIkq5ZQCXwvliDkpxnZk1APXBp3LGMVKyJxHPAXknDteG4omdmpQRJxPXu/utw9Atmtmc4fU/gxbjii9kRwPFmtoGgCXIRQX+AXcMmatB7KQEk3P2v4fDNBImF3kPbHQv8w91fcvd+4NcE7618fR+l8306NE+4j9OBjZMSXW5Lqy4ys2OB84Dj3b1vkmJLW7EmEg8A+4W9pHci6Oh0W8wxxS48Znk1sNbdv5806Tbg9PD56cBvJju2XODuX3f3WnefQ/CeWeHunwD+BJwczla05QPg7v8EnjWz/cNR7wLa0Xso2TPA4WZWEX7mBssoX99H6XyfJr/+JxN8doq2VSpJyrIzswXATwmSiJxMwIv2ypZm9n6C491Tgf9y94tjDil2ZnYkcC/wCNv7APxfgn4SNwH/QnC79lPdfVMsQeYIM2sEvuLuHzSzfQhaKKoJelg35eKvhsliZgcTdEbdCXgK+DTBjxa9h0Jm9i3gowRnSv0N+AzBsfG8fB+N9n1qZhcBq9z9NjMrB64j6He1CfiYuz8VX8S5I42yWw7MI+hPA/CMux8fU7ijKtpEQkRERHZcsR7aEBERkQxQIiEiIiKRKZEQERGRyJRIiIiISGRKJERERCQyJRKSE8xsq5mtCe+G+D9mVrED67rGzE4On1813g3ZzKzRzN4RYRsbzKxmxLi/hvvwjJm9FD5fk+6dDs2sa4zxF4UXpBkt9sE7kB4/eOdAM/twlJvQmdnlZnZ0+LzVzFYlTasPx703ab+6wrsWrjGzX5jZYjO7csQ6W82sPny+3Ir8rp8yMUnfC4+Z2UNm9mUzmxJOqzezH46z7Bwz+/g402eZ2c3h8ze8d9OIbbGZzUoaHve7ppApkZBc8Zq7HxzeDfF14OzkiUlX/JsQd/+Mu7ePM0sjMOFEYoxtvd3dDwbOB24M9+dgd98w3nIWGPOz6O7nu/vyFNu+zd0vCQc/THAnwbSZ2W7A4e5+T9LoPczsuBHbuWNwv4BVwCfC4U+lsZnrgP8zkbik6A1+LxwIvJvgLpkXALj7Knf//DjLzgFGTSTMrMTdO9z95NGmp2kxwSXOCeNJ9V1TsJRISC66F3hL+Iv7XjO7DWg3s6lmdqmZPWBmD5vZZ2GoIr4y/HW8HNhjcEUjfhG/z8weDH/Z3BW2FJwNfCn81XOUme1uZr8Kt/GAmR0RLrubmf0x/GV0FZDWnQvN7EIz+0rS8KPhL6U5Yby/AB5l++WDfxBu4y4z2z0cl9zC8j4z+7uZPQicmLTexWEZvAM4Hrg03Kd9w3kH59sveTjJScD/jhh3KcFleTPlNuC0DK5Pikh4VcezgM+Fn/nkFrljklrK/mZm04BLgKPCcV8KPyO3mdkK4K7wM/ho0ib2Cr8vnjCzC8L1DpvHzL4SfqZPJrjvxfXh+nce8V1zmpk9En7em5OW7zKzi8PvoPvNrCBuXqdEQnJK2PJwHMHVNSG4T8MX3H0uwZ3vXnH3w4DDgH81s72BjwD7E/wK/xSjtDCElfLPgJPcfT5wSthS8BPgB+GvnnsJ7p3xg3AbJxHeLpzgV9Cfw19GtxBcoXFH7Qf8p7sf6O5PE9y8aVW4jbvDbSbvQ3m4Dx8CDgXeNHKF7v4Xggr7q+E+PQm8YsHVJiG4yuTPR4nlCII7UCZrA143s3dG3cERsW0GysLWD5EJC6+GOZWkHwuhrwBLwpayo4DXCG4Wd2/4OfhBON8hwMnufswoq19I8Jk/CDhlMCkYI46bGd4i99rgtPBwRzPBvXgOBg4zs8FbwlcC94ffQfcA/5r+3ucuJRKSK3Y2szUEH85nCO75AbDS3f8RPn8P8Klwvr8S3IZ4P+Bo4L/dfau7dwArRln/4cA9g+sa5/LMxwJXhtu4DdjFgruhHg20hMv+Hti8Q3sbeNrd708a3gbcGD5vAY4cMf8BBDd7eiK8T0FLmtu5Cvi0mU0luCzzL0eZZ0+C23+P9B3gG2luZ6zL5CaPf5Gk5mCRDLkP+L6ZfR7YNel27CPdOc5n/0533xgmBb/mjZ+/dB0GtIY3ZRsArif4/oDgsO3vwuerCQ6/5L1Ix51FsuC18NfEEDOD4DbUQ6OAf3P3O0bM9/4MxjGFoK9A7yixRDHA8IS9POl5N+PL1PXrf0XQurECWO3uo9118bURsQUBuK8ws+8QJGKpbARGdqasBjqThsvDbYlMmAX3tdlKkJC+dXC8u19iZr8H3g/cZ2bvHWMV433mRn7enPE/v1H0J92sbCsFUgerRULyyR3AORbc6hwzm2tmlQRNhB8N+1DsCYzWFH8/cHR4KAQzqw7HbwGmJc33R+DfBgeSDgncQ9hxy4IOiOmefbCBoDkVMzsE2Huceaew/e6PHwf+PGL634E5ZrZvODxWf4Nh+xQmRXcAP2b0wxoAa4G3jDHtO8DXxol70APAEWb2Jgh61QNlwLPhsBEcjtmQxrpEhgkPT/4EuHLknUPNbF93f8Tdmwnehwfwxs92Ku82s2oz25mgw/J9wAsEnY53M7My4INJ84+1/pXAMWZWE7YCnkZwqLJgKZGQfHIVwe2WHww7QP2UIKO/BXginPYLgmP7w7j7SwQdtX5tZg+x/RDCb4GPDHa2BD4P1FvQmbOd7WePfIsgEXmMoJPjM2nG/CugOlzuc8C6cebtBhaG+7YIuGjEPvSG+/D7sMPkWLcUvgH4atjpbDDpuJ7g0Mkfx1jm9wRnsLyBu9/O6Ic9Rs73AvAF4Pbw0NDlwGnuPngn2UMJjg+P1ewsMtLO4WfzMWA5wfv3W6PM98WwY+PDQD/wB+BhYGvYsfFLaWxrJcHn9WHgV+FZIf0En8OVwJ0Eyfyga4CfDHa2HBzp7s8T9M/4E/AQQStgvtwSPhLd/VOkCFhw5sh0d//mOPP8Gfigu7+cpRiuAG5z97uysX4RiUdBHJ8RkbGZ2S3AvgStHOP5MsHZKFlJJIBHlUSIFB61SIiIiEhk6iMhIiIikSmREBERkciUSIiIiEhkSiREREQkMiUSIiIiEtn/D91zYN3jMYV/AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "if not os.path.exists(f'plots/{name}'):\n",
        "  os.makedirs(f'plots/{name}')\n",
        "\n",
        "f, axs = plt.subplots(1, 2, figsize=(8,6), gridspec_kw={'width_ratios': [4, 1]})\n",
        "\n",
        "f.suptitle(f'Residual Plot - {name}', fontsize=13, fontweight='bold',  y=0.92) \n",
        "axs[0].scatter(pred,residuals, label='Validation Set', alpha=0.75, color='tab:green')   \n",
        "axs[0].set_ylabel('Residual (NTU)')\n",
        "axs[0].set_xlabel('Predicted Turbidity (NTU)')      \n",
        "axs[0].axhline(0, color='black')\n",
        "axs[0].legend()\n",
        "axs[0].grid()\n",
        "\n",
        "axs[1].hist(residuals, bins=50, orientation=\"horizontal\", density=True, alpha=0.9, color='tab:green')\n",
        "axs[1].axhline(0, color='black')\n",
        "axs[1].set_xlabel('Distribution')  \n",
        "axs[1].yaxis.tick_right()\n",
        "axs[1].grid(axis='y')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.05)\n",
        "\n",
        "plt.savefig(f'{save_dir}/residualPlotVal_{name}.png', dpi=150)\n",
        "plt.savefig(f'{plot_dir}/residualPlotVal_{name}.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fbTAIvIhYGtt"
      },
      "outputs": [],
      "source": [
        "cv_df = pd.DataFrame.from_dict({'val_loss': VALIDATION_LOSS, 'val_mae': VALIDATION_MAE, 'val_mse': VALIDATION_MSE, 'val_R2': VALIDATION_R2}, orient='index').T\n",
        "cv_csv_file = f'{save_dir}/cross_val.csv'\n",
        "with open(cv_csv_file, mode='w') as f:\n",
        "    cv_df.to_csv(f)\n",
        "    \n",
        "rslt_csv_file = f'{save_dir}/val_result.csv'\n",
        "with open(rslt_csv_file, mode='w') as f:\n",
        "    rslt_df.to_csv(f)\n",
        "\n",
        "rslt_csv_file = f'{plot_dir}/val_result.csv'\n",
        "with open(rslt_csv_file, mode='w') as f:\n",
        "    rslt_df.to_csv(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTKe7NxRYGtt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "save_path = f\"/content/gdrive/MyDrive/MODEL BERHASIL/modelperbaikan/ResNet/{name}\"\n",
        "if not os.path.exists(save_path):\n",
        "  os.makedirs(save_path)\n",
        "\n",
        "oripath = \"saved_models/.\"\n",
        "!cp -a \"{oripath}\" \"{save_path}\" # copies files to google drive\n",
        "\n",
        "save_path2 = f\"/content/gdrive/MyDrive/MODEL BERHASIL/PlotPerbaikan/ResNet/{name}\"\n",
        "if not os.path.exists(save_path2):\n",
        "  os.makedirs(save_path2)\n",
        "\n",
        "oripath2 = \"plot_dir/.\"\n",
        "!cp -a \"{oripath2}\" \"{save_path2}\" # copies files to google drive"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "resnet_CV_ori.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}