{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naufalhisyam/TurbidityPrediction-thesis/blob/main/train_model_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpSYbrzpM90P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "!pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn.model_selection import train_test_split\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKCAZxGrzo8m"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/naufalhisyam/TurbidityPrediction-thesis.git\n",
        "os.chdir('/content/TurbidityPrediction-thesis') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CrL24L20ir7"
      },
      "source": [
        "**PREPARING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNwDTsrAzo8o"
      },
      "outputs": [],
      "source": [
        "images = pd.read_csv(r'./Datasets/0degree/0degInfo.csv') #load dataset info\n",
        "train_df, test_df = train_test_split(images, train_size=0.9, shuffle=True, random_state=1) #Split into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoQoBig2zo8o"
      },
      "outputs": [],
      "source": [
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    horizontal_flip=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA-9Gp_Tzo8p"
      },
      "outputs": [],
      "source": [
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Turbidity',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Turbidity',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Turbidity',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woSoOSOwzo8q"
      },
      "source": [
        "**CREATING THE MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyGUAtAJdnFQ"
      },
      "source": [
        "Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQToQ6MENCTt"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    #Create model\n",
        "    base_model = tf.keras.applications.DenseNet121(\n",
        "        include_top=False, weights=None, \n",
        "        input_shape=(224, 224, 3), pooling='avg')\n",
        "    out = base_model.output\n",
        "    prediction = tf.keras.layers.Dense(1, activation=\"linear\")(out)\n",
        "    model = tf.keras.Model(inputs = base_model.input, outputs = prediction)\n",
        "\n",
        "    #Compile the model\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(loss=\"mse\", optimizer=opt,\n",
        "                  metrics=['mae', tfa.metrics.RSquare(name=\"R2\")])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1rINXUigLTK"
      },
      "source": [
        "Training Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp8dP9o0zo8s"
      },
      "outputs": [],
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "        \n",
        "earlyStop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=5,\n",
        "    restore_best_weights=True)\n",
        "\n",
        "class CustomModelCheckpointCallback(tf.keras.callbacks.ModelCheckpoint):\n",
        "\n",
        "    def __init__(self, ignore_first, *args, **kwargs):\n",
        "      super(CustomModelCheckpointCallback, self).__init__(*args, **kwargs)\n",
        "      self.ignore_first = ignore_first\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        if epoch+1> self.ignore_first:\n",
        "            super().on_epoch_end(epoch, logs)\n",
        "\n",
        "pathname = 'saved_model/densenet-epoch{epoch:02d}-loss{val_loss:.2f}'\n",
        "checkpoint = CustomModelCheckpointCallback(\n",
        "    ignore_first=80, filepath = pathname,\n",
        "    monitor='val_loss', mode='min',\n",
        "    save_best_only=True, save_freq='epoch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAogg36tzo8t"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV2nFqfLf5yB"
      },
      "outputs": [],
      "source": [
        "num_epoch = 100\n",
        "history = model.fit(train_images, validation_data=val_images, \n",
        "                    epochs=num_epoch, batch_size=8, callbacks=[tensorboard_callback, checkpoint], verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save Model Manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_val_loss = history.history['val_loss'][-1]\n",
        "name = f'densenet-epoch{num_epoch}-loss{last_val_loss}'\n",
        "model.save(f\"saved_model/{name}\")\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_csv_file = f'saved_model/{name}/history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "#tf.keras.utils.plot_model(model, f\"saved_model/{name}/densenet_model_arch.png\", show_shapes=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7FnC4Q2gXGL"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFCSQyKH46W4"
      },
      "outputs": [],
      "source": [
        "pred_turbid = np.squeeze(model.predict(test_images))\n",
        "true_turbid = test_images.labels\n",
        "residuals = true_turbid - pred_turbid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIQTkGf8SEUC"
      },
      "outputs": [],
      "source": [
        "f, axs = plt.subplots(1, 2, figsize=(8,5), gridspec_kw={'width_ratios': [4, 1]})\n",
        "\n",
        "axs[0].scatter(pred_turbid,residuals)\n",
        "axs[0].set_title('Residual Plot dari Model DenseNet-121', fontsize=13, fontweight='bold')           \n",
        "axs[0].set_ylabel('Residual')\n",
        "axs[0].set_xlabel('Predicted Turbidity')      \n",
        "axs[0].axhline(0, color='black')\n",
        "axs[0].grid()\n",
        "\n",
        "axs[1].hist(residuals, bins=40, orientation=\"horizontal\", density=True)\n",
        "axs[1].axhline(0, color='black')\n",
        "axs[1].set_xlabel('Distribution')  \n",
        "axs[1].yaxis.tick_right()\n",
        "axs[1].grid(axis='y')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.05)\n",
        "plt.savefig(f'saved_model/{name}/residualPlot_{name}.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjeQEjhyUom-"
      },
      "outputs": [],
      "source": [
        "ms_error = history.history['loss']\n",
        "val_ms_error = history.history['val_loss']\n",
        "ma_error = history.history['mae']\n",
        "val_ma_error = history.history['val_mae']\n",
        "r2 = history.history['R2']\n",
        "val_r2 = history.history['val_R2']\n",
        "\n",
        "epochs = range(1, len(ms_error) + 1)\n",
        "\n",
        "f, axs = plt.subplots(3, 1, figsize=(6,14))\n",
        "axs[0].plot(epochs, ms_error, 'tab:orange', label='train_loss (mse)')\n",
        "axs[0].plot(epochs, val_ms_error, 'tab:blue', label='val_loss (mse)')\n",
        "axs[0].set_title('MSE Selama Training', fontsize=13, fontweight='bold')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('MSE')\n",
        "axs[0].legend(facecolor='white')\n",
        "axs[0].grid()\n",
        "\n",
        "axs[1].plot(epochs, ma_error, 'tab:orange', label='train_mae')\n",
        "axs[1].plot(epochs, val_ma_error, 'tab:blue', label='val_mae')\n",
        "axs[1].set_title('MAE Selama Training', fontsize=13, fontweight='bold')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('MAE')\n",
        "axs[1].legend(facecolor='white')\n",
        "axs[1].grid()\n",
        "\n",
        "axs[2].plot(epochs, r2, 'tab:orange', label='train_R2')\n",
        "axs[2].plot(epochs, val_r2, 'tab:blue', label='val_R2')\n",
        "axs[2].set_title('$R^2$ Selama Training', fontsize=13, fontweight='bold')\n",
        "axs[2].set_xlabel('Epoch')\n",
        "axs[2].set_ylabel('$R^2$')\n",
        "axs[2].legend(facecolor='white')\n",
        "axs[2].grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'saved_model/{name}/trainPlot_{name}.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDRWzVhPZ9qj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "save_path = f\"/content/gdrive/MyDrive/Hasil_Training/DenseNet\"\n",
        "if not os.path.exists(save_path):\n",
        "  os.makedirs(save_path)\n",
        "\n",
        "oripath = \"saved_model/.\"\n",
        "!cp -a \"{oripath}\" \"{save_path}\" # copies files to google drive"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "train_model_densenet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
